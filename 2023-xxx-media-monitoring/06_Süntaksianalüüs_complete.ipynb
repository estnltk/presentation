{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6213e3f",
   "metadata": {},
   "source": [
    "## Süntaksianalüüs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0a3a3",
   "metadata": {},
   "source": [
    "Selles notebookis kasutatakse ära automaatset süntaksianalüüsi, et leida huvipakkuvate nimeüksustega seotud täiendid (millised nad on), verbid (mida nad teevad) ning nende verbide küljes olevad määrused (kuidas midagi tehakse jne). Leitud sõnade põhjal pannakse paika üksikud laiemad teemad ning valitakse sõnade seast teemasid ilmestavad märksõnad, mille kaudu saab lauseid temaatilistesse klassidesse jaotada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "869aef06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.taggers import StanzaSyntaxEnsembleWebTagger\n",
    "from estnltk_neural.taggers.syntax.stanza_tagger.ensemble_tagger import StanzaSyntaxEnsembleTagger\n",
    "from estnltk_neural.taggers import StanzaSyntaxTagger\n",
    "from estnltk.taggers import SyntaxDependencyRetagger\n",
    "import sqlite3\n",
    "from estnltk.converters import json_to_text\n",
    "from estnltk.converters import text_to_json\n",
    "import csv\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f4360c",
   "metadata": {},
   "source": [
    "### I taggerid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff8041",
   "metadata": {},
   "source": [
    "Veebi kaudu kasutatav tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d79b7ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>BatchProcessingWebTagger</h4>\n",
       "Tags dependency syntactic analysis using EstNLTK StanzaSyntaxTagger's webservice.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>StanzaSyntaxEnsembleWebTagger</td>\n",
       "      <td>stanza_ensemble_syntax</td>\n",
       "      <td>('id', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc')</td>\n",
       "      <td>('words', 'sentences', 'morph_extended')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>https://api.tartunlp.ai/estnltk/tagger/stanza_syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_layer</th>\n",
       "      <td>words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_max_size</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_enveloping_layer</th>\n",
       "      <td>sentences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "StanzaSyntaxEnsembleWebTagger(input_layers=('words', 'sentences', 'morph_extended'), output_layer=stanza_ensemble_syntax, output_attributes=('id', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc'), url=https://api.tartunlp.ai/estnltk/tagger/stanza_syntax, batch_layer=words, batch_max_size=125, batch_enveloping_layer=sentences)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanza_syntax_ensemble_web_tagger = \\\n",
    "    StanzaSyntaxEnsembleWebTagger(url='https://api.tartunlp.ai/estnltk/tagger/stanza_syntax')\n",
    "stanza_syntax_ensemble_web_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef320674",
   "metadata": {},
   "source": [
    "Siin võetakse märgendamisel kasutusele Stanza ensemble taggeri asemel tavaline Stanza tagger, sest selle töökiirus on parem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d8f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza_tagger = StanzaSyntaxTagger(input_type='morph_analysis', input_morph_layer='morph_analysis', add_parent_and_children=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e3e691",
   "metadata": {},
   "source": [
    "### II andmete sisselugemine ja süntaksianalüüsi kihi peale märgendamine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d07e9",
   "metadata": {},
   "source": [
    "Kõigepealt loetakse andmebaasist sisse laused, millele on PhraseTaggeriga märgendatud peale mõni huvipakkuvatest nimeüksustest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2998e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentence_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "178cb65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"media_data_complete.db\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c0c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID asemel võtta tabelist sentence_ID\n",
    "for row in cur.execute(\"SELECT sentence_ID, sentence FROM phrase_tagger_sentences\"):\n",
    "    sentence_id = row[0]\n",
    "    sentence = json_to_text(json_text=row[1])\n",
    "    sentences.append(sentence)\n",
    "    sentence_ids.append(sentence_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cbc4c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56b5f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18569"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd959d",
   "metadata": {},
   "source": [
    "Seejärel märgendatakse lausetele süntaksianalüüsi kiht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10141a5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "('ambiguous enveloping layer: entity_phrases', \"in the 'StanzaSyntaxEnsembleWebTagger'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[0;32m      2\u001b[0m     sentence\u001b[38;5;241m.\u001b[39mtag_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmorph_extended\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mstanza_syntax_ensemble_web_tagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     SyntaxDependencyRetagger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstanza_ensemble_syntax\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mretag(sentence) \u001b[38;5;66;03m#Parent ja children atribuutide lisamiseks kihile\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\estnltk_core\\taggers\\tagger.py:343\u001b[0m, in \u001b[0;36mTagger.tag\u001b[1;34m(self, text, status)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtag\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: Union[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseText\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m], status: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseText\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Annotates Text object with this tagger.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    Note: derived classes **should not override** this method.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m        Input Text object which has a new (attached) layer created by this tagger.\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 343\u001b[0m     text\u001b[38;5;241m.\u001b[39madd_layer(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelation_layers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\estnltk_core\\taggers\\tagger.py:306\u001b[0m, in \u001b[0;36mTagger.make_layer\u001b[1;34m(self, text, layers, status)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing input layer: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(layer))\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 306\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    308\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min the \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\estnltk\\web_taggers\\v01\\batch_processing_web_tagger.py:162\u001b[0m, in \u001b[0;36mBatchProcessingWebTagger._make_layer\u001b[1;34m(self, text, layers, status)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_layer\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: Text, layers: MutableMapping[\u001b[38;5;28mstr\u001b[39m, Layer], status: \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 162\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\estnltk\\web_taggers\\v01\\batch_processing_web_tagger.py:114\u001b[0m, in \u001b[0;36mBatchProcessingWebTagger.batch_process\u001b[1;34m(self, text, layers, parameters)\u001b[0m\n\u001b[0;32m    112\u001b[0m         target_text\u001b[38;5;241m.\u001b[39madd_layer(layer)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Split large Text obj into smaller ones\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m smaller_texts, separators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_text_into_smaller_texts_via_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_text\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Process smaller Texts\u001b[39;00m\n\u001b[0;32m    116\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch processing \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m chunks ...\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(smaller_texts)) )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\estnltk\\web_taggers\\v01\\batch_processing_web_tagger.py:296\u001b[0m, in \u001b[0;36mBatchProcessingWebTagger._split_text_into_smaller_texts_via_layer\u001b[1;34m(self, large_text)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk_separators) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunks) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# Exctract chunks\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ( \u001b[43mextract_sections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlarge_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers_to_keep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlarge_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtrim_overlapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrimming_required\u001b[49m\u001b[43m)\u001b[49m, chunk_separators )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\estnltk_core\\layer_operations\\iterators\\splitting.py:84\u001b[0m, in \u001b[0;36mextract_sections\u001b[1;34m(text, sections, layers_to_keep, trim_overlapping)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m enveloping:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ambiguous:\n\u001b[1;32m---> 84\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mambiguous enveloping layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m layer_name)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m span \u001b[38;5;129;01min\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mspans:\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: ('ambiguous enveloping layer: entity_phrases', \"in the 'StanzaSyntaxEnsembleWebTagger'\")"
     ]
    }
   ],
   "source": [
    "#Veebitaggeriga\n",
    "for sentence in sentences:\n",
    "    sentence.tag_layer('morph_extended')\n",
    "    stanza_syntax_ensemble_web_tagger.tag(sentence)\n",
    "    SyntaxDependencyRetagger('stanza_ensemble_syntax').retag(sentence) #Parent ja children atribuutide lisamiseks kihile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be326cd",
   "metadata": {},
   "source": [
    "Veebitaggeriga tekkis märgendamisel mõne lause juures viga, mis on seotud PhraseTaggeri abil peale märgendatud nimeüksuste kihiga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43906b16",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "('[enforce fail at ..\\\\c10\\\\core\\\\impl\\\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 6370721952 bytes.', \"in the 'StanzaSyntaxTagger'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#sentence.tag_layer('morph_extended')\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mstanza_tagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\estnltk_core\\taggers\\tagger.py:343\u001b[0m, in \u001b[0;36mTagger.tag\u001b[1;34m(self, text, status)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtag\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: Union[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseText\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m], status: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseText\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Annotates Text object with this tagger.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    Note: derived classes **should not override** this method.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m        Input Text object which has a new (attached) layer created by this tagger.\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 343\u001b[0m     text\u001b[38;5;241m.\u001b[39madd_layer(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelation_layers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\estnltk_core\\taggers\\tagger.py:306\u001b[0m, in \u001b[0;36mTagger.make_layer\u001b[1;34m(self, text, layers, status)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing input layer: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(layer))\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 306\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    308\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min the \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\estnltk_neural\\taggers\\syntax\\stanza_tagger\\stanza_tagger.py:234\u001b[0m, in \u001b[0;36mStanzaSyntaxTagger._make_layer\u001b[1;34m(self, text, layers, status)\u001b[0m\n\u001b[0;32m    231\u001b[0m layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_layer_template()\n\u001b[0;32m    232\u001b[0m layer\u001b[38;5;241m.\u001b[39mtext_object\u001b[38;5;241m=\u001b[39mtext\n\u001b[1;32m--> 234\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m [analysis \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mto_dict() \u001b[38;5;28;01mfor\u001b[39;00m analysis \u001b[38;5;129;01min\u001b[39;00m sentence]\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line, span \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(extracted_data, parent_layer):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\stanza\\pipeline\\core.py:464\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, doc, processors)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc, processors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\stanza\\pipeline\\core.py:415\u001b[0m, in \u001b[0;36mPipeline.process\u001b[1;34m(self, doc, processors)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors\u001b[38;5;241m.\u001b[39mget(processor_name):\n\u001b[0;32m    414\u001b[0m         process \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors[processor_name]\u001b[38;5;241m.\u001b[39mbulk_process \u001b[38;5;28;01mif\u001b[39;00m bulk \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors[processor_name]\u001b[38;5;241m.\u001b[39mprocess\n\u001b[1;32m--> 415\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\stanza\\pipeline\\depparse_processor.py:62\u001b[0m, in \u001b[0;36mDepparseProcessor.process\u001b[1;34m(self, document)\u001b[0m\n\u001b[0;32m     60\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch):\n\u001b[1;32m---> 62\u001b[0m     preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mdata_orig_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     preds \u001b[38;5;241m=\u001b[39m unsort(preds, batch\u001b[38;5;241m.\u001b[39mdata_orig_idx)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\stanza\\models\\depparse\\trainer.py:70\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[1;34m(self, batch, unsort)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     69\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m word\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwordchars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwordchars_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlemma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeprel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_orig_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwordlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m head_seqs \u001b[38;5;241m=\u001b[39m [chuliu_edmonds_one_root(adj[:l, :l])[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m adj, l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(preds[\u001b[38;5;241m0\u001b[39m], sentlens)] \u001b[38;5;66;03m# remove attachment for the root\u001b[39;00m\n\u001b[0;32m     72\u001b[0m deprel_seqs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeprel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munmap([preds[\u001b[38;5;241m1\u001b[39m][i][j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][h] \u001b[38;5;28;01mfor\u001b[39;00m j, h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(hs)]) \u001b[38;5;28;01mfor\u001b[39;00m i, hs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(head_seqs)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\stanza\\models\\depparse\\model.py:162\u001b[0m, in \u001b[0;36mParser.forward\u001b[1;34m(self, word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, lemma, head, deprel, word_orig_idx, sentlens, wordlens, text)\u001b[0m\n\u001b[0;32m    159\u001b[0m lstm_outputs, _ \u001b[38;5;241m=\u001b[39m pad_packed_sequence(lstm_outputs, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    161\u001b[0m unlabeled_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munlabeled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(lstm_outputs), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(lstm_outputs))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 162\u001b[0m deprel_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeprel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m#goldmask = head.new_zeros(*head.size(), head.size(-1)+1, dtype=torch.uint8)\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m#goldmask.scatter_(2, head.unsqueeze(2), 1)\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinearization\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\stanza\\models\\common\\biaffine.py:74\u001b[0m, in \u001b[0;36mDeepBiaffineScorer.forward\u001b[1;34m(self, input1, input2)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input1, input2):\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW2\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\stanza\\models\\common\\biaffine.py:59\u001b[0m, in \u001b[0;36mPairwiseBiaffineScorer.forward\u001b[1;34m(self, input1, input2)\u001b[0m\n\u001b[0;32m     57\u001b[0m input1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([input1, input1\u001b[38;5;241m.\u001b[39mnew_ones(\u001b[38;5;241m*\u001b[39minput1\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)], \u001b[38;5;28mlen\u001b[39m(input1\u001b[38;5;241m.\u001b[39msize())\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     58\u001b[0m input2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([input2, input2\u001b[38;5;241m.\u001b[39mnew_ones(\u001b[38;5;241m*\u001b[39minput2\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)], \u001b[38;5;28mlen\u001b[39m(input2\u001b[38;5;241m.\u001b[39msize())\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_bilin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\stanza\\models\\common\\biaffine.py:29\u001b[0m, in \u001b[0;36mPairwiseBilinear.forward\u001b[1;34m(self, input1, input2)\u001b[0m\n\u001b[0;32m     27\u001b[0m input2 \u001b[38;5;241m=\u001b[39m input2\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# (N x (L1 x O) x D2) * (N x D2 x L2) -> (N x (L1 x O) x L2)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mintermediate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput1_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput2_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# (N x (L1 x O) x L2) -> (N x L1 x L2 x O)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mview(input1_size[\u001b[38;5;241m0\u001b[39m], input1_size[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size, input2_size[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: ('[enforce fail at ..\\\\c10\\\\core\\\\impl\\\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 6370721952 bytes.', \"in the 'StanzaSyntaxTagger'\")"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    stanza_tagger.tag(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
