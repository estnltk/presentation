{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "automaatne info eraldamine - Colab.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAvmZNH8Anrm"
      },
      "source": [
        "<H1 style=\"text-align: center;\">\n",
        "Tekstitöötluse põhietapid\n",
        "</H1>\n",
        "\n",
        "<H4 style=\"text-align: center;\">\n",
        "Dage Särg\n",
        "</H4>\n",
        "\n",
        "<H4 style=\"text-align: center;\">\n",
        "Automaatne info eraldamine eestikeelsest tekstist. 08.10.2020\n",
        "</H4>\n",
        "\n",
        "<H4 style=\"text-align: center;\">\n",
        "Notebook leitav: https://tinyurl.com/nlp-notebook\n",
        "</H4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcjnn_HAAnru"
      },
      "source": [
        "### Colab 101:\n",
        "\n",
        "Google Colaboratory (edaspidi: Google Colab) on veebipõhine keskkond, kus on mugav jooksutada Pythoni koodi ning jagada seda ka teistega.\n",
        "Enda arvutisse midagi installida pole tarvis, piisab, kui omad Google kontot ja logid veebibrauseri kaudu sisse.\n",
        "\n",
        "Colabi kasutamiseks:\n",
        "* Ava käesolev notebook oma arvutis (https://tinyurl.com/nlp-notebook) \n",
        "* Logi oma google'i kontoga sisse (kui pole veel loginud)\n",
        "* Salvesta käesolev märkmik enda Google Drive kettale, valides _File_ menüüst -> _Save a copy in Drive_.\n",
        "* Ja saadki asuda katsetama.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3xmDfoZBwWs"
      },
      "source": [
        "Katseta Pythoni koodi käivitamist järgmisel lahtril: mine lahtri peale ja vajuta **shift+ENTER** või kliki lahtri kõrval olevale \"Run Cell\" nupule:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytTaDMx0BEXm",
        "outputId": "cb808537-f0f7-46cd-8a46-770abc042d18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Tere!\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tere!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WpOt_DcB9sa"
      },
      "source": [
        "**Käivitamise järjekord on oluline**: lahtreid tuleb reeglina käivitada üksteise järel ning enne käivitamist veenduda, et kõik eelnevad lahtrid on täidetud. Kui käivitamisel tekib veateade `NameError: name '...' is not defined`, on tõenäoliselt põhjuseks just vale lahtrite käivitamise järjekord: varasemast on jäänud mõni vastava nimega komponenti importiv lahter käivitamata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrnD2L5KCUaR"
      },
      "source": [
        "\n",
        "Järgmine samm on Pythoni teegi EstNLTK installimine.\n",
        "\n",
        "Google Colab-is EstNLTK installimiseks tuleb lihtsalt klikkida järgnevale lahtrile ja vajutada shift+ENTER (või klikkida \"Run Cell\" nupule) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNHrPNyaCbyI",
        "outputId": "ecf2ec54-521d-4a88-af58-b237997bc354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        }
      },
      "source": [
        "!pip install estnltk==1.6.7b0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting estnltk==1.6.7b0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/22/042991e0ec86dc5b49740f4a4972b451b94577fe07f90feebefad09af69a/estnltk-1.6.7b0-cp36-cp36m-manylinux2014_x86_64.whl (96.4MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4MB 52kB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2015.07.19 in /usr/local/lib/python3.6/dist-packages (from estnltk==1.6.7b0) (2019.12.20)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from estnltk==1.6.7b0) (1.0.1)\n",
            "Requirement already satisfied: nltk>=3.0.4 in /usr/local/lib/python3.6/dist-packages (from estnltk==1.6.7b0) (3.2.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from estnltk==1.6.7b0) (4.2.6)\n",
            "Collecting conllu==3.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/61/f9/4d66cd89e31fb77f70a7cda6b72aca34572df1dd09805d765ce1bb0f24b5/conllu-3.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from estnltk==1.6.7b0) (2.5)\n",
            "Collecting cached-property>=1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.16.2 in /usr/local/lib/python3.6/dist-packages (from estnltk==1.6.7b0) (1.1.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from estnltk==1.6.7b0) (0.0.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from html5lib->estnltk==1.6.7b0) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib->estnltk==1.6.7b0) (0.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->estnltk==1.6.7b0) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.16.2->estnltk==1.6.7b0) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.16.2->estnltk==1.6.7b0) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.16.2->estnltk==1.6.7b0) (2018.9)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->estnltk==1.6.7b0) (4.6.3)\n",
            "Installing collected packages: conllu, cached-property, python-crfsuite, estnltk\n",
            "Successfully installed cached-property-1.5.2 conllu-3.1.1 estnltk-1.6.7b0 python-crfsuite-0.9.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hET_dXQxCtNv"
      },
      "source": [
        "Tulemusena peaksid nägema, kuidas laetakse alla ja installitakse estnltk ja selle tööks vajalikud sõltuvusteegid. \n",
        "Kõigi järgnevate lahtrite käivitamine eeldab, et estnltk on juba installitud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxANo2QPCurb"
      },
      "source": [
        "Aga kui kasutad seda märkmikku läbi oma arvutisse installitud Jupyter Notebooki, teosta EstNLTK installimine meilile saadetud juhiste järgi ning jäta käsk `!pip install ...` üldse  vahele."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QX_YmURAnrx"
      },
      "source": [
        "## 1. Teksti segmenteerimine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vIWPr3DAnr1",
        "outputId": "bcc2afe0-33d4-43b4-e008-08947e53ff90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "from estnltk import Text\n",
        "# Teksti töötlemiseks peame tegema stringi Text objektiks\n",
        "text = Text(\"Festivalil osales üle 30 000 muusikahuvilise.\")\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td><div align = \"left\">Festivalil osales üle 30 000 muusikahuvilise.</div></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Text(text='Festivalil osales üle 30 000 muusikahuvilise.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUx3Gf-mAnsY",
        "outputId": "fab3b39b-3edb-486f-dfde-cfdbc4a71c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "# tag_layer() meetod märgib peale standardsed analüüsikihid,\n",
        "# mida on vaja pea kõigi keeletöötlusülesannete juures\n",
        "text.tag_layer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td><div align = \"left\">Festivalil osales üle 30 000 muusikahuvilise.</div></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>sentences</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>tokens</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>compound_tokens</td>\n",
              "      <td>type, normalized</td>\n",
              "      <td>None</td>\n",
              "      <td>tokens</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>words</td>\n",
              "      <td>normalized_form</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
              "      <td>words</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Text(text='Festivalil osales üle 30 000 muusikahuvilise.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPLxfI4nAnsm",
        "outputId": "c3342c56-d5a4-48ad-c186-18a40cf55ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text.text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Festivalil osales üle 30 000 muusikahuvilise.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di0w4dlcAnsy",
        "outputId": "09452385-eec9-461b-abf5-8bc357614d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "# Tokens e sõned - mitte alati lingvistiliselt motiveeritud\n",
        "text.tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>tokens</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>Festivalil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>osales</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>üle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>muusikahuvilise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='tokens', attributes=(), spans=SL[Span('Festivalil', [{}]),\n",
              "Span('osales', [{}]),\n",
              "Span('üle', [{}]),\n",
              "Span('30', [{}]),\n",
              "Span('000', [{}]),\n",
              "Span('muusikahuvilise', [{}]),\n",
              "Span('.', [{}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jndHaAqTAns9",
        "outputId": "672e2922-e751-43f1-b749-3ef874a6d01a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "# Words e sõnad - mõned tokenid ühendatakse edasiseks töötluseks kokku\n",
        "text.words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>words</td>\n",
              "      <td>normalized_form</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>normalized_form</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>Festivalil</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>osales</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>üle</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30 000</td>\n",
              "      <td>30000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>muusikahuvilise</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>.</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Festivalil', [{'normalized_form': None}]),\n",
              "Span('osales', [{'normalized_form': None}]),\n",
              "Span('üle', [{'normalized_form': None}]),\n",
              "Span('30 000', [{'normalized_form': '30000'}]),\n",
              "Span('muusikahuvilise', [{'normalized_form': None}]),\n",
              "Span('.', [{'normalized_form': None}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD0XEywTAntK",
        "outputId": "5bbec2ea-8e26-41c8-9cf4-19d71646fcf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# On võimalik märgendada ka osalauseid\n",
        "text = Text('Nendel, kes minu ja Oudekki kaotusele loodavad, on ettekujutus, et rahval polegi hääli.')\n",
        "\n",
        "text.tag_layer(['clauses'])\n",
        "text.clauses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>clauses</td>\n",
              "      <td>clause_type</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>clause_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['Nendel', 'on', 'ettekujutus', ',']</td>\n",
              "      <td>regular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[',', 'kes', 'minu', 'ja', 'Oudekki', 'kaotusele', 'loodavad', ',']</td>\n",
              "      <td>embedded</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['et', 'rahval', 'polegi', 'hääli', '.']</td>\n",
              "      <td>regular</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='clauses', attributes=('clause_type',), spans=SL[EnvelopingSpan(['Nendel', 'on', 'ettekujutus', ','], [{'clause_type': 'regular'}]),\n",
              "EnvelopingSpan([',', 'kes', 'minu', 'ja', 'Oudekki', 'kaotusele', 'loodavad', ','], [{'clause_type': 'embedded'}]),\n",
              "EnvelopingSpan(['et', 'rahval', 'polegi', 'hääli', '.'], [{'clause_type': 'regular'}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpQG10YEAntm",
        "outputId": "292b9987-f5ac-4fff-b2bf-220b4e21ed59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# Laused - punkt ei toimi alati eraldajana\n",
        "text = Text('Tartu Rattaralli toimub 29. mail 2020. \\\n",
        "Tartu Rattaralli stardi- ja finišipaik \\\n",
        "on traditsiooniliselt Tartu kesklinnas, Turu tänaval.')\n",
        "text.tag_layer()\n",
        "text.sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>sentences</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['Tartu', 'Rattaralli', 'toimub', '29.', 'mail', '2020.']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['Tartu', 'Rattaralli', 'stardi-', 'ja', 'finišipaik', 'on', 'traditsiooniliselt ..., type: &lt;class 'list'&gt;, length: 13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='sentences', attributes=(), spans=SL[EnvelopingSpan(['Tartu', 'Rattaralli', 'toimub', '29.', 'mail', '2020.'], [{}]),\n",
              "EnvelopingSpan(['Tartu', 'Rattaralli', 'stardi-', 'ja', 'finišipaik', 'on', 'traditsiooniliselt', 'Tartu', 'kesklinnas', ',', 'Turu', 'tänaval', '.'], [{}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY4_Z-P_Anty",
        "outputId": "72b4523d-cfe1-4f31-bcf0-a7010ce66db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# Tekst koosneb lausetest, mis koosnevad omakorda sõnadest\n",
        "for sentence in text.sentences:\n",
        "    print(' Lause: ', sentence.enclosing_text)\n",
        "    for word in sentence:\n",
        "        # Väljastame sõna ja sõnaliigi\n",
        "        print( word.text, word.morph_analysis.partofspeech[0] )\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Lause:  Tartu Rattaralli toimub 29. mail 2020.\n",
            "Tartu H\n",
            "Rattaralli S\n",
            "toimub V\n",
            "29. O\n",
            "mail S\n",
            "2020. O\n",
            "\n",
            " Lause:  Tartu Rattaralli stardi- ja finišipaik on traditsiooniliselt Tartu kesklinnas, Turu tänaval.\n",
            "Tartu H\n",
            "Rattaralli S\n",
            "stardi- S\n",
            "ja J\n",
            "finišipaik S\n",
            "on V\n",
            "traditsiooniliselt D\n",
            "Tartu H\n",
            "kesklinnas S\n",
            ", Z\n",
            "Turu H\n",
            "tänaval S\n",
            ". Z\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXWsRbw-Ant9"
      },
      "source": [
        "## 2. Lemmatiseerimine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEYk4nsPAnuB",
        "outputId": "d4eb736f-b738-42f2-fe34-1256b5028269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "# Morf analüüs eesti keele puhul baassamm \n",
        "t = Text('Mida ubadest teha? Oad võib salatisse panna.').tag_layer()\n",
        "t.lemma"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>AmbiguousAttributeList</h4>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>mis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td></td>\n",
              "      <td>mis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>uba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>tegema</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>uba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>võima</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>salat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>panema</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "AmbiguousAttributeList([['mis', 'mis'], ['uba'], ['tegema'], ['?'], ['uba'], ['võima'], ['salat'], ['panema'], ['.']], ('lemma',))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONSs1PaOAnua",
        "outputId": "359ca17f-40be-4368-9db9-21cb157cec33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "source": [
        "# Morf analüüs eesti keele puhul baassamm \n",
        "t = Text('Mida ubadest teha? Oad võib salatisse panna.').tag_layer()\n",
        "t.morph_analysis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
              "      <td>words</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>normalized_text</th>\n",
              "      <th>lemma</th>\n",
              "      <th>root</th>\n",
              "      <th>root_tokens</th>\n",
              "      <th>ending</th>\n",
              "      <th>clitic</th>\n",
              "      <th>form</th>\n",
              "      <th>partofspeech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>Mida</td>\n",
              "      <td>Mida</td>\n",
              "      <td>mis</td>\n",
              "      <td>mis</td>\n",
              "      <td>['mis']</td>\n",
              "      <td>da</td>\n",
              "      <td></td>\n",
              "      <td>pl p</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td></td>\n",
              "      <td>Mida</td>\n",
              "      <td>mis</td>\n",
              "      <td>mis</td>\n",
              "      <td>['mis']</td>\n",
              "      <td>da</td>\n",
              "      <td></td>\n",
              "      <td>sg p</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>ubadest</td>\n",
              "      <td>ubadest</td>\n",
              "      <td>uba</td>\n",
              "      <td>uba</td>\n",
              "      <td>['uba']</td>\n",
              "      <td>dest</td>\n",
              "      <td></td>\n",
              "      <td>pl el</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>teha</td>\n",
              "      <td>teha</td>\n",
              "      <td>tegema</td>\n",
              "      <td>tege</td>\n",
              "      <td>['tege']</td>\n",
              "      <td>a</td>\n",
              "      <td></td>\n",
              "      <td>da</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>['?']</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Oad</td>\n",
              "      <td>Oad</td>\n",
              "      <td>uba</td>\n",
              "      <td>uba</td>\n",
              "      <td>['uba']</td>\n",
              "      <td>d</td>\n",
              "      <td></td>\n",
              "      <td>pl n</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>võib</td>\n",
              "      <td>võib</td>\n",
              "      <td>võima</td>\n",
              "      <td>või</td>\n",
              "      <td>['või']</td>\n",
              "      <td>b</td>\n",
              "      <td></td>\n",
              "      <td>b</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>salatisse</td>\n",
              "      <td>salatisse</td>\n",
              "      <td>salat</td>\n",
              "      <td>salat</td>\n",
              "      <td>['salat']</td>\n",
              "      <td>sse</td>\n",
              "      <td></td>\n",
              "      <td>sg ill</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>panna</td>\n",
              "      <td>panna</td>\n",
              "      <td>panema</td>\n",
              "      <td>pane</td>\n",
              "      <td>['pane']</td>\n",
              "      <td>a</td>\n",
              "      <td></td>\n",
              "      <td>da</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>['.']</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Z</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Mida', [{'normalized_text': 'Mida', 'lemma': 'mis', 'root': 'mis', 'root_tokens': ['mis'], 'ending': 'da', 'clitic': '', 'form': 'pl p', 'partofspeech': 'P'}, {'normalized_text': 'Mida', 'lemma': 'mis', 'root': 'mis', 'root_tokens': ['mis'], 'ending': 'da', 'clitic': '', 'form': 'sg p', 'partofspeech': 'P'}]),\n",
              "Span('ubadest', [{'normalized_text': 'ubadest', 'lemma': 'uba', 'root': 'uba', 'root_tokens': ['uba'], 'ending': 'dest', 'clitic': '', 'form': 'pl el', 'partofspeech': 'S'}]),\n",
              "Span('teha', [{'normalized_text': 'teha', 'lemma': 'tegema', 'root': 'tege', 'root_tokens': ['tege'], 'ending': 'a', 'clitic': '', 'form': 'da', 'partofspeech': 'V'}]),\n",
              "Span('?', [{'normalized_text': '?', 'lemma': '?', 'root': '?', 'root_tokens': ['?'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
              "Span('Oad', [{'normalized_text': 'Oad', 'lemma': 'uba', 'root': 'uba', 'root_tokens': ['uba'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
              "Span('võib', [{'normalized_text': 'võib', 'lemma': 'võima', 'root': 'või', 'root_tokens': ['või'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
              "Span('salatisse', [{'normalized_text': 'salatisse', 'lemma': 'salat', 'root': 'salat', 'root_tokens': ['salat'], 'ending': 'sse', 'clitic': '', 'form': 'sg ill', 'partofspeech': 'S'}]),\n",
              "Span('panna', [{'normalized_text': 'panna', 'lemma': 'panema', 'root': 'pane', 'root_tokens': ['pane'], 'ending': 'a', 'clitic': '', 'form': 'da', 'partofspeech': 'V'}]),\n",
              "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4U02FVbAnul",
        "outputId": "a04e82ee-848b-4b33-c629-379881ad3ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "# Võime vaadata ka vaid parajasti huvitavaid atribuute, mitte kogu analüüsi\n",
        "t.morph_analysis['text', 'lemma', 'partofspeech']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>AmbiguousAttributeTupleList</h4>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lemma</th>\n",
              "      <th>partofspeech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Mida</td>\n",
              "      <td>mis</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td></td>\n",
              "      <td>Mida</td>\n",
              "      <td>mis</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>ubadest</td>\n",
              "      <td>uba</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>teha</td>\n",
              "      <td>tegema</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>Oad</td>\n",
              "      <td>uba</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>võib</td>\n",
              "      <td>võima</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>salatisse</td>\n",
              "      <td>salat</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>panna</td>\n",
              "      <td>panema</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>Z</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "AmbiguousAttributeTupleList([[['Mida', 'mis', 'P'], ['Mida', 'mis', 'P']], [['ubadest', 'uba', 'S']], [['teha', 'tegema', 'V']], [['?', '?', 'Z']], [['Oad', 'uba', 'S']], [['võib', 'võima', 'V']], [['salatisse', 'salat', 'S']], [['panna', 'panema', 'V']], [['.', '.', 'Z']]], ('text', 'lemma', 'partofspeech'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjoXcMrYAnux"
      },
      "source": [
        "#### Näide: leiame kõik tekstis olevad nimisõnad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uklnJBZcAnu1",
        "outputId": "44a08759-1606-499d-8f0f-5a879e9d7a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "my_text = Text('Nagu nimigi reedab, on nurgasaag kõige \\\n",
        "tõhusam tööriist erinevate puitdetailide lõikamiseks, \\\n",
        "kus eesmärgiks on saavutada täpne lõikenurk ning oluline on \\\n",
        "lõikenurga seadistamise võimalus. Näiteks pildiraamide \\\n",
        "meisterdamisel, kus on oluline, et detailide lõikenurgad \\\n",
        "oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag \\\n",
        "täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. \\\n",
        "Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise \\\n",
        "lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned \\\n",
        "saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks \\\n",
        "keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka \\\n",
        "kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide \\\n",
        "ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks \\\n",
        "puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade \\\n",
        "või puitparketi paigaldamisel.')\n",
        "my_text.tag_layer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td><div align = \"left\">Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.</div></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>sentences</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>tokens</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>compound_tokens</td>\n",
              "      <td>type, normalized</td>\n",
              "      <td>None</td>\n",
              "      <td>tokens</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>words</td>\n",
              "      <td>normalized_form</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
              "      <td>words</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Text(text='Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP10a0BuAnvK",
        "outputId": "0fbbcd04-5d01-422b-ff62-2a022466c2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "noun_lemmas = []\n",
        "for lemmas, postags in zip(my_text.lemma, my_text.partofspeech):\n",
        "    if 'S' in postags: # text.lemma ja partofspeech on listid, kuna analüüse võib olla mitu\n",
        "        noun_lemmas += lemmas\n",
        "noun_lemmas  \n",
        "\n",
        "from collections import Counter\n",
        "Counter(noun_lemmas).most_common()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nurgasaag', 4),\n",
              " ('lõikenurk', 4),\n",
              " ('näide', 3),\n",
              " ('tööriist', 2),\n",
              " ('puitdetail', 2),\n",
              " ('lõikamine', 2),\n",
              " ('seadistamine', 2),\n",
              " ('detail', 2),\n",
              " ('nimi', 1),\n",
              " ('eesmärk', 1),\n",
              " ('võimalus', 1),\n",
              " ('pildiraam', 1),\n",
              " ('meisterdamine', 1),\n",
              " ('kraad', 1),\n",
              " ('juht', 1),\n",
              " ('täpsus', 1),\n",
              " ('lõige', 1),\n",
              " ('korratavus', 1),\n",
              " ('osa', 1),\n",
              " ('suund', 1),\n",
              " ('lisa', 1),\n",
              " ('saag', 1),\n",
              " ('saetera', 1),\n",
              " ('kaldenurk', 1),\n",
              " ('kasu', 1),\n",
              " ('laius', 1),\n",
              " ('puulaud', 1),\n",
              " ('ristlõige', 1),\n",
              " ('tegemine', 1),\n",
              " ('järkamine', 1),\n",
              " ('puitkonstruktsioon', 1),\n",
              " ('ehitamine', 1),\n",
              " ('terrassilaud', 1),\n",
              " ('puitparkett', 1),\n",
              " ('paigaldamine', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYMVfTgsAnvV"
      },
      "source": [
        "#### Näide: leiame kõik infinitiivset verbi sisaldavad laused:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS1QoBniAnvX",
        "outputId": "c08533f3-37d2-497a-d295-293d43964a6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "infinitive_sentences = []\n",
        "for sent in my_text.sentences: # vaatame teksti lause kaupa\n",
        "    for form in sent.form: # vaatame läbi kõik lause sõnade vormiinfod\n",
        "        if 'da' in form:\n",
        "            a = sent.enclosing_text # lause tekst stringina\n",
        "            infinitive_sentences.append(a)\n",
        "            break\n",
        "infinitive_sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWFKZmZ8Anwk"
      },
      "source": [
        "## 5. Semantiline analüüs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjj3WVHtAnwp"
      },
      "source": [
        "### Ajaväljendite tuvastamine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usC1O3sNAnws"
      },
      "source": [
        "text3 = Text('EKA sisearhitektuuri osakond ja RMK avavad neljapäeval kell 16.00 RMK Tallinna kontoris (Toompuiestee 24) näituse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQlYLd7AAnw0",
        "outputId": "b14b5219-9600-4809-f860-4bcd8ebcd179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "# Märgendame ajaväljendid\n",
        "from estnltk.taggers import TimexTagger\n",
        "\n",
        "tagger = TimexTagger()\n",
        "text3.tag_layer()\n",
        "tagger.tag( text3 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td><div align = \"left\">EKA sisearhitektuuri osakond ja RMK avavad neljapäeval kell 16.00 RMK Tallinna kontoris (Toompuiestee 24) näituse</div></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<h4>Metadata</h4>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>document_creation_time</td>\n",
              "      <td>2020-10-04T19:21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>sentences</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>tokens</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>compound_tokens</td>\n",
              "      <td>type, normalized</td>\n",
              "      <td>None</td>\n",
              "      <td>tokens</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>words</td>\n",
              "      <td>normalized_form</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
              "      <td>words</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>timexes</td>\n",
              "      <td>tid, type, value, temporal_function, anchor_time_id, mod, quant, freq, begin_point, end_point, part_of_interval</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Text(text='EKA sisearhitektuuri osakond ja RMK avavad neljapäeval kell 16.00 RMK Tallinna kontoris (Toompuiestee 24) näituse')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1KUrwqgAnw9",
        "outputId": "730c63ec-d601-4f7d-86ca-ef660ad9d19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "text3.timexes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>timexes</td>\n",
              "      <td>tid, type, value, temporal_function, anchor_time_id, mod, quant, freq, begin_point, end_point, part_of_interval</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>tid</th>\n",
              "      <th>type</th>\n",
              "      <th>value</th>\n",
              "      <th>temporal_function</th>\n",
              "      <th>anchor_time_id</th>\n",
              "      <th>mod</th>\n",
              "      <th>quant</th>\n",
              "      <th>freq</th>\n",
              "      <th>begin_point</th>\n",
              "      <th>end_point</th>\n",
              "      <th>part_of_interval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['neljapäeval', 'kell', '16.00']</td>\n",
              "      <td>t1</td>\n",
              "      <td>TIME</td>\n",
              "      <td>2020-10-08T16:00</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='timexes', attributes=('tid', 'type', 'value', 'temporal_function', 'anchor_time_id', 'mod', 'quant', 'freq', 'begin_point', 'end_point', 'part_of_interval'), spans=SL[EnvelopingSpan(['neljapäeval', 'kell', '16.00'], [{'tid': 't1', 'type': 'TIME', 'value': '2020-10-08T16:00', 'temporal_function': True, 'anchor_time_id': None, 'mod': None, 'quant': None, 'freq': None, 'begin_point': None, 'end_point': None, 'part_of_interval': None}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzHvzHckAnxH",
        "outputId": "c6652e2a-7877-4ae2-ae8f-a39349f77989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "# Soovi korral võime määratleda teksti loomise aja\n",
        "text3 = Text('EKA sisearhitektuuri osakond ja RMK \\\n",
        "avavad neljapäeval kell 16.00 \\\n",
        "RMK Tallinna kontoris (Toompuiestee 24) näituse').tag_layer()\n",
        "text3.meta['document_creation_time'] = '2019-10-27'\n",
        "tagger.tag(text3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td><div align = \"left\">EKA sisearhitektuuri osakond ja RMK avavad neljapäeval kell 16.00 RMK Tallinna kontoris (Toompuiestee 24) näituse</div></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<h4>Metadata</h4>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>document_creation_time</td>\n",
              "      <td>2019-10-27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>sentences</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>tokens</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>compound_tokens</td>\n",
              "      <td>type, normalized</td>\n",
              "      <td>None</td>\n",
              "      <td>tokens</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>words</td>\n",
              "      <td>normalized_form</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
              "      <td>words</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>timexes</td>\n",
              "      <td>tid, type, value, temporal_function, anchor_time_id, mod, quant, freq, begin_point, end_point, part_of_interval</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Text(text='EKA sisearhitektuuri osakond ja RMK avavad neljapäeval kell 16.00 RMK Tallinna kontoris (Toompuiestee 24) näituse')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmEvHZW8AnxV",
        "outputId": "b23cb399-33ee-4bed-e661-8f16813d4cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "text3.timexes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>timexes</td>\n",
              "      <td>tid, type, value, temporal_function, anchor_time_id, mod, quant, freq, begin_point, end_point, part_of_interval</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>tid</th>\n",
              "      <th>type</th>\n",
              "      <th>value</th>\n",
              "      <th>temporal_function</th>\n",
              "      <th>anchor_time_id</th>\n",
              "      <th>mod</th>\n",
              "      <th>quant</th>\n",
              "      <th>freq</th>\n",
              "      <th>begin_point</th>\n",
              "      <th>end_point</th>\n",
              "      <th>part_of_interval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['neljapäeval', 'kell', '16.00']</td>\n",
              "      <td>t1</td>\n",
              "      <td>TIME</td>\n",
              "      <td>2019-10-31T16:00</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='timexes', attributes=('tid', 'type', 'value', 'temporal_function', 'anchor_time_id', 'mod', 'quant', 'freq', 'begin_point', 'end_point', 'part_of_interval'), spans=SL[EnvelopingSpan(['neljapäeval', 'kell', '16.00'], [{'tid': 't1', 'type': 'TIME', 'value': '2019-10-31T16:00', 'temporal_function': True, 'anchor_time_id': None, 'mod': None, 'quant': None, 'freq': None, 'begin_point': None, 'end_point': None, 'part_of_interval': None}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVHvOOCzAnxj"
      },
      "source": [
        "### Aadresside tuvastamine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPHjT8WnAnxl"
      },
      "source": [
        "# Toimub kahes etapis\n",
        "from estnltk.taggers import AddressPartTagger, AddressGrammarTagger\n",
        "address_token_tagger = AddressPartTagger(output_layer='address_tokens')\n",
        "address_tagger = AddressGrammarTagger(output_layer='addresses', \n",
        "                                      input_layer='address_tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crTcf82QAnxv"
      },
      "source": [
        "text = Text(\"Ootame teid 2. novembril külla \\\n",
        "aadressil Aia 6, Tartu.\").tag_layer(['words'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHmFcjYdAnx4",
        "outputId": "f178209d-8749-453c-d564-5e6b2cf2504f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "# Esiteks märgime peale võimalikud aadresside komponendid\n",
        "address_token_tagger.tag(text)[\"address_tokens\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>address_tokens</td>\n",
              "      <td>grammar_symbol, type</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>grammar_symbol</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>Ootame teid</td>\n",
              "      <td>RANDOM_TEXT</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>MAJA</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>novembril külla aadressil</td>\n",
              "      <td>RANDOM_TEXT</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Aia</td>\n",
              "      <td>TÄNAV</td>\n",
              "      <td>tänav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>MAJA</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Tartu</td>\n",
              "      <td>ASULA</td>\n",
              "      <td>asula</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td></td>\n",
              "      <td>TÄNAV</td>\n",
              "      <td>tänav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='address_tokens', attributes=('grammar_symbol', 'type'), spans=SL[Span('Ootame teid', [{'grammar_symbol': 'RANDOM_TEXT', 'type': None}]),\n",
              "Span('2', [{'grammar_symbol': 'MAJA', 'type': None}]),\n",
              "Span('novembril külla aadressil', [{'grammar_symbol': 'RANDOM_TEXT', 'type': None}]),\n",
              "Span('Aia', [{'grammar_symbol': 'TÄNAV', 'type': 'tänav'}]),\n",
              "Span('6', [{'grammar_symbol': 'MAJA', 'type': None}]),\n",
              "Span('Tartu', [{'grammar_symbol': 'ASULA', 'type': 'asula'}, {'grammar_symbol': 'TÄNAV', 'type': 'tänav'}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9O2bLdXAnyB",
        "outputId": "05956431-6d67-480c-d359-d98b92d60f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "# Teiseks leiame aadressid sealt, kus sobivad komponendid järjest esinevad\n",
        "address_tagger.tag(text)['addresses']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>addresses</td>\n",
              "      <td>grammar_symbol, TÄNAV, MAJA, ASULA, MAAKOND, INDEKS</td>\n",
              "      <td>None</td>\n",
              "      <td>address_tokens</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>grammar_symbol</th>\n",
              "      <th>TÄNAV</th>\n",
              "      <th>MAJA</th>\n",
              "      <th>ASULA</th>\n",
              "      <th>MAAKOND</th>\n",
              "      <th>INDEKS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['Aia', '6', 'Tartu']</td>\n",
              "      <td>ADDRESS</td>\n",
              "      <td>Aia</td>\n",
              "      <td>6</td>\n",
              "      <td>Tartu</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='addresses', attributes=('grammar_symbol', 'TÄNAV', 'MAJA', 'ASULA', 'MAAKOND', 'INDEKS'), spans=SL[EnvelopingSpan(['Aia', '6', 'Tartu'], [{'grammar_symbol': 'ADDRESS', 'TÄNAV': 'Aia', 'MAJA': '6', 'ASULA': 'Tartu', 'MAAKOND': '', 'INDEKS': ''}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si76jZlJAnyK"
      },
      "source": [
        "### Verbiahelate tuvastamine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAi5b-rLAnyM"
      },
      "source": [
        "from estnltk.taggers import VerbChainDetector\n",
        "vc_detector = VerbChainDetector()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-sNDfaFAnyY",
        "outputId": "1dec24eb-e9e1-4b96-f77b-713a2cfec10c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "from estnltk import Text\n",
        "# Loome teksti\n",
        "text = Text('Kas Juku alustas kodutööga? Minuteada ei alustanud.')\n",
        "# Lisame verbiahelate tuvastamiseks vajalikud sisendkihid\n",
        "text.tag_layer(['words', 'sentences', 'morph_analysis', 'clauses'])\n",
        "\n",
        "# Tuvastame verbiahelad\n",
        "vc_detector.tag( text )\n",
        "\n",
        "# Väljastame verbiahelad (vastavad tekstid)\n",
        "text.verb_chains"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>verb_chains</td>\n",
              "      <td>pattern, roots, word_ids, mood, polarity, tense, voice, remaining_verbs</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>pattern</th>\n",
              "      <th>roots</th>\n",
              "      <th>word_ids</th>\n",
              "      <th>mood</th>\n",
              "      <th>polarity</th>\n",
              "      <th>tense</th>\n",
              "      <th>voice</th>\n",
              "      <th>remaining_verbs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['alustas']</td>\n",
              "      <td>['verb']</td>\n",
              "      <td>['alusta']</td>\n",
              "      <td>[2]</td>\n",
              "      <td>indic</td>\n",
              "      <td>POS</td>\n",
              "      <td>imperfect</td>\n",
              "      <td>personal</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['ei', 'alustanud']</td>\n",
              "      <td>['ei', 'verb']</td>\n",
              "      <td>['ei', 'alusta']</td>\n",
              "      <td>[6, 7]</td>\n",
              "      <td>indic</td>\n",
              "      <td>NEG</td>\n",
              "      <td>imperfect</td>\n",
              "      <td>personal</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='verb_chains', attributes=('pattern', 'roots', 'word_ids', 'mood', 'polarity', 'tense', 'voice', 'remaining_verbs'), spans=SL[EnvelopingSpan(['alustas'], [{'pattern': ['verb'], 'roots': ['alusta'], 'word_ids': [2], 'mood': 'indic', 'polarity': 'POS', 'tense': 'imperfect', 'voice': 'personal', 'remaining_verbs': False}]),\n",
              "EnvelopingSpan(['ei', 'alustanud'], [{'pattern': ['ei', 'verb'], 'roots': ['ei', 'alusta'], 'word_ids': [6, 7], 'mood': 'indic', 'polarity': 'NEG', 'tense': 'imperfect', 'voice': 'personal', 'remaining_verbs': False}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUSljOzkAnyh"
      },
      "source": [
        "## Oma märgendajate kirjutamine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21y6FE5UAnyj"
      },
      "source": [
        "### PhraseTagger\n",
        "#### võimaldab märgendada kihis järjest esinevaid elemente mingi atribuudi alusel\n",
        "\n",
        "Proovime kirjutada taggerit, mis märgendaks lihtsaid nimisõnafraase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SmThjYxAnyk"
      },
      "source": [
        "from estnltk.taggers import PhraseTagger\n",
        "\n",
        "# Kasutame fraaside esmaseks määratlemiseks sõnaliike\n",
        "phrase_list = [\n",
        "               { '_phrase_': ('A', 'S')},\n",
        "               { '_phrase_':  ('C', 'S')},\n",
        "               { '_phrase_':  ('U', 'S')}\n",
        "              ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAOHFxpIAnyt"
      },
      "source": [
        "# Defineerime taggeri, mis phrase_list muutujas olevaid fraasitüüpe märgendaks\n",
        "phrase_tagger = PhraseTagger(output_layer='noun_phrases',\n",
        "                      input_layer='morph_analysis',\n",
        "                      input_attribute='partofspeech',\n",
        "                      vocabulary=phrase_list,\n",
        "                      key='_phrase_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT3gUIL9Any1",
        "outputId": "1670812a-5fcb-4f85-9a44-6b024a9b0081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "# Rakendame kirjutatud taggerit morfanalüüsitud tekstile\n",
        "t = Text('Viimasedki pardid lendasid soojemale maale, \\\n",
        "kui jää läks liiga paksuks jõest toidu hankimiseks.').tag_layer()\n",
        "phrase_tagger.tag(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td><div align = \"left\">Viimasedki pardid lendasid soojemale maale, kui jää läks liiga paksuks jõest toidu hankimiseks.</div></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>sentences</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>tokens</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>compound_tokens</td>\n",
              "      <td>type, normalized</td>\n",
              "      <td>None</td>\n",
              "      <td>tokens</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>words</td>\n",
              "      <td>normalized_form</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
              "      <td>words</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>noun_phrases</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Text(text='Viimasedki pardid lendasid soojemale maale, kui jää läks liiga paksuks jõest toidu hankimiseks.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR74zs9oAnzB",
        "outputId": "35613ad6-5a53-4742-ee65-6f70dd391eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Leiame nimisõnafraasid\n",
        "# Puuduvad algvormid\n",
        "# Paremate tulemuste jaoks peaks arvesse võtma rohkem kui sõnaliike\n",
        "t.noun_phrases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>noun_phrases</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['Viimasedki', 'pardid']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['soojemale', 'maale']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['paksuks', 'jõest']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='noun_phrases', attributes=(), spans=SL[EnvelopingSpan(['Viimasedki', 'pardid'], [{}]),\n",
              "EnvelopingSpan(['soojemale', 'maale'], [{}]),\n",
              "EnvelopingSpan(['paksuks', 'jõest'], [{}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HXPC11kAnzL"
      },
      "source": [
        "# Dekoraator võimaldab lisada oma uuele kihile atribuute - lisame lemmad\n",
        "def decorator(span, annotation):\n",
        "    annotation['lemmas'] = ' '.join([l[0] for l in span.lemma])\n",
        "    return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnYbBZnEAnzW"
      },
      "source": [
        "# Uus phrase_tagger, mis paneb uude kihti ka fraasid algvormis\n",
        "phrase_tagger2 = PhraseTagger(output_layer='noun_phrases2',\n",
        "                      input_layer='morph_analysis',\n",
        "                      input_attribute='partofspeech',\n",
        "                      vocabulary=phrase_list,\n",
        "                      key='_phrase_',\n",
        "                      output_attributes = ['lemmas'],\n",
        "                      decorator = decorator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdYeo-NRAnze",
        "outputId": "7b3b4698-420b-4fc1-b00e-0c6db0bce8b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Olemas ilusad algvormis fraasid\n",
        "# Vaja oleks ka sõna vormiinfot arvestada\n",
        "phrase_tagger2.tag(t)\n",
        "t.noun_phrases2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>noun_phrases2</td>\n",
              "      <td>lemmas</td>\n",
              "      <td>None</td>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>lemmas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['Viimasedki', 'pardid']</td>\n",
              "      <td>viimane part</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['soojemale', 'maale']</td>\n",
              "      <td>soojem maa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['paksuks', 'jõest']</td>\n",
              "      <td>paks jõgi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='noun_phrases2', attributes=('lemmas',), spans=SL[EnvelopingSpan(['Viimasedki', 'pardid'], [{'lemmas': 'viimane part'}]),\n",
              "EnvelopingSpan(['soojemale', 'maale'], [{'lemmas': 'soojem maa'}]),\n",
              "EnvelopingSpan(['paksuks', 'jõest'], [{'lemmas': 'paks jõgi'}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1nB67zmAnzq"
      },
      "source": [
        "# Täiendame dekoraatorit - arvestame ka vormide ühilduvust\n",
        "def decorator2(span, annotation):\n",
        "    annotation['lemmas'] = ' '.join([l[0] for l in span.lemma])\n",
        "    \n",
        "    ninataga_sg = ['sg ter', 'sg ab', 'sg kom', 'sg es']\n",
        "    ninataga_pl = ['pl ter', 'pl ab', 'pl kom', 'pl es']\n",
        "    # Omadussõna ja nimisõna samas vormis -> OK\n",
        "    if span[0].form == span[1].form:\n",
        "        return True\n",
        "    # Omadussõna ainsuse omastavas ja nimisõna 4 viimases käändes ainsuses -> OK\n",
        "    elif span[0].form[0] == 'sg g' and span[1].form[0] in ninataga_sg:\n",
        "        return True\n",
        "    # Omadussõna mitm omastavas ja nimisõna 4 viimases käändes mitm -> OK\n",
        "    elif span[0].form[0] == 'pl g' and span[1].form[0] in ninataga_pl:\n",
        "        return True\n",
        "    # Kõik muud juhud -> ei sobi fraas\n",
        "    else: \n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF2m7d-hAnz1"
      },
      "source": [
        "phrase_tagger3 = PhraseTagger(output_layer='noun_phrases3',\n",
        "                      input_layer='morph_analysis',\n",
        "                      input_attribute='partofspeech',\n",
        "                      vocabulary=phrase_list,\n",
        "                      key='_phrase_',\n",
        "                      output_attributes = ['lemmas'],\n",
        "                      decorator = decorator2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ifMjP1BAn0G",
        "outputId": "d5160b6d-779b-47f8-9969-dcd0366d3ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "# Märgendame kolmanda nimisõnafraaside kihi\n",
        "phrase_tagger3.tag(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td><div align = \"left\">Viimasedki pardid lendasid soojemale maale, kui jää läks liiga paksuks jõest toidu hankimiseks.</div></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>sentences</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>tokens</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>compound_tokens</td>\n",
              "      <td>type, normalized</td>\n",
              "      <td>None</td>\n",
              "      <td>tokens</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>words</td>\n",
              "      <td>normalized_form</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
              "      <td>words</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>noun_phrases</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>noun_phrases2</td>\n",
              "      <td>lemmas</td>\n",
              "      <td>None</td>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>noun_phrases3</td>\n",
              "      <td>lemmas</td>\n",
              "      <td>None</td>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Text(text='Viimasedki pardid lendasid soojemale maale, kui jää läks liiga paksuks jõest toidu hankimiseks.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjRoPESIAn0S",
        "outputId": "ed2c29b9-9b71-4f32-e9d5-e8f731c870f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# Tulemused vastavad ootustele\n",
        "t.noun_phrases3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>noun_phrases3</td>\n",
              "      <td>lemmas</td>\n",
              "      <td>None</td>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>lemmas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['Viimasedki', 'pardid']</td>\n",
              "      <td>viimane part</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['soojemale', 'maale']</td>\n",
              "      <td>soojem maa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='noun_phrases3', attributes=('lemmas',), spans=SL[EnvelopingSpan(['Viimasedki', 'pardid'], [{'lemmas': 'viimane part'}]),\n",
              "EnvelopingSpan(['soojemale', 'maale'], [{'lemmas': 'soojem maa'}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8ScGE6rAn0d",
        "outputId": "e854e893-69eb-4999-a007-6dbfffbece6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Fraase on lihtne stringidena kätte saada\n",
        "for i in t.noun_phrases3:\n",
        "    print(i.lemmas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "viimane part\n",
            "soojem maa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYugpLnIAn0q"
      },
      "source": [
        "# Näide: leiame, millised nimisõnafraasid esinevad kõige sagedamini eesti vanasõnades"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcUtQR_aFsXL",
        "outputId": "cd755d4c-1923-4ac5-ea18-09943f770947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "!wget https://owncloud.ut.ee/owncloud/index.php/s/MLq2GQ9GHHmQpnJ/download -O proverbs.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-04 19:31:38--  https://owncloud.ut.ee/owncloud/index.php/s/MLq2GQ9GHHmQpnJ/download\n",
            "Resolving owncloud.ut.ee (owncloud.ut.ee)... 193.40.5.90\n",
            "Connecting to owncloud.ut.ee (owncloud.ut.ee)|193.40.5.90|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45408 (44K) [text/plain]\n",
            "Saving to: ‘proverbs.txt’\n",
            "\n",
            "proverbs.txt        100%[===================>]  44.34K   151KB/s    in 0.3s    \n",
            "\n",
            "2020-10-04 19:31:40 (151 KB/s) - ‘proverbs.txt’ saved [45408/45408]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azD_EK17An03"
      },
      "source": [
        "with open(\"proverbs.txt\", \"r\", encoding = 'utf8') as fin:\n",
        "    # Failis on iga vanasõna eraldi real - saame listi vanasõnadest\n",
        "    proverbs = fin.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GXrOmSaGB1c",
        "outputId": "df203324-308d-4ad8-db29-22dc69e46a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "proverbs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ega mets tühi ole.\\n',\n",
              " 'Mets vaese mehe kasukas.\\n',\n",
              " 'Karu elab vanast rasvast.\\n',\n",
              " 'Madisepäevast hakkab uus lumi vana sööma.\\n',\n",
              " 'Kui kuldnokad tulevad vanakuu põhjas välja, siis teise kuu vanas põhjas läheb talve ära.\\n',\n",
              " 'Näed valget liblikat kevadel esiti, siis on vaenuline elu; näed kirju ― kirju elu; näed musta ― murelik elu; näed kollast ― kõige parem elu.\\n',\n",
              " 'Mis noor mees teeb, see vana mees rikub.\\n',\n",
              " 'Mihklipäev arvati vanapagana heinategemise päev olevat.\\n',\n",
              " 'Kui talve ajal puud alati lund täis on, siis ütleb vanarahvas: puud on vaevas ja tuleb vaene aeg.\\n',\n",
              " 'Noorkuu vihm kosutab rohkem kui vanakuu oma.\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVgR3YpsAn1K",
        "outputId": "353ddf64-3199-4396-942f-603bb916bb82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Loendur fraaside kokkulugemiseks\n",
        "noun_phrases_counts = Counter()\n",
        "\n",
        "for text in tqdm(proverbs): # vaatame vanasõnade listi järjest läbi\n",
        "    t = Text(text).tag_layer() # teeme vanasõna Text objektiks ja analüüsime\n",
        "    phrase_tagger3.tag(t) # märgime peale nimisõnafraasid oma parima taggeriga\n",
        "    if len(t.noun_phrases3) > 0: \n",
        "        for p in t.noun_phrases3: # suurendame loendurit vastava fraasi kohal\n",
        "            noun_phrases_counts[p.lemmas] += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:05<00:00, 175.58it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ug3vI3An1i",
        "outputId": "76f1abe6-4bfe-45e4-9a50-13e0e6a13075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "# Saamegi kätte sagedasemad nimisõnafraasid\n",
        "noun_phrases_counts.most_common(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tühi kõht', 11),\n",
              " ('vana koer', 11),\n",
              " ('vaene mees', 7),\n",
              " ('vana mees', 5),\n",
              " ('vaene inimene', 5)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlP4ayVgAn1s"
      },
      "source": [
        "### Nimeüksuste tuvastamine (NER - Named Entity Recognition)\n",
        "\n",
        "EstNLTK sisaldab automaatset nimeüksuste tuvastajat. \n",
        "\n",
        "Programm võimaldab tuvastada 3 liiki nimeüksuseid:\n",
        "\n",
        "* isikunimesid ( lühend: PER );\n",
        "\n",
        "* asukohanimesid ( lühend: LOC );\n",
        "\n",
        "* organisatsiooninimesid ( lühend: ORG )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuC_BN6uAn1u",
        "outputId": "ed04e64a-d9ce-4426-a2fa-bf924c419617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from estnltk.taggers import NerTagger\n",
        "ner_tagger = NerTagger()\n",
        "\n",
        "# Milliseid kihte ner_tagger vajab?\n",
        "ner_tagger.input_layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('morph_analysis',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLRT7N3nAn14",
        "outputId": "f0cab1f6-aedc-4cbd-986d-3b579104f9ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "from estnltk import Text\n",
        "# tekitame näidisteksti\n",
        "t = Text(''' Eesti President on Kersti Kaljulaid. Eesti Energia on \\ \n",
        "Eesti riigile kuuluv rahvusvaheline energiaettevõte. ''')\n",
        "\n",
        "# lisame tekstile vajamineva 'morph_analysis' kihi\n",
        "t.tag_layer('morph_analysis')\n",
        "\n",
        "# lisame nimeüksuste märgenduse\n",
        "ner_tagger.tag(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td><div align = \"left\"> Eesti President on Kersti Kaljulaid. Eesti Energia on \\ </br>Eesti riigile kuuluv rahvusvaheline energiaettevõte. </div></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>sentences</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>tokens</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>compound_tokens</td>\n",
              "      <td>type, normalized</td>\n",
              "      <td>None</td>\n",
              "      <td>tokens</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>words</td>\n",
              "      <td>normalized_form</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
              "      <td>words</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>ner</td>\n",
              "      <td>nertag</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Text(text=' Eesti President on Kersti Kaljulaid. Eesti Energia on \\\\ \\nEesti riigile kuuluv rahvusvaheline energiaettevõte. ')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KImnJ0NAn2G",
        "outputId": "b82d5320-f670-43ce-f6a8-453f22657aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# väljastab tuvastatud nimeüksused\n",
        "t.ner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>ner</td>\n",
              "      <td>nertag</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>nertag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['Eesti']</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['Kersti', 'Kaljulaid']</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['Eesti', 'Energia']</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['Eesti', 'riigile']</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='ner', attributes=('nertag',), spans=SL[EnvelopingSpan(['Eesti'], [{'nertag': 'LOC'}]),\n",
              "EnvelopingSpan(['Kersti', 'Kaljulaid'], [{'nertag': 'PER'}]),\n",
              "EnvelopingSpan(['Eesti', 'Energia'], [{'nertag': 'ORG'}]),\n",
              "EnvelopingSpan(['Eesti', 'riigile'], [{'nertag': 'LOC'}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlX1OvSYAn2Q"
      },
      "source": [
        "### Oma nimeüksuste lisamine\n",
        "\n",
        "1) Leiame võimalikult suure hulga näiteid vastavast nimeüksusest\n",
        " \n",
        "2) Märgendame ümber olemasoleva korpuse - anname seal esinevatele vastavatele nimeüksustele soovitud märgendid\n",
        "\n",
        "3) Treenime nimeüksuste tuvastaja ümbermärgendatud korpuse peal\n",
        "\n",
        "4) Märgendame oma nimeüksusi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uiVqZIdAn2S"
      },
      "source": [
        "### Oma nimeüksuste lisamine - kuidas luua leksikone?\n",
        "1) Spetsiifilised allikad - nt eesnimede loetelu, ametite loetelu\n",
        "\n",
        "2) Wordnet\n",
        "\n",
        "3) Suurel korpusel treenitud sõnavektorid - nt word2vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I33g4stLAn2U"
      },
      "source": [
        "## Baassõnavara kaardistamine - Wordnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1w-LzYzAn2W",
        "outputId": "5d6b028e-f846-4be2-8afb-976b9956a307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Wordneti kasutamiseks tuleb importida vastav moodul ja luua Wordneti objekt:\n",
        "from estnltk.wordnet import Wordnet\n",
        "\n",
        "wn = Wordnet()\n",
        "toit = wn['toit']\n",
        "toit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Synset('toit.n.01')\", \"Synset('toit.n.02')\", \"Synset('toit.n.03')\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9JucNuwAn2s",
        "outputId": "b128969d-0d6f-4ca0-bc58-e54f3485943f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "toit[0].definition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ettevalmistatud (keedetud, küpsetatud, grillitud, lõigutud vm) toiduained lauale panemiseks ja söömiseks; valmisained, mida süüakse kõhu täitmiseks'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxH8ciraAn22",
        "outputId": "566334a3-cbd7-45b3-dbfe-6f3abbbe0414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "toit[2].definition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'aine, mida süüakse või omandatakse muul moel kehasse, et hoida alal elu, saada energiat jne'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltMsJpi3An3A"
      },
      "source": [
        "toidud = toit[2].closure('hyponym')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV0uZRhqAn3K",
        "outputId": "5b4e0bf5-bc94-4776-99b5-e1caab215e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "toidud[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Synset('sööt.n.01')\",\n",
              " \"Synset('söödavili.n.01')\",\n",
              " \"Synset('loomne sööt.n.01')\",\n",
              " \"Synset('kalajahu.n.01')\",\n",
              " \"Synset('loomajahu.n.01')\",\n",
              " \"Synset('verejahu.n.01')\",\n",
              " \"Synset('rohukuivis.n.01')\",\n",
              " \"Synset('mahlakas sööt.n.01')\",\n",
              " \"Synset('silo.n.01')\",\n",
              " \"Synset('märgsilo.n.01')\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPgLLzzGAn3Z",
        "outputId": "3a3f18cb-de71-4baf-e7ad-c57d3e0fb13e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(toidud)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy1WIaQHAn3f",
        "outputId": "a3bbbc5f-9a27-4baa-a934-58c01a7c7f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "toidud[1000].lemmas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kohupiimakotlett', 'sõrnik']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7ihKQkYHORv"
      },
      "source": [
        "# Baassõnavara kaardistamine - Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JloyxiVqAn3o",
        "outputId": "38e367e8-a63c-42a6-aa39-a97e2d893655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import csv\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from estnltk import Text\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:textcleaner.py:37: 'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcKgsfp9HV7y",
        "outputId": "5cfbcc8d-b4ff-4e32-ab6f-5b485b2a4909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!wget http://193.40.33.66/pretrained/cbow_100_5_10_20.zip -O model.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-04 19:36:45--  http://193.40.33.66/pretrained/cbow_100_5_10_20.zip\n",
            "Connecting to 193.40.33.66:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 396307401 (378M) [application/zip]\n",
            "Saving to: ‘model.zip’\n",
            "\n",
            "model.zip           100%[===================>] 377.95M  8.26MB/s    in 47s     \n",
            "\n",
            "2020-10-04 19:37:34 (8.01 MB/s) - ‘model.zip’ saved [396307401/396307401]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vjI7EE5H0H3",
        "outputId": "b3750f88-3918-4ffb-8c27-d5d06950c2ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "from zipfile import ZipFile \n",
        "# avame kokkupakitud faili\n",
        "with ZipFile('model.zip', 'r') as zip_file: \n",
        "    #väljastame arhiivi sisu (milliseid faile see sisaldab?)\n",
        "    zip_file.printdir() \n",
        "    # pakime faili lahti (jooksvasse kausta)\n",
        "    zip_file.extractall() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Name                                             Modified             Size\n",
            "cbow_100_5_10_20/                              2018-11-28 21:44:12            0\n",
            "cbow_100_5_10_20/ettenten.txt.sense_vectors    2018-11-28 14:38:12    654513324\n",
            "cbow_100_5_10_20/ettenten.txt.sense_vectors.inventory.csv 2018-11-28 14:38:14     16367362\n",
            "cbow_100_5_10_20/ettenten.txt.word_vectors     2018-11-24 02:55:00    454415902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3UIrYhPAn30",
        "outputId": "0ffb6910-28a6-488d-82cd-a9f534cf1463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# model from here http://193.40.33.66/pretrained/cbow_100_5_10_20.zip\n",
        "# documentation here https://github.com/eleriaedmaa/embeddings\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format(\"cbow_100_5_10_20/ettenten.txt.word_vectors\", binary=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:utils_any2vec.py:170: loading projection weights from cbow_100_5_10_20/ettenten.txt.word_vectors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:utils_any2vec.py:232: loaded (470688, 100) matrix from cbow_100_5_10_20/ettenten.txt.word_vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgnISYuZAn3-",
        "outputId": "0b02e1e4-26d6-4f8b-e8dc-8fdb9f0d6771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "most_similar = model.most_similar(positive=['kurk', 'porgand'], topn=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:keyedvectors.py:1360: precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Nsni5moCAn4M",
        "outputId": "700262e6-5242-4162-d2e9-8f9789ed2a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "most_similar[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tomat', 0.883423924446106),\n",
              " ('õun', 0.8118515014648438),\n",
              " ('arbuus', 0.8091526627540588),\n",
              " ('kartul', 0.8073391318321228),\n",
              " ('sibul', 0.8037582635879517),\n",
              " ('maasikas', 0.8013646602630615),\n",
              " ('küüslauk', 0.7977540493011475),\n",
              " ('hernes', 0.7962827682495117),\n",
              " ('värske_kurk', 0.7874271869659424),\n",
              " ('kapsas', 0.7873393297195435)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm2ezYLuAn4X",
        "outputId": "b65e664d-e559-4d0d-adcb-82ab757ea24b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "most_similar = model.most_similar(positive=['müüja', 'dirigent', 'ehitaja'], topn=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oKRSPZE0An4e",
        "outputId": "5cca6b63-03d1-4dad-eb44-90e2e1bc9e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "most_similar[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('töömees', 0.7112044095993042),\n",
              " ('ehitusfirma', 0.6680212616920471),\n",
              " ('ehitusettevõtja', 0.6548689603805542),\n",
              " ('klienditeenindaja', 0.6475248336791992),\n",
              " ('peatöövõtja', 0.6439967155456543),\n",
              " ('ehitusmees', 0.6306072473526001),\n",
              " ('töödejuhataja', 0.6255624890327454),\n",
              " ('alltöövõtja', 0.6250218749046326),\n",
              " ('maaler', 0.622079610824585),\n",
              " ('haljastusfirma', 0.6190921068191528)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY9PZBkLAn4o"
      },
      "source": [
        "### Oma nimeüksuste lisamine\n",
        "\n",
        "1) Leiame võimalikult suure hulga näiteid vastavast nimeüksusest\n",
        " \n",
        "2) Märgendame ümber olemasoleva korpuse - anname seal esinevatele vastavatele nimeüksustele soovitud märgendid\n",
        "\n",
        "3) Treenime nimeüksuste tuvastaja ümbermärgendatud korpuse peal\n",
        "\n",
        "4) Märgendame oma nimeüksusi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxqvdZ11An4q"
      },
      "source": [
        "from estnltk.taggers.estner.ner_trainer import NerTrainer\n",
        "from estnltk.taggers.estner.refac.ner import ModelStorageUtil\n",
        "from estnltk.core import DEFAULT_PY3_NER_MODEL_DIR\n",
        "\n",
        "model_dir=DEFAULT_PY3_NER_MODEL_DIR\n",
        "modelUtil = ModelStorageUtil(model_dir)\n",
        "nersettings = modelUtil.load_settings()\n",
        "trainer = NerTrainer(nersettings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puDZjrsQAn4y"
      },
      "source": [
        "# See on meie treeningkorpus - peab olema morfoloogiliselt märgendatud\n",
        "text = Text('Eesti president käis Euroopas.').tag_layer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu7NDqi2An45",
        "outputId": "b004a3b3-70e0-4377-b51b-5b08ec316711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "text.words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>words</td>\n",
              "      <td>normalized_form</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>normalized_form</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>Eesti</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>president</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>käis</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Euroopas</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>.</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Eesti', [{'normalized_form': None}]),\n",
              "Span('president', [{'normalized_form': None}]),\n",
              "Span('käis', [{'normalized_form': None}]),\n",
              "Span('Euroopas', [{'normalized_form': None}]),\n",
              "Span('.', [{'normalized_form': None}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWkhDpyUAn5B"
      },
      "source": [
        "# Igale sõnale peab vastama märgend; iga lause kohta üks list\n",
        "labels = ['B-LOC','B-VOC','O','B-LOC', 'O']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ3NAY0hAn5I",
        "outputId": "c7d85ff8-264e-466a-a3c4-a368d30799dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Treenime, kasutades treeningkorpust ja märgendeid;\n",
        "# salvestame tulemuse kausta 'test'\n",
        "trainer.train(text, [labels], 'test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 0\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 117\n",
            "Seconds required: 0.003\n",
            "\n",
            "Stochastic Gradient Descent (SGD)\n",
            "c2: 0.001000\n",
            "max_iterations: 1000\n",
            "period: 10\n",
            "delta: 0.000001\n",
            "\n",
            "Calibrating the learning rate (eta)\n",
            "calibration.eta: 0.100000\n",
            "calibration.rate: 2.000000\n",
            "calibration.samples: 1\n",
            "calibration.candidates: 10\n",
            "calibration.max_trials: 20\n",
            "Initial loss: 5.493061\n",
            "Trial #1 (eta = 0.100000): 5.493583 (worse)\n",
            "Trial #2 (eta = 0.050000): 5.493192 (worse)\n",
            "Trial #3 (eta = 0.025000): 5.493094 (worse)\n",
            "Trial #4 (eta = 0.012500): 5.493070 (worse)\n",
            "Trial #5 (eta = 0.006250): 5.493063 (worse)\n",
            "Trial #6 (eta = 0.003125): 5.493062 (worse)\n",
            "Trial #7 (eta = 0.001563): 5.493062 (worse)\n",
            "Trial #8 (eta = 0.000781): 5.493061 (worse)\n",
            "Trial #9 (eta = 0.000391): 5.493061 (worse)\n",
            "Trial #10 (eta = 0.000195): 5.493061 (worse)\n",
            "Trial #11 (eta = 0.000098): 5.493061 (worse)\n",
            "Trial #12 (eta = 0.000049): 5.493061 (worse)\n",
            "Trial #13 (eta = 0.000024): 5.493061 (worse)\n",
            "Trial #14 (eta = 0.000012): 5.493061 (worse)\n",
            "Trial #15 (eta = 0.000006): 5.493061 (worse)\n",
            "Trial #16 (eta = 0.000003): 5.493061 (worse)\n",
            "Trial #17 (eta = 0.000002): 5.493061 (worse)\n",
            "Trial #18 (eta = 0.000001): 5.493061 (worse)\n",
            "Trial #19 (eta = 0.000000): 5.493061 (worse)\n",
            "Best learning rate (eta): 0.000000\n",
            "Seconds required: 0.000\n",
            "\n",
            "***** Epoch #1 *****\n",
            "Loss: 5.493061\n",
            "Feature L2-norm: 0.000003\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 1\n",
            "Seconds required for this iteration: 0.002\n",
            "\n",
            "***** Epoch #2 *****\n",
            "Loss: 5.493042\n",
            "Feature L2-norm: 0.000006\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 2\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #3 *****\n",
            "Loss: 5.493022\n",
            "Feature L2-norm: 0.000008\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 3\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #4 *****\n",
            "Loss: 5.493002\n",
            "Feature L2-norm: 0.000011\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 4\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #5 *****\n",
            "Loss: 5.492982\n",
            "Feature L2-norm: 0.000014\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 5\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #6 *****\n",
            "Loss: 5.492962\n",
            "Feature L2-norm: 0.000017\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 6\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #7 *****\n",
            "Loss: 5.492942\n",
            "Feature L2-norm: 0.000019\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 7\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #8 *****\n",
            "Loss: 5.492922\n",
            "Feature L2-norm: 0.000022\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 8\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #9 *****\n",
            "Loss: 5.492902\n",
            "Feature L2-norm: 0.000025\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 9\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #10 *****\n",
            "Loss: 5.492882\n",
            "Feature L2-norm: 0.000028\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 10\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #11 *****\n",
            "Loss: 5.492863\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000030\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 11\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #12 *****\n",
            "Loss: 5.492843\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000033\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 12\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #13 *****\n",
            "Loss: 5.492823\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000036\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 13\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #14 *****\n",
            "Loss: 5.492803\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000039\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 14\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #15 *****\n",
            "Loss: 5.492783\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000041\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 15\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #16 *****\n",
            "Loss: 5.492763\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000044\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 16\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #17 *****\n",
            "Loss: 5.492743\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000047\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 17\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #18 *****\n",
            "Loss: 5.492723\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000050\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 18\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #19 *****\n",
            "Loss: 5.492704\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000052\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 19\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #20 *****\n",
            "Loss: 5.492684\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000055\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 20\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #21 *****\n",
            "Loss: 5.492664\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000058\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 21\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #22 *****\n",
            "Loss: 5.492644\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000061\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 22\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #23 *****\n",
            "Loss: 5.492624\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000063\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 23\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #24 *****\n",
            "Loss: 5.492604\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000066\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 24\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #25 *****\n",
            "Loss: 5.492584\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000069\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 25\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #26 *****\n",
            "Loss: 5.492564\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000072\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 26\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #27 *****\n",
            "Loss: 5.492544\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000074\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 27\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #28 *****\n",
            "Loss: 5.492525\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000077\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 28\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #29 *****\n",
            "Loss: 5.492505\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000080\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 29\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #30 *****\n",
            "Loss: 5.492485\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000083\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 30\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #31 *****\n",
            "Loss: 5.492465\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000085\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 31\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #32 *****\n",
            "Loss: 5.492445\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000088\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 32\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #33 *****\n",
            "Loss: 5.492425\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000091\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 33\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #34 *****\n",
            "Loss: 5.492405\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000094\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 34\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #35 *****\n",
            "Loss: 5.492385\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000096\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 35\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #36 *****\n",
            "Loss: 5.492366\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000099\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 36\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #37 *****\n",
            "Loss: 5.492346\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000102\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 37\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #38 *****\n",
            "Loss: 5.492326\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000105\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 38\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #39 *****\n",
            "Loss: 5.492306\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000107\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 39\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #40 *****\n",
            "Loss: 5.492286\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000110\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 40\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #41 *****\n",
            "Loss: 5.492266\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000113\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 41\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #42 *****\n",
            "Loss: 5.492246\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000116\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 42\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #43 *****\n",
            "Loss: 5.492226\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000118\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 43\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #44 *****\n",
            "Loss: 5.492207\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000121\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 44\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #45 *****\n",
            "Loss: 5.492187\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000124\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 45\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #46 *****\n",
            "Loss: 5.492167\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000127\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 46\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #47 *****\n",
            "Loss: 5.492147\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000129\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 47\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #48 *****\n",
            "Loss: 5.492127\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000132\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 48\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #49 *****\n",
            "Loss: 5.492107\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000135\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 49\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #50 *****\n",
            "Loss: 5.492087\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000138\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 50\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #51 *****\n",
            "Loss: 5.492067\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000140\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 51\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #52 *****\n",
            "Loss: 5.492047\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000143\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 52\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #53 *****\n",
            "Loss: 5.492028\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000146\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 53\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #54 *****\n",
            "Loss: 5.492008\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000149\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 54\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #55 *****\n",
            "Loss: 5.491988\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000151\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 55\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #56 *****\n",
            "Loss: 5.491968\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000154\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 56\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #57 *****\n",
            "Loss: 5.491948\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000157\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 57\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #58 *****\n",
            "Loss: 5.491928\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000160\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 58\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #59 *****\n",
            "Loss: 5.491908\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000162\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 59\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #60 *****\n",
            "Loss: 5.491888\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000165\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 60\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #61 *****\n",
            "Loss: 5.491869\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000168\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 61\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #62 *****\n",
            "Loss: 5.491849\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000171\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 62\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #63 *****\n",
            "Loss: 5.491829\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000173\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 63\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #64 *****\n",
            "Loss: 5.491809\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000176\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 64\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #65 *****\n",
            "Loss: 5.491789\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000179\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 65\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #66 *****\n",
            "Loss: 5.491769\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000182\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 66\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #67 *****\n",
            "Loss: 5.491749\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000185\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 67\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #68 *****\n",
            "Loss: 5.491729\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000187\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 68\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #69 *****\n",
            "Loss: 5.491710\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000190\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 69\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #70 *****\n",
            "Loss: 5.491690\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000193\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 70\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #71 *****\n",
            "Loss: 5.491670\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000196\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 71\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #72 *****\n",
            "Loss: 5.491650\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000198\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 72\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #73 *****\n",
            "Loss: 5.491630\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000201\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 73\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #74 *****\n",
            "Loss: 5.491610\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000204\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 74\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #75 *****\n",
            "Loss: 5.491590\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000207\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 75\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #76 *****\n",
            "Loss: 5.491570\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000209\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 76\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #77 *****\n",
            "Loss: 5.491551\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000212\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 77\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #78 *****\n",
            "Loss: 5.491531\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000215\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 78\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #79 *****\n",
            "Loss: 5.491511\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000218\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 79\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #80 *****\n",
            "Loss: 5.491491\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000220\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 80\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #81 *****\n",
            "Loss: 5.491471\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000223\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 81\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #82 *****\n",
            "Loss: 5.491451\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000226\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 82\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #83 *****\n",
            "Loss: 5.491431\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000229\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 83\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #84 *****\n",
            "Loss: 5.491411\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000231\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 84\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #85 *****\n",
            "Loss: 5.491392\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000234\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 85\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #86 *****\n",
            "Loss: 5.491372\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000237\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 86\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #87 *****\n",
            "Loss: 5.491352\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000240\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 87\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #88 *****\n",
            "Loss: 5.491332\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000242\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 88\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #89 *****\n",
            "Loss: 5.491312\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000245\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 89\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #90 *****\n",
            "Loss: 5.491292\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000248\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 90\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #91 *****\n",
            "Loss: 5.491272\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000251\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 91\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #92 *****\n",
            "Loss: 5.491252\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000253\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 92\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #93 *****\n",
            "Loss: 5.491233\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000256\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 93\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #94 *****\n",
            "Loss: 5.491213\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000259\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 94\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #95 *****\n",
            "Loss: 5.491193\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000262\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 95\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #96 *****\n",
            "Loss: 5.491173\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000264\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 96\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #97 *****\n",
            "Loss: 5.491153\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000267\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 97\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #98 *****\n",
            "Loss: 5.491133\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000270\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 98\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #99 *****\n",
            "Loss: 5.491113\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000273\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 99\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #100 *****\n",
            "Loss: 5.491093\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000275\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 100\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #101 *****\n",
            "Loss: 5.491073\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000278\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 101\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #102 *****\n",
            "Loss: 5.491054\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000281\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 102\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #103 *****\n",
            "Loss: 5.491034\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000284\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 103\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #104 *****\n",
            "Loss: 5.491014\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000286\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 104\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #105 *****\n",
            "Loss: 5.490994\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000289\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 105\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #106 *****\n",
            "Loss: 5.490974\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000292\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 106\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #107 *****\n",
            "Loss: 5.490954\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000295\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 107\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #108 *****\n",
            "Loss: 5.490934\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000297\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 108\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #109 *****\n",
            "Loss: 5.490914\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000300\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 109\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #110 *****\n",
            "Loss: 5.490895\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000303\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 110\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #111 *****\n",
            "Loss: 5.490875\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000306\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 111\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #112 *****\n",
            "Loss: 5.490855\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000308\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 112\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #113 *****\n",
            "Loss: 5.490835\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000311\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 113\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #114 *****\n",
            "Loss: 5.490815\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000314\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 114\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #115 *****\n",
            "Loss: 5.490795\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000317\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 115\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #116 *****\n",
            "Loss: 5.490775\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000319\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 116\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #117 *****\n",
            "Loss: 5.490756\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000322\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 117\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #118 *****\n",
            "Loss: 5.490736\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000325\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 118\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #119 *****\n",
            "Loss: 5.490716\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000328\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 119\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #120 *****\n",
            "Loss: 5.490696\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000330\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 120\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #121 *****\n",
            "Loss: 5.490676\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000333\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 121\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #122 *****\n",
            "Loss: 5.490656\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000336\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 122\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #123 *****\n",
            "Loss: 5.490636\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000339\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 123\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #124 *****\n",
            "Loss: 5.490616\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000341\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 124\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #125 *****\n",
            "Loss: 5.490597\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000344\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 125\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #126 *****\n",
            "Loss: 5.490577\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000347\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 126\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #127 *****\n",
            "Loss: 5.490557\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000350\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 127\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #128 *****\n",
            "Loss: 5.490537\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000352\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 128\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #129 *****\n",
            "Loss: 5.490517\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000355\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 129\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #130 *****\n",
            "Loss: 5.490497\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000358\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 130\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #131 *****\n",
            "Loss: 5.490477\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000361\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 131\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #132 *****\n",
            "Loss: 5.490457\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000363\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 132\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #133 *****\n",
            "Loss: 5.490438\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000366\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 133\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #134 *****\n",
            "Loss: 5.490418\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000369\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 134\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #135 *****\n",
            "Loss: 5.490398\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000372\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 135\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #136 *****\n",
            "Loss: 5.490378\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000375\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 136\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #137 *****\n",
            "Loss: 5.490358\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000377\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 137\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #138 *****\n",
            "Loss: 5.490338\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000380\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 138\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #139 *****\n",
            "Loss: 5.490318\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000383\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 139\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #140 *****\n",
            "Loss: 5.490298\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000386\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 140\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #141 *****\n",
            "Loss: 5.490279\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000388\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 141\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #142 *****\n",
            "Loss: 5.490259\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000391\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 142\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #143 *****\n",
            "Loss: 5.490239\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000394\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 143\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #144 *****\n",
            "Loss: 5.490219\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000397\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 144\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #145 *****\n",
            "Loss: 5.490199\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000399\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 145\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #146 *****\n",
            "Loss: 5.490179\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000402\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 146\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #147 *****\n",
            "Loss: 5.490159\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000405\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 147\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #148 *****\n",
            "Loss: 5.490139\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000408\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 148\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #149 *****\n",
            "Loss: 5.490120\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000410\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 149\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #150 *****\n",
            "Loss: 5.490100\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000413\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 150\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #151 *****\n",
            "Loss: 5.490080\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000416\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 151\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #152 *****\n",
            "Loss: 5.490060\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000419\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 152\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #153 *****\n",
            "Loss: 5.490040\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000421\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 153\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #154 *****\n",
            "Loss: 5.490020\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000424\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 154\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #155 *****\n",
            "Loss: 5.490000\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000427\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 155\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #156 *****\n",
            "Loss: 5.489980\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000430\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 156\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #157 *****\n",
            "Loss: 5.489961\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000432\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 157\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #158 *****\n",
            "Loss: 5.489941\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000435\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 158\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #159 *****\n",
            "Loss: 5.489921\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000438\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 159\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #160 *****\n",
            "Loss: 5.489901\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000441\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 160\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #161 *****\n",
            "Loss: 5.489881\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000443\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 161\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #162 *****\n",
            "Loss: 5.489861\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000446\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 162\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #163 *****\n",
            "Loss: 5.489841\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000449\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 163\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #164 *****\n",
            "Loss: 5.489822\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000452\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 164\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #165 *****\n",
            "Loss: 5.489802\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000454\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 165\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #166 *****\n",
            "Loss: 5.489782\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000457\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 166\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #167 *****\n",
            "Loss: 5.489762\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000460\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 167\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #168 *****\n",
            "Loss: 5.489742\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000463\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 168\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #169 *****\n",
            "Loss: 5.489722\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000465\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 169\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #170 *****\n",
            "Loss: 5.489702\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000468\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 170\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #171 *****\n",
            "Loss: 5.489682\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000471\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 171\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #172 *****\n",
            "Loss: 5.489663\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000474\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 172\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #173 *****\n",
            "Loss: 5.489643\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000476\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 173\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #174 *****\n",
            "Loss: 5.489623\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000479\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 174\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #175 *****\n",
            "Loss: 5.489603\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000482\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 175\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #176 *****\n",
            "Loss: 5.489583\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000485\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 176\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #177 *****\n",
            "Loss: 5.489563\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000487\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 177\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #178 *****\n",
            "Loss: 5.489543\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000490\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 178\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #179 *****\n",
            "Loss: 5.489523\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000493\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 179\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #180 *****\n",
            "Loss: 5.489504\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000496\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 180\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #181 *****\n",
            "Loss: 5.489484\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000498\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 181\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #182 *****\n",
            "Loss: 5.489464\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000501\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 182\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #183 *****\n",
            "Loss: 5.489444\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000504\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 183\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #184 *****\n",
            "Loss: 5.489424\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000507\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 184\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #185 *****\n",
            "Loss: 5.489404\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000509\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 185\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #186 *****\n",
            "Loss: 5.489384\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000512\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 186\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #187 *****\n",
            "Loss: 5.489365\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000515\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 187\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #188 *****\n",
            "Loss: 5.489345\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000518\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 188\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #189 *****\n",
            "Loss: 5.489325\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000520\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 189\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #190 *****\n",
            "Loss: 5.489305\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000523\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 190\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #191 *****\n",
            "Loss: 5.489285\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000526\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 191\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #192 *****\n",
            "Loss: 5.489265\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000529\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 192\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #193 *****\n",
            "Loss: 5.489245\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000531\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 193\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #194 *****\n",
            "Loss: 5.489225\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000534\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 194\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #195 *****\n",
            "Loss: 5.489206\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000537\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 195\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #196 *****\n",
            "Loss: 5.489186\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000540\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 196\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #197 *****\n",
            "Loss: 5.489166\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000542\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 197\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #198 *****\n",
            "Loss: 5.489146\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000545\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 198\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #199 *****\n",
            "Loss: 5.489126\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000548\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 199\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #200 *****\n",
            "Loss: 5.489106\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000551\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 200\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #201 *****\n",
            "Loss: 5.489086\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000553\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 201\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #202 *****\n",
            "Loss: 5.489067\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000556\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 202\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #203 *****\n",
            "Loss: 5.489047\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000559\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 203\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #204 *****\n",
            "Loss: 5.489027\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000562\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 204\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #205 *****\n",
            "Loss: 5.489007\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000564\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 205\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #206 *****\n",
            "Loss: 5.488987\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000567\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 206\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #207 *****\n",
            "Loss: 5.488967\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000570\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 207\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #208 *****\n",
            "Loss: 5.488947\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000573\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 208\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #209 *****\n",
            "Loss: 5.488927\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000575\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 209\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #210 *****\n",
            "Loss: 5.488908\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000578\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 210\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #211 *****\n",
            "Loss: 5.488888\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000581\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 211\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #212 *****\n",
            "Loss: 5.488868\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000584\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 212\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #213 *****\n",
            "Loss: 5.488848\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000586\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 213\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #214 *****\n",
            "Loss: 5.488828\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000589\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 214\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #215 *****\n",
            "Loss: 5.488808\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000592\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 215\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #216 *****\n",
            "Loss: 5.488788\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000595\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 216\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #217 *****\n",
            "Loss: 5.488769\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000598\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 217\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #218 *****\n",
            "Loss: 5.488749\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000600\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 218\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #219 *****\n",
            "Loss: 5.488729\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000603\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 219\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #220 *****\n",
            "Loss: 5.488709\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000606\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 220\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #221 *****\n",
            "Loss: 5.488689\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000609\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 221\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #222 *****\n",
            "Loss: 5.488669\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000611\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 222\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #223 *****\n",
            "Loss: 5.488649\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000614\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 223\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #224 *****\n",
            "Loss: 5.488629\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000617\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 224\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #225 *****\n",
            "Loss: 5.488610\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000620\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 225\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #226 *****\n",
            "Loss: 5.488590\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000622\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 226\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #227 *****\n",
            "Loss: 5.488570\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000625\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 227\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #228 *****\n",
            "Loss: 5.488550\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000628\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 228\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #229 *****\n",
            "Loss: 5.488530\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000631\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 229\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #230 *****\n",
            "Loss: 5.488510\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000633\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 230\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #231 *****\n",
            "Loss: 5.488490\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000636\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 231\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #232 *****\n",
            "Loss: 5.488471\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000639\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 232\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #233 *****\n",
            "Loss: 5.488451\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000642\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 233\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #234 *****\n",
            "Loss: 5.488431\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000644\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 234\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #235 *****\n",
            "Loss: 5.488411\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000647\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 235\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #236 *****\n",
            "Loss: 5.488391\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000650\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 236\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #237 *****\n",
            "Loss: 5.488371\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000653\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 237\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #238 *****\n",
            "Loss: 5.488351\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000655\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 238\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #239 *****\n",
            "Loss: 5.488331\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000658\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 239\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #240 *****\n",
            "Loss: 5.488312\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000661\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 240\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #241 *****\n",
            "Loss: 5.488292\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000664\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 241\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #242 *****\n",
            "Loss: 5.488272\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000666\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 242\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #243 *****\n",
            "Loss: 5.488252\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000669\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 243\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #244 *****\n",
            "Loss: 5.488232\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000672\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 244\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #245 *****\n",
            "Loss: 5.488212\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000675\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 245\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #246 *****\n",
            "Loss: 5.488192\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000677\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 246\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #247 *****\n",
            "Loss: 5.488173\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000680\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 247\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #248 *****\n",
            "Loss: 5.488153\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000683\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 248\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #249 *****\n",
            "Loss: 5.488133\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000686\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 249\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #250 *****\n",
            "Loss: 5.488113\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000688\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 250\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #251 *****\n",
            "Loss: 5.488093\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000691\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 251\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #252 *****\n",
            "Loss: 5.488073\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000694\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 252\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #253 *****\n",
            "Loss: 5.488053\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000697\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 253\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #254 *****\n",
            "Loss: 5.488034\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000699\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 254\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #255 *****\n",
            "Loss: 5.488014\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000702\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 255\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #256 *****\n",
            "Loss: 5.487994\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000705\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 256\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #257 *****\n",
            "Loss: 5.487974\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000708\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 257\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #258 *****\n",
            "Loss: 5.487954\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000710\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 258\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #259 *****\n",
            "Loss: 5.487934\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000713\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 259\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #260 *****\n",
            "Loss: 5.487914\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000716\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 260\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #261 *****\n",
            "Loss: 5.487894\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000719\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 261\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #262 *****\n",
            "Loss: 5.487875\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000721\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 262\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #263 *****\n",
            "Loss: 5.487855\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000724\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 263\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #264 *****\n",
            "Loss: 5.487835\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000727\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 264\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #265 *****\n",
            "Loss: 5.487815\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000730\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 265\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #266 *****\n",
            "Loss: 5.487795\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000732\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 266\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #267 *****\n",
            "Loss: 5.487775\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000735\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 267\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #268 *****\n",
            "Loss: 5.487755\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000738\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 268\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #269 *****\n",
            "Loss: 5.487736\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000741\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 269\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #270 *****\n",
            "Loss: 5.487716\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000743\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 270\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #271 *****\n",
            "Loss: 5.487696\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000746\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 271\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #272 *****\n",
            "Loss: 5.487676\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000749\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 272\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #273 *****\n",
            "Loss: 5.487656\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000752\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 273\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #274 *****\n",
            "Loss: 5.487636\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000754\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 274\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #275 *****\n",
            "Loss: 5.487616\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000757\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 275\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #276 *****\n",
            "Loss: 5.487597\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000760\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 276\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #277 *****\n",
            "Loss: 5.487577\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000763\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 277\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #278 *****\n",
            "Loss: 5.487557\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000765\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 278\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #279 *****\n",
            "Loss: 5.487537\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000768\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 279\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #280 *****\n",
            "Loss: 5.487517\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000771\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 280\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #281 *****\n",
            "Loss: 5.487497\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000774\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 281\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #282 *****\n",
            "Loss: 5.487477\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000776\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 282\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #283 *****\n",
            "Loss: 5.487458\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000779\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 283\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #284 *****\n",
            "Loss: 5.487438\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000782\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 284\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #285 *****\n",
            "Loss: 5.487418\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000785\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 285\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #286 *****\n",
            "Loss: 5.487398\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000787\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 286\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #287 *****\n",
            "Loss: 5.487378\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000790\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 287\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #288 *****\n",
            "Loss: 5.487358\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000793\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 288\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #289 *****\n",
            "Loss: 5.487338\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000796\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 289\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #290 *****\n",
            "Loss: 5.487319\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000798\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 290\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #291 *****\n",
            "Loss: 5.487299\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000801\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 291\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #292 *****\n",
            "Loss: 5.487279\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000804\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 292\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #293 *****\n",
            "Loss: 5.487259\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000807\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 293\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #294 *****\n",
            "Loss: 5.487239\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000809\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 294\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #295 *****\n",
            "Loss: 5.487219\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000812\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 295\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #296 *****\n",
            "Loss: 5.487199\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000815\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 296\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #297 *****\n",
            "Loss: 5.487179\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000818\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 297\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #298 *****\n",
            "Loss: 5.487160\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000820\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 298\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #299 *****\n",
            "Loss: 5.487140\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000823\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 299\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #300 *****\n",
            "Loss: 5.487120\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000826\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 300\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #301 *****\n",
            "Loss: 5.487100\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000829\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 301\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #302 *****\n",
            "Loss: 5.487080\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000831\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 302\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #303 *****\n",
            "Loss: 5.487060\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000834\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 303\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #304 *****\n",
            "Loss: 5.487040\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000837\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 304\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #305 *****\n",
            "Loss: 5.487021\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000840\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 305\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #306 *****\n",
            "Loss: 5.487001\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000842\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 306\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #307 *****\n",
            "Loss: 5.486981\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000845\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 307\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #308 *****\n",
            "Loss: 5.486961\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000848\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 308\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #309 *****\n",
            "Loss: 5.486941\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000851\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 309\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #310 *****\n",
            "Loss: 5.486921\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000853\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 310\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #311 *****\n",
            "Loss: 5.486901\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000856\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 311\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #312 *****\n",
            "Loss: 5.486882\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000859\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 312\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #313 *****\n",
            "Loss: 5.486862\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000862\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 313\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #314 *****\n",
            "Loss: 5.486842\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000865\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 314\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #315 *****\n",
            "Loss: 5.486822\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000867\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 315\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #316 *****\n",
            "Loss: 5.486802\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000870\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 316\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #317 *****\n",
            "Loss: 5.486782\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000873\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 317\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #318 *****\n",
            "Loss: 5.486762\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000876\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 318\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #319 *****\n",
            "Loss: 5.486743\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000878\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 319\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #320 *****\n",
            "Loss: 5.486723\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000881\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 320\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #321 *****\n",
            "Loss: 5.486703\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000884\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 321\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #322 *****\n",
            "Loss: 5.486683\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000887\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 322\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #323 *****\n",
            "Loss: 5.486663\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000889\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 323\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #324 *****\n",
            "Loss: 5.486643\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000892\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 324\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #325 *****\n",
            "Loss: 5.486623\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000895\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 325\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #326 *****\n",
            "Loss: 5.486604\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000898\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 326\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #327 *****\n",
            "Loss: 5.486584\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000900\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 327\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #328 *****\n",
            "Loss: 5.486564\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000903\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 328\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #329 *****\n",
            "Loss: 5.486544\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000906\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 329\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #330 *****\n",
            "Loss: 5.486524\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000909\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 330\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #331 *****\n",
            "Loss: 5.486504\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000911\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 331\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #332 *****\n",
            "Loss: 5.486484\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000914\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 332\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #333 *****\n",
            "Loss: 5.486465\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000917\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 333\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #334 *****\n",
            "Loss: 5.486445\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000920\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 334\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #335 *****\n",
            "Loss: 5.486425\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000922\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 335\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #336 *****\n",
            "Loss: 5.486405\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000925\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 336\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #337 *****\n",
            "Loss: 5.486385\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000928\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 337\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #338 *****\n",
            "Loss: 5.486365\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000931\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 338\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #339 *****\n",
            "Loss: 5.486345\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000933\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 339\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #340 *****\n",
            "Loss: 5.486326\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000936\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 340\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #341 *****\n",
            "Loss: 5.486306\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000939\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 341\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #342 *****\n",
            "Loss: 5.486286\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000942\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 342\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #343 *****\n",
            "Loss: 5.486266\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000944\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 343\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #344 *****\n",
            "Loss: 5.486246\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000947\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 344\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #345 *****\n",
            "Loss: 5.486226\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000950\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 345\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #346 *****\n",
            "Loss: 5.486206\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000953\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 346\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #347 *****\n",
            "Loss: 5.486187\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000955\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 347\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #348 *****\n",
            "Loss: 5.486167\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000958\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 348\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #349 *****\n",
            "Loss: 5.486147\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000961\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 349\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #350 *****\n",
            "Loss: 5.486127\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000964\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 350\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #351 *****\n",
            "Loss: 5.486107\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000966\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 351\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #352 *****\n",
            "Loss: 5.486087\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000969\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 352\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #353 *****\n",
            "Loss: 5.486067\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000972\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 353\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #354 *****\n",
            "Loss: 5.486048\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000975\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 354\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #355 *****\n",
            "Loss: 5.486028\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000977\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 355\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #356 *****\n",
            "Loss: 5.486008\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000980\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 356\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #357 *****\n",
            "Loss: 5.485988\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000983\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 357\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #358 *****\n",
            "Loss: 5.485968\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000986\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 358\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #359 *****\n",
            "Loss: 5.485948\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000988\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 359\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #360 *****\n",
            "Loss: 5.485929\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000991\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 360\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #361 *****\n",
            "Loss: 5.485909\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000994\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 361\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #362 *****\n",
            "Loss: 5.485889\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000997\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 362\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #363 *****\n",
            "Loss: 5.485869\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.000999\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 363\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #364 *****\n",
            "Loss: 5.485849\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001002\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 364\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #365 *****\n",
            "Loss: 5.485829\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001005\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 365\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #366 *****\n",
            "Loss: 5.485809\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001008\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 366\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #367 *****\n",
            "Loss: 5.485790\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001010\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 367\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #368 *****\n",
            "Loss: 5.485770\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001013\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 368\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #369 *****\n",
            "Loss: 5.485750\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001016\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 369\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #370 *****\n",
            "Loss: 5.485730\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001019\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 370\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #371 *****\n",
            "Loss: 5.485710\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001021\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 371\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #372 *****\n",
            "Loss: 5.485690\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001024\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 372\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #373 *****\n",
            "Loss: 5.485670\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001027\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 373\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #374 *****\n",
            "Loss: 5.485651\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001030\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 374\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #375 *****\n",
            "Loss: 5.485631\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001032\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 375\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #376 *****\n",
            "Loss: 5.485611\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001035\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 376\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #377 *****\n",
            "Loss: 5.485591\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001038\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 377\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #378 *****\n",
            "Loss: 5.485571\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001041\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 378\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #379 *****\n",
            "Loss: 5.485551\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001043\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 379\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #380 *****\n",
            "Loss: 5.485531\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001046\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 380\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #381 *****\n",
            "Loss: 5.485512\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001049\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 381\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #382 *****\n",
            "Loss: 5.485492\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001052\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 382\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #383 *****\n",
            "Loss: 5.485472\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001054\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 383\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #384 *****\n",
            "Loss: 5.485452\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001057\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 384\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #385 *****\n",
            "Loss: 5.485432\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001060\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 385\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #386 *****\n",
            "Loss: 5.485412\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001063\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 386\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #387 *****\n",
            "Loss: 5.485392\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001065\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 387\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #388 *****\n",
            "Loss: 5.485373\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001068\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 388\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #389 *****\n",
            "Loss: 5.485353\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001071\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 389\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #390 *****\n",
            "Loss: 5.485333\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001074\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 390\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #391 *****\n",
            "Loss: 5.485313\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001076\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 391\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #392 *****\n",
            "Loss: 5.485293\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001079\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 392\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #393 *****\n",
            "Loss: 5.485273\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001082\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 393\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #394 *****\n",
            "Loss: 5.485254\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001085\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 394\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #395 *****\n",
            "Loss: 5.485234\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001087\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 395\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #396 *****\n",
            "Loss: 5.485214\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001090\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 396\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #397 *****\n",
            "Loss: 5.485194\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001093\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 397\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #398 *****\n",
            "Loss: 5.485174\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001096\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 398\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #399 *****\n",
            "Loss: 5.485154\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001098\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 399\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #400 *****\n",
            "Loss: 5.485134\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001101\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 400\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #401 *****\n",
            "Loss: 5.485115\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001104\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 401\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #402 *****\n",
            "Loss: 5.485095\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001107\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 402\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #403 *****\n",
            "Loss: 5.485075\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001109\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 403\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #404 *****\n",
            "Loss: 5.485055\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001112\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 404\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #405 *****\n",
            "Loss: 5.485035\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001115\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 405\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #406 *****\n",
            "Loss: 5.485015\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001118\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 406\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #407 *****\n",
            "Loss: 5.484995\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001120\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 407\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #408 *****\n",
            "Loss: 5.484976\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001123\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 408\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #409 *****\n",
            "Loss: 5.484956\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001126\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 409\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #410 *****\n",
            "Loss: 5.484936\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001129\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 410\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #411 *****\n",
            "Loss: 5.484916\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001131\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 411\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #412 *****\n",
            "Loss: 5.484896\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001134\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 412\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #413 *****\n",
            "Loss: 5.484876\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001137\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 413\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #414 *****\n",
            "Loss: 5.484857\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001140\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 414\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #415 *****\n",
            "Loss: 5.484837\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001142\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 415\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #416 *****\n",
            "Loss: 5.484817\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001145\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 416\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #417 *****\n",
            "Loss: 5.484797\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001148\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 417\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #418 *****\n",
            "Loss: 5.484777\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001151\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 418\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #419 *****\n",
            "Loss: 5.484757\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001153\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 419\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #420 *****\n",
            "Loss: 5.484737\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001156\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 420\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #421 *****\n",
            "Loss: 5.484718\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001159\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 421\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #422 *****\n",
            "Loss: 5.484698\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001162\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 422\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #423 *****\n",
            "Loss: 5.484678\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001164\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 423\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #424 *****\n",
            "Loss: 5.484658\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001167\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 424\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #425 *****\n",
            "Loss: 5.484638\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001170\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 425\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #426 *****\n",
            "Loss: 5.484618\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001173\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 426\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #427 *****\n",
            "Loss: 5.484598\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001175\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 427\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #428 *****\n",
            "Loss: 5.484579\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001178\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 428\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #429 *****\n",
            "Loss: 5.484559\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001181\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 429\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #430 *****\n",
            "Loss: 5.484539\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001184\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 430\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #431 *****\n",
            "Loss: 5.484519\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001186\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 431\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #432 *****\n",
            "Loss: 5.484499\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001189\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 432\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #433 *****\n",
            "Loss: 5.484479\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001192\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 433\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #434 *****\n",
            "Loss: 5.484460\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001195\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 434\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #435 *****\n",
            "Loss: 5.484440\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001197\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 435\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #436 *****\n",
            "Loss: 5.484420\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001200\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 436\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #437 *****\n",
            "Loss: 5.484400\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001203\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 437\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #438 *****\n",
            "Loss: 5.484380\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001206\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 438\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #439 *****\n",
            "Loss: 5.484360\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001208\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 439\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #440 *****\n",
            "Loss: 5.484340\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001211\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 440\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #441 *****\n",
            "Loss: 5.484321\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001214\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 441\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #442 *****\n",
            "Loss: 5.484301\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001217\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 442\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #443 *****\n",
            "Loss: 5.484281\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001220\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 443\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #444 *****\n",
            "Loss: 5.484261\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001222\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 444\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #445 *****\n",
            "Loss: 5.484241\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001225\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 445\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #446 *****\n",
            "Loss: 5.484221\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001228\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 446\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #447 *****\n",
            "Loss: 5.484202\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001231\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 447\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #448 *****\n",
            "Loss: 5.484182\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001233\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 448\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #449 *****\n",
            "Loss: 5.484162\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001236\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 449\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #450 *****\n",
            "Loss: 5.484142\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001239\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 450\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #451 *****\n",
            "Loss: 5.484122\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001242\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 451\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #452 *****\n",
            "Loss: 5.484102\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001244\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 452\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #453 *****\n",
            "Loss: 5.484082\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001247\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 453\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #454 *****\n",
            "Loss: 5.484063\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001250\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 454\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #455 *****\n",
            "Loss: 5.484043\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001253\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 455\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #456 *****\n",
            "Loss: 5.484023\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001255\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 456\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #457 *****\n",
            "Loss: 5.484003\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001258\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 457\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #458 *****\n",
            "Loss: 5.483983\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001261\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 458\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #459 *****\n",
            "Loss: 5.483963\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001264\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 459\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #460 *****\n",
            "Loss: 5.483944\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001266\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 460\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #461 *****\n",
            "Loss: 5.483924\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001269\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 461\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #462 *****\n",
            "Loss: 5.483904\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001272\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 462\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #463 *****\n",
            "Loss: 5.483884\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001275\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 463\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #464 *****\n",
            "Loss: 5.483864\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001277\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 464\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #465 *****\n",
            "Loss: 5.483844\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001280\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 465\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #466 *****\n",
            "Loss: 5.483824\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001283\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 466\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #467 *****\n",
            "Loss: 5.483805\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001286\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 467\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #468 *****\n",
            "Loss: 5.483785\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001288\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 468\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #469 *****\n",
            "Loss: 5.483765\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001291\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 469\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #470 *****\n",
            "Loss: 5.483745\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001294\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 470\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #471 *****\n",
            "Loss: 5.483725\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001297\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 471\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #472 *****\n",
            "Loss: 5.483705\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001299\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 472\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #473 *****\n",
            "Loss: 5.483686\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001302\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 473\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #474 *****\n",
            "Loss: 5.483666\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001305\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 474\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #475 *****\n",
            "Loss: 5.483646\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001308\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 475\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #476 *****\n",
            "Loss: 5.483626\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001310\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 476\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #477 *****\n",
            "Loss: 5.483606\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001313\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 477\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #478 *****\n",
            "Loss: 5.483586\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001316\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 478\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #479 *****\n",
            "Loss: 5.483566\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001319\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 479\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #480 *****\n",
            "Loss: 5.483547\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001321\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 480\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #481 *****\n",
            "Loss: 5.483527\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001324\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 481\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #482 *****\n",
            "Loss: 5.483507\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001327\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 482\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #483 *****\n",
            "Loss: 5.483487\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001330\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 483\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #484 *****\n",
            "Loss: 5.483467\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001332\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 484\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #485 *****\n",
            "Loss: 5.483447\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001335\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 485\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #486 *****\n",
            "Loss: 5.483428\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001338\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 486\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #487 *****\n",
            "Loss: 5.483408\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001341\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 487\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #488 *****\n",
            "Loss: 5.483388\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001343\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 488\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #489 *****\n",
            "Loss: 5.483368\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001346\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 489\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #490 *****\n",
            "Loss: 5.483348\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001349\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 490\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #491 *****\n",
            "Loss: 5.483328\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001352\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 491\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #492 *****\n",
            "Loss: 5.483308\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001354\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 492\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #493 *****\n",
            "Loss: 5.483289\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001357\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 493\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #494 *****\n",
            "Loss: 5.483269\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001360\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 494\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #495 *****\n",
            "Loss: 5.483249\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001363\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 495\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #496 *****\n",
            "Loss: 5.483229\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001365\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 496\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #497 *****\n",
            "Loss: 5.483209\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001368\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 497\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #498 *****\n",
            "Loss: 5.483189\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001371\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 498\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #499 *****\n",
            "Loss: 5.483170\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001374\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 499\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #500 *****\n",
            "Loss: 5.483150\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001376\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 500\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #501 *****\n",
            "Loss: 5.483130\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001379\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 501\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #502 *****\n",
            "Loss: 5.483110\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001382\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 502\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #503 *****\n",
            "Loss: 5.483090\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001385\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 503\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #504 *****\n",
            "Loss: 5.483070\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001387\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 504\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #505 *****\n",
            "Loss: 5.483051\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001390\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 505\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #506 *****\n",
            "Loss: 5.483031\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001393\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 506\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #507 *****\n",
            "Loss: 5.483011\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001396\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 507\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #508 *****\n",
            "Loss: 5.482991\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001398\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 508\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #509 *****\n",
            "Loss: 5.482971\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001401\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 509\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #510 *****\n",
            "Loss: 5.482951\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001404\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 510\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #511 *****\n",
            "Loss: 5.482931\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001407\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 511\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #512 *****\n",
            "Loss: 5.482912\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001409\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 512\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #513 *****\n",
            "Loss: 5.482892\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001412\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 513\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #514 *****\n",
            "Loss: 5.482872\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001415\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 514\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #515 *****\n",
            "Loss: 5.482852\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001418\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 515\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #516 *****\n",
            "Loss: 5.482832\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001420\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 516\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #517 *****\n",
            "Loss: 5.482812\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001423\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 517\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #518 *****\n",
            "Loss: 5.482793\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001426\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 518\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #519 *****\n",
            "Loss: 5.482773\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001429\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 519\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #520 *****\n",
            "Loss: 5.482753\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001431\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 520\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #521 *****\n",
            "Loss: 5.482733\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001434\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 521\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #522 *****\n",
            "Loss: 5.482713\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001437\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 522\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #523 *****\n",
            "Loss: 5.482693\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001440\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 523\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #524 *****\n",
            "Loss: 5.482674\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001442\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 524\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #525 *****\n",
            "Loss: 5.482654\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001445\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 525\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #526 *****\n",
            "Loss: 5.482634\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001448\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 526\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #527 *****\n",
            "Loss: 5.482614\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001451\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 527\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #528 *****\n",
            "Loss: 5.482594\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001453\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 528\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #529 *****\n",
            "Loss: 5.482574\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001456\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 529\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #530 *****\n",
            "Loss: 5.482554\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001459\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 530\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #531 *****\n",
            "Loss: 5.482535\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001462\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 531\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #532 *****\n",
            "Loss: 5.482515\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001464\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 532\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #533 *****\n",
            "Loss: 5.482495\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001467\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 533\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #534 *****\n",
            "Loss: 5.482475\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001470\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 534\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #535 *****\n",
            "Loss: 5.482455\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001473\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 535\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #536 *****\n",
            "Loss: 5.482435\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001475\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 536\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #537 *****\n",
            "Loss: 5.482416\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001478\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 537\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #538 *****\n",
            "Loss: 5.482396\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001481\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 538\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #539 *****\n",
            "Loss: 5.482376\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001484\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 539\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #540 *****\n",
            "Loss: 5.482356\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001486\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 540\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #541 *****\n",
            "Loss: 5.482336\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001489\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 541\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #542 *****\n",
            "Loss: 5.482316\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001492\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 542\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #543 *****\n",
            "Loss: 5.482297\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001495\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 543\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #544 *****\n",
            "Loss: 5.482277\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001497\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 544\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #545 *****\n",
            "Loss: 5.482257\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001500\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 545\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #546 *****\n",
            "Loss: 5.482237\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001503\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 546\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #547 *****\n",
            "Loss: 5.482217\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001506\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 547\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #548 *****\n",
            "Loss: 5.482197\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001508\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 548\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #549 *****\n",
            "Loss: 5.482178\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001511\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 549\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #550 *****\n",
            "Loss: 5.482158\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001514\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 550\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #551 *****\n",
            "Loss: 5.482138\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001517\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 551\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #552 *****\n",
            "Loss: 5.482118\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001519\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 552\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #553 *****\n",
            "Loss: 5.482098\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001522\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 553\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #554 *****\n",
            "Loss: 5.482078\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001525\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 554\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #555 *****\n",
            "Loss: 5.482059\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001528\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 555\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #556 *****\n",
            "Loss: 5.482039\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001530\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 556\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #557 *****\n",
            "Loss: 5.482019\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001533\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 557\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #558 *****\n",
            "Loss: 5.481999\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001536\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 558\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #559 *****\n",
            "Loss: 5.481979\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001539\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 559\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #560 *****\n",
            "Loss: 5.481959\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001541\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 560\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #561 *****\n",
            "Loss: 5.481939\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001544\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 561\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #562 *****\n",
            "Loss: 5.481920\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001547\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 562\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #563 *****\n",
            "Loss: 5.481900\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001550\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 563\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #564 *****\n",
            "Loss: 5.481880\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001552\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 564\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #565 *****\n",
            "Loss: 5.481860\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001555\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 565\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #566 *****\n",
            "Loss: 5.481840\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001558\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 566\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #567 *****\n",
            "Loss: 5.481820\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001561\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 567\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #568 *****\n",
            "Loss: 5.481801\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001563\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 568\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #569 *****\n",
            "Loss: 5.481781\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001566\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 569\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #570 *****\n",
            "Loss: 5.481761\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001569\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 570\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #571 *****\n",
            "Loss: 5.481741\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001572\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 571\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #572 *****\n",
            "Loss: 5.481721\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001574\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 572\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #573 *****\n",
            "Loss: 5.481701\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001577\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 573\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #574 *****\n",
            "Loss: 5.481682\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001580\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 574\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #575 *****\n",
            "Loss: 5.481662\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001583\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 575\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #576 *****\n",
            "Loss: 5.481642\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001585\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 576\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #577 *****\n",
            "Loss: 5.481622\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001588\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 577\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #578 *****\n",
            "Loss: 5.481602\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001591\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 578\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #579 *****\n",
            "Loss: 5.481582\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001594\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 579\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #580 *****\n",
            "Loss: 5.481563\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001596\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 580\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #581 *****\n",
            "Loss: 5.481543\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001599\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 581\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #582 *****\n",
            "Loss: 5.481523\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001602\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 582\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #583 *****\n",
            "Loss: 5.481503\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001605\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 583\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #584 *****\n",
            "Loss: 5.481483\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001607\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 584\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #585 *****\n",
            "Loss: 5.481463\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001610\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 585\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #586 *****\n",
            "Loss: 5.481444\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001613\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 586\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #587 *****\n",
            "Loss: 5.481424\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001616\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 587\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #588 *****\n",
            "Loss: 5.481404\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001618\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 588\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #589 *****\n",
            "Loss: 5.481384\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001621\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 589\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #590 *****\n",
            "Loss: 5.481364\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001624\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 590\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #591 *****\n",
            "Loss: 5.481344\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001627\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 591\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #592 *****\n",
            "Loss: 5.481325\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001629\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 592\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #593 *****\n",
            "Loss: 5.481305\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001632\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 593\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #594 *****\n",
            "Loss: 5.481285\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001635\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 594\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #595 *****\n",
            "Loss: 5.481265\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001638\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 595\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #596 *****\n",
            "Loss: 5.481245\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001640\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 596\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #597 *****\n",
            "Loss: 5.481225\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001643\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 597\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #598 *****\n",
            "Loss: 5.481206\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001646\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 598\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #599 *****\n",
            "Loss: 5.481186\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001649\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 599\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #600 *****\n",
            "Loss: 5.481166\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001651\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 600\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #601 *****\n",
            "Loss: 5.481146\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001654\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 601\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #602 *****\n",
            "Loss: 5.481126\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001657\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 602\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #603 *****\n",
            "Loss: 5.481106\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001660\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 603\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #604 *****\n",
            "Loss: 5.481087\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001662\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 604\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #605 *****\n",
            "Loss: 5.481067\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001665\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 605\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #606 *****\n",
            "Loss: 5.481047\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001668\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 606\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #607 *****\n",
            "Loss: 5.481027\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001671\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 607\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #608 *****\n",
            "Loss: 5.481007\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001673\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 608\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #609 *****\n",
            "Loss: 5.480987\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001676\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 609\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #610 *****\n",
            "Loss: 5.480968\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001679\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 610\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #611 *****\n",
            "Loss: 5.480948\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001682\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 611\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #612 *****\n",
            "Loss: 5.480928\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001684\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 612\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #613 *****\n",
            "Loss: 5.480908\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001687\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 613\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #614 *****\n",
            "Loss: 5.480888\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001690\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 614\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #615 *****\n",
            "Loss: 5.480868\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001693\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 615\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #616 *****\n",
            "Loss: 5.480849\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001695\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 616\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #617 *****\n",
            "Loss: 5.480829\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001698\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 617\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #618 *****\n",
            "Loss: 5.480809\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001701\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 618\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #619 *****\n",
            "Loss: 5.480789\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001704\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 619\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #620 *****\n",
            "Loss: 5.480769\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001706\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 620\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #621 *****\n",
            "Loss: 5.480749\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001709\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 621\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #622 *****\n",
            "Loss: 5.480730\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001712\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 622\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #623 *****\n",
            "Loss: 5.480710\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001715\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 623\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #624 *****\n",
            "Loss: 5.480690\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001717\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 624\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #625 *****\n",
            "Loss: 5.480670\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001720\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 625\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #626 *****\n",
            "Loss: 5.480650\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001723\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 626\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #627 *****\n",
            "Loss: 5.480630\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001726\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 627\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #628 *****\n",
            "Loss: 5.480611\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001728\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 628\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #629 *****\n",
            "Loss: 5.480591\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001731\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 629\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #630 *****\n",
            "Loss: 5.480571\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001734\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 630\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #631 *****\n",
            "Loss: 5.480551\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001737\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 631\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #632 *****\n",
            "Loss: 5.480531\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001739\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 632\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #633 *****\n",
            "Loss: 5.480511\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001742\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 633\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #634 *****\n",
            "Loss: 5.480492\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001745\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 634\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #635 *****\n",
            "Loss: 5.480472\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001748\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 635\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #636 *****\n",
            "Loss: 5.480452\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001750\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 636\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #637 *****\n",
            "Loss: 5.480432\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001753\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 637\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #638 *****\n",
            "Loss: 5.480412\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001756\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 638\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #639 *****\n",
            "Loss: 5.480392\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001759\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 639\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #640 *****\n",
            "Loss: 5.480373\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001761\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 640\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #641 *****\n",
            "Loss: 5.480353\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001764\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 641\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #642 *****\n",
            "Loss: 5.480333\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001767\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 642\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #643 *****\n",
            "Loss: 5.480313\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001770\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 643\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #644 *****\n",
            "Loss: 5.480293\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001772\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 644\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #645 *****\n",
            "Loss: 5.480273\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001775\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 645\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #646 *****\n",
            "Loss: 5.480254\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001778\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 646\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #647 *****\n",
            "Loss: 5.480234\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001781\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 647\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #648 *****\n",
            "Loss: 5.480214\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001783\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 648\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #649 *****\n",
            "Loss: 5.480194\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001786\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 649\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #650 *****\n",
            "Loss: 5.480174\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001789\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 650\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #651 *****\n",
            "Loss: 5.480154\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001792\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 651\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #652 *****\n",
            "Loss: 5.480135\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001794\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 652\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #653 *****\n",
            "Loss: 5.480115\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001797\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 653\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #654 *****\n",
            "Loss: 5.480095\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001800\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 654\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #655 *****\n",
            "Loss: 5.480075\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001803\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 655\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #656 *****\n",
            "Loss: 5.480055\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001805\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 656\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #657 *****\n",
            "Loss: 5.480035\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001808\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 657\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #658 *****\n",
            "Loss: 5.480016\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001811\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 658\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #659 *****\n",
            "Loss: 5.479996\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001814\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 659\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #660 *****\n",
            "Loss: 5.479976\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001816\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 660\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #661 *****\n",
            "Loss: 5.479956\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001819\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 661\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #662 *****\n",
            "Loss: 5.479936\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001822\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 662\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #663 *****\n",
            "Loss: 5.479916\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001825\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 663\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #664 *****\n",
            "Loss: 5.479897\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001827\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 664\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #665 *****\n",
            "Loss: 5.479877\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001830\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 665\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #666 *****\n",
            "Loss: 5.479857\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001833\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 666\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #667 *****\n",
            "Loss: 5.479837\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001836\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 667\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #668 *****\n",
            "Loss: 5.479817\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001838\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 668\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #669 *****\n",
            "Loss: 5.479797\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001841\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 669\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #670 *****\n",
            "Loss: 5.479778\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001844\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 670\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #671 *****\n",
            "Loss: 5.479758\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001847\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 671\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #672 *****\n",
            "Loss: 5.479738\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001849\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 672\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #673 *****\n",
            "Loss: 5.479718\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001852\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 673\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #674 *****\n",
            "Loss: 5.479698\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001855\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 674\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #675 *****\n",
            "Loss: 5.479678\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001858\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 675\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #676 *****\n",
            "Loss: 5.479659\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001860\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 676\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #677 *****\n",
            "Loss: 5.479639\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001863\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 677\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #678 *****\n",
            "Loss: 5.479619\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001866\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 678\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #679 *****\n",
            "Loss: 5.479599\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001869\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 679\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #680 *****\n",
            "Loss: 5.479579\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001871\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 680\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #681 *****\n",
            "Loss: 5.479560\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001874\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 681\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #682 *****\n",
            "Loss: 5.479540\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001877\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 682\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #683 *****\n",
            "Loss: 5.479520\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001880\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 683\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #684 *****\n",
            "Loss: 5.479500\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001882\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 684\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #685 *****\n",
            "Loss: 5.479480\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001885\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 685\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #686 *****\n",
            "Loss: 5.479460\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001888\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 686\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #687 *****\n",
            "Loss: 5.479441\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001891\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 687\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #688 *****\n",
            "Loss: 5.479421\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001893\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 688\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #689 *****\n",
            "Loss: 5.479401\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001896\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 689\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #690 *****\n",
            "Loss: 5.479381\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001899\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 690\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #691 *****\n",
            "Loss: 5.479361\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001902\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 691\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #692 *****\n",
            "Loss: 5.479341\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001904\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 692\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #693 *****\n",
            "Loss: 5.479322\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001907\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 693\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #694 *****\n",
            "Loss: 5.479302\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001910\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 694\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #695 *****\n",
            "Loss: 5.479282\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001913\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 695\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #696 *****\n",
            "Loss: 5.479262\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001915\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 696\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #697 *****\n",
            "Loss: 5.479242\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001918\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 697\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #698 *****\n",
            "Loss: 5.479222\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001921\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 698\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #699 *****\n",
            "Loss: 5.479203\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001924\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 699\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #700 *****\n",
            "Loss: 5.479183\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001926\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 700\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #701 *****\n",
            "Loss: 5.479163\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001929\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 701\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #702 *****\n",
            "Loss: 5.479143\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001932\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 702\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #703 *****\n",
            "Loss: 5.479123\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001935\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 703\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #704 *****\n",
            "Loss: 5.479104\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001937\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 704\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #705 *****\n",
            "Loss: 5.479084\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001940\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 705\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #706 *****\n",
            "Loss: 5.479064\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001943\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 706\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #707 *****\n",
            "Loss: 5.479044\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001946\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 707\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #708 *****\n",
            "Loss: 5.479024\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001948\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 708\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #709 *****\n",
            "Loss: 5.479004\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001951\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 709\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #710 *****\n",
            "Loss: 5.478985\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001954\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 710\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #711 *****\n",
            "Loss: 5.478965\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001957\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 711\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #712 *****\n",
            "Loss: 5.478945\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001959\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 712\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #713 *****\n",
            "Loss: 5.478925\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001962\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 713\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #714 *****\n",
            "Loss: 5.478905\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001965\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 714\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #715 *****\n",
            "Loss: 5.478885\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001968\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 715\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #716 *****\n",
            "Loss: 5.478866\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001970\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 716\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #717 *****\n",
            "Loss: 5.478846\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001973\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 717\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #718 *****\n",
            "Loss: 5.478826\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001976\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 718\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #719 *****\n",
            "Loss: 5.478806\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001979\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 719\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #720 *****\n",
            "Loss: 5.478786\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001981\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 720\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #721 *****\n",
            "Loss: 5.478766\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001984\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 721\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #722 *****\n",
            "Loss: 5.478747\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001987\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 722\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #723 *****\n",
            "Loss: 5.478727\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001990\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 723\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #724 *****\n",
            "Loss: 5.478707\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001992\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 724\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #725 *****\n",
            "Loss: 5.478687\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001995\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 725\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #726 *****\n",
            "Loss: 5.478667\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.001998\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 726\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #727 *****\n",
            "Loss: 5.478648\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002001\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 727\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #728 *****\n",
            "Loss: 5.478628\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002003\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 728\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #729 *****\n",
            "Loss: 5.478608\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002006\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 729\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #730 *****\n",
            "Loss: 5.478588\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002009\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 730\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #731 *****\n",
            "Loss: 5.478568\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002012\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 731\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #732 *****\n",
            "Loss: 5.478548\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002014\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 732\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #733 *****\n",
            "Loss: 5.478529\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002017\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 733\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #734 *****\n",
            "Loss: 5.478509\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002020\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 734\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #735 *****\n",
            "Loss: 5.478489\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002023\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 735\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #736 *****\n",
            "Loss: 5.478469\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002025\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 736\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #737 *****\n",
            "Loss: 5.478449\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002028\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 737\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #738 *****\n",
            "Loss: 5.478429\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002031\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 738\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #739 *****\n",
            "Loss: 5.478410\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002034\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 739\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #740 *****\n",
            "Loss: 5.478390\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002036\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 740\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #741 *****\n",
            "Loss: 5.478370\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002039\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 741\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #742 *****\n",
            "Loss: 5.478350\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002042\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 742\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #743 *****\n",
            "Loss: 5.478330\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002045\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 743\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #744 *****\n",
            "Loss: 5.478311\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002047\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 744\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #745 *****\n",
            "Loss: 5.478291\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002050\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 745\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #746 *****\n",
            "Loss: 5.478271\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002053\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 746\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #747 *****\n",
            "Loss: 5.478251\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002056\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 747\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #748 *****\n",
            "Loss: 5.478231\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002058\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 748\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #749 *****\n",
            "Loss: 5.478211\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002061\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 749\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #750 *****\n",
            "Loss: 5.478192\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002064\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 750\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #751 *****\n",
            "Loss: 5.478172\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002067\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 751\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #752 *****\n",
            "Loss: 5.478152\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002069\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 752\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #753 *****\n",
            "Loss: 5.478132\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002072\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 753\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #754 *****\n",
            "Loss: 5.478112\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002075\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 754\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #755 *****\n",
            "Loss: 5.478092\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002078\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 755\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #756 *****\n",
            "Loss: 5.478073\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002080\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 756\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #757 *****\n",
            "Loss: 5.478053\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002083\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 757\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #758 *****\n",
            "Loss: 5.478033\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002086\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 758\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #759 *****\n",
            "Loss: 5.478013\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002089\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 759\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #760 *****\n",
            "Loss: 5.477993\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002091\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 760\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #761 *****\n",
            "Loss: 5.477974\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002094\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 761\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #762 *****\n",
            "Loss: 5.477954\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002097\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 762\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #763 *****\n",
            "Loss: 5.477934\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002100\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 763\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #764 *****\n",
            "Loss: 5.477914\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002102\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 764\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #765 *****\n",
            "Loss: 5.477894\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002105\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 765\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #766 *****\n",
            "Loss: 5.477874\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002108\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 766\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #767 *****\n",
            "Loss: 5.477855\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002111\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 767\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #768 *****\n",
            "Loss: 5.477835\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002113\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 768\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #769 *****\n",
            "Loss: 5.477815\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002116\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 769\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #770 *****\n",
            "Loss: 5.477795\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002119\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 770\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #771 *****\n",
            "Loss: 5.477775\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002122\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 771\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #772 *****\n",
            "Loss: 5.477756\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002124\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 772\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #773 *****\n",
            "Loss: 5.477736\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002127\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 773\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #774 *****\n",
            "Loss: 5.477716\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002130\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 774\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #775 *****\n",
            "Loss: 5.477696\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002133\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 775\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #776 *****\n",
            "Loss: 5.477676\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002135\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 776\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #777 *****\n",
            "Loss: 5.477656\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002138\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 777\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #778 *****\n",
            "Loss: 5.477637\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002141\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 778\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #779 *****\n",
            "Loss: 5.477617\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002144\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 779\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #780 *****\n",
            "Loss: 5.477597\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002146\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 780\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #781 *****\n",
            "Loss: 5.477577\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002149\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 781\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #782 *****\n",
            "Loss: 5.477557\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002152\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 782\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #783 *****\n",
            "Loss: 5.477537\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002155\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 783\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #784 *****\n",
            "Loss: 5.477518\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002157\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 784\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #785 *****\n",
            "Loss: 5.477498\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002160\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 785\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #786 *****\n",
            "Loss: 5.477478\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002163\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 786\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #787 *****\n",
            "Loss: 5.477458\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002166\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 787\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #788 *****\n",
            "Loss: 5.477438\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002168\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 788\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #789 *****\n",
            "Loss: 5.477419\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002171\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 789\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #790 *****\n",
            "Loss: 5.477399\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002174\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 790\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #791 *****\n",
            "Loss: 5.477379\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002177\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 791\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #792 *****\n",
            "Loss: 5.477359\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002179\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 792\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #793 *****\n",
            "Loss: 5.477339\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002182\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 793\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #794 *****\n",
            "Loss: 5.477319\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002185\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 794\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #795 *****\n",
            "Loss: 5.477300\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002188\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 795\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #796 *****\n",
            "Loss: 5.477280\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002190\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 796\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #797 *****\n",
            "Loss: 5.477260\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002193\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 797\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #798 *****\n",
            "Loss: 5.477240\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002196\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 798\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #799 *****\n",
            "Loss: 5.477220\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002199\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 799\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #800 *****\n",
            "Loss: 5.477201\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002201\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 800\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #801 *****\n",
            "Loss: 5.477181\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002204\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 801\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #802 *****\n",
            "Loss: 5.477161\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002207\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 802\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #803 *****\n",
            "Loss: 5.477141\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002210\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 803\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #804 *****\n",
            "Loss: 5.477121\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002212\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 804\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #805 *****\n",
            "Loss: 5.477101\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002215\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 805\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #806 *****\n",
            "Loss: 5.477082\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002218\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 806\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #807 *****\n",
            "Loss: 5.477062\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002221\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 807\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #808 *****\n",
            "Loss: 5.477042\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002223\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 808\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #809 *****\n",
            "Loss: 5.477022\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002226\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 809\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #810 *****\n",
            "Loss: 5.477002\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002229\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 810\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #811 *****\n",
            "Loss: 5.476983\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002232\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 811\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #812 *****\n",
            "Loss: 5.476963\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002234\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 812\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #813 *****\n",
            "Loss: 5.476943\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002237\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 813\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #814 *****\n",
            "Loss: 5.476923\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002240\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 814\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #815 *****\n",
            "Loss: 5.476903\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002243\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 815\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #816 *****\n",
            "Loss: 5.476883\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002245\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 816\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #817 *****\n",
            "Loss: 5.476864\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002248\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 817\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #818 *****\n",
            "Loss: 5.476844\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002251\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 818\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #819 *****\n",
            "Loss: 5.476824\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002254\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 819\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #820 *****\n",
            "Loss: 5.476804\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002256\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 820\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #821 *****\n",
            "Loss: 5.476784\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002259\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 821\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #822 *****\n",
            "Loss: 5.476765\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002262\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 822\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #823 *****\n",
            "Loss: 5.476745\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002265\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 823\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #824 *****\n",
            "Loss: 5.476725\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002267\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 824\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #825 *****\n",
            "Loss: 5.476705\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002270\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 825\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #826 *****\n",
            "Loss: 5.476685\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002273\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 826\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #827 *****\n",
            "Loss: 5.476666\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002276\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 827\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #828 *****\n",
            "Loss: 5.476646\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002278\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 828\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #829 *****\n",
            "Loss: 5.476626\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002281\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 829\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #830 *****\n",
            "Loss: 5.476606\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002284\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 830\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #831 *****\n",
            "Loss: 5.476586\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002287\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 831\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #832 *****\n",
            "Loss: 5.476566\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002289\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 832\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #833 *****\n",
            "Loss: 5.476547\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002292\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 833\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #834 *****\n",
            "Loss: 5.476527\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002295\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 834\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #835 *****\n",
            "Loss: 5.476507\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002298\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 835\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #836 *****\n",
            "Loss: 5.476487\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002300\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 836\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #837 *****\n",
            "Loss: 5.476467\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002303\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 837\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #838 *****\n",
            "Loss: 5.476448\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002306\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 838\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #839 *****\n",
            "Loss: 5.476428\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002309\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 839\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #840 *****\n",
            "Loss: 5.476408\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002311\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 840\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #841 *****\n",
            "Loss: 5.476388\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002314\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 841\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #842 *****\n",
            "Loss: 5.476368\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002317\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 842\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #843 *****\n",
            "Loss: 5.476348\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002320\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 843\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #844 *****\n",
            "Loss: 5.476329\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002322\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 844\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #845 *****\n",
            "Loss: 5.476309\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002325\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 845\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #846 *****\n",
            "Loss: 5.476289\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002328\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 846\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #847 *****\n",
            "Loss: 5.476269\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002331\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 847\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #848 *****\n",
            "Loss: 5.476249\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002333\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 848\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #849 *****\n",
            "Loss: 5.476230\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002336\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 849\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #850 *****\n",
            "Loss: 5.476210\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002339\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 850\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #851 *****\n",
            "Loss: 5.476190\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002342\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 851\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #852 *****\n",
            "Loss: 5.476170\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002344\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 852\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #853 *****\n",
            "Loss: 5.476150\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002347\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 853\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #854 *****\n",
            "Loss: 5.476131\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002350\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 854\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #855 *****\n",
            "Loss: 5.476111\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002353\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 855\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #856 *****\n",
            "Loss: 5.476091\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002355\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 856\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #857 *****\n",
            "Loss: 5.476071\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002358\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 857\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #858 *****\n",
            "Loss: 5.476051\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002361\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 858\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #859 *****\n",
            "Loss: 5.476031\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002364\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 859\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #860 *****\n",
            "Loss: 5.476012\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002366\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 860\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #861 *****\n",
            "Loss: 5.475992\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002369\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 861\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #862 *****\n",
            "Loss: 5.475972\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002372\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 862\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #863 *****\n",
            "Loss: 5.475952\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002375\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 863\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #864 *****\n",
            "Loss: 5.475932\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002377\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 864\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #865 *****\n",
            "Loss: 5.475913\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002380\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 865\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #866 *****\n",
            "Loss: 5.475893\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002383\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 866\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #867 *****\n",
            "Loss: 5.475873\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002386\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 867\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #868 *****\n",
            "Loss: 5.475853\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002388\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 868\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #869 *****\n",
            "Loss: 5.475833\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002391\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 869\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #870 *****\n",
            "Loss: 5.475813\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002394\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 870\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #871 *****\n",
            "Loss: 5.475794\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002397\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 871\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #872 *****\n",
            "Loss: 5.475774\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002399\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 872\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #873 *****\n",
            "Loss: 5.475754\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002402\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 873\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #874 *****\n",
            "Loss: 5.475734\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002405\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 874\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #875 *****\n",
            "Loss: 5.475714\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002408\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 875\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #876 *****\n",
            "Loss: 5.475695\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002410\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 876\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #877 *****\n",
            "Loss: 5.475675\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002413\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 877\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #878 *****\n",
            "Loss: 5.475655\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002416\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 878\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #879 *****\n",
            "Loss: 5.475635\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002419\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 879\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #880 *****\n",
            "Loss: 5.475615\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002421\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 880\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #881 *****\n",
            "Loss: 5.475596\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002424\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 881\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #882 *****\n",
            "Loss: 5.475576\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002427\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 882\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #883 *****\n",
            "Loss: 5.475556\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002430\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 883\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #884 *****\n",
            "Loss: 5.475536\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002432\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 884\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #885 *****\n",
            "Loss: 5.475516\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002435\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 885\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #886 *****\n",
            "Loss: 5.475497\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002438\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 886\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #887 *****\n",
            "Loss: 5.475477\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002441\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 887\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #888 *****\n",
            "Loss: 5.475457\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002443\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 888\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #889 *****\n",
            "Loss: 5.475437\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002446\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 889\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #890 *****\n",
            "Loss: 5.475417\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002449\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 890\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #891 *****\n",
            "Loss: 5.475397\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002452\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 891\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #892 *****\n",
            "Loss: 5.475378\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002454\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 892\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #893 *****\n",
            "Loss: 5.475358\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002457\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 893\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #894 *****\n",
            "Loss: 5.475338\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002460\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 894\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #895 *****\n",
            "Loss: 5.475318\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002463\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 895\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #896 *****\n",
            "Loss: 5.475298\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002465\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 896\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #897 *****\n",
            "Loss: 5.475279\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002468\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 897\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #898 *****\n",
            "Loss: 5.475259\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002471\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 898\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #899 *****\n",
            "Loss: 5.475239\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002474\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 899\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #900 *****\n",
            "Loss: 5.475219\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002476\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 900\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #901 *****\n",
            "Loss: 5.475199\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002479\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 901\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #902 *****\n",
            "Loss: 5.475180\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002482\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 902\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #903 *****\n",
            "Loss: 5.475160\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002485\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 903\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #904 *****\n",
            "Loss: 5.475140\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002487\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 904\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #905 *****\n",
            "Loss: 5.475120\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002490\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 905\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #906 *****\n",
            "Loss: 5.475100\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002493\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 906\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #907 *****\n",
            "Loss: 5.475080\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002496\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 907\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #908 *****\n",
            "Loss: 5.475061\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002498\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 908\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #909 *****\n",
            "Loss: 5.475041\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002501\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 909\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #910 *****\n",
            "Loss: 5.475021\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002504\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 910\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #911 *****\n",
            "Loss: 5.475001\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002507\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 911\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #912 *****\n",
            "Loss: 5.474981\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002509\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 912\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #913 *****\n",
            "Loss: 5.474962\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002512\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 913\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #914 *****\n",
            "Loss: 5.474942\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002515\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 914\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #915 *****\n",
            "Loss: 5.474922\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002518\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 915\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #916 *****\n",
            "Loss: 5.474902\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002520\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 916\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #917 *****\n",
            "Loss: 5.474882\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002523\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 917\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #918 *****\n",
            "Loss: 5.474863\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002526\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 918\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #919 *****\n",
            "Loss: 5.474843\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002529\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 919\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #920 *****\n",
            "Loss: 5.474823\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002531\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 920\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #921 *****\n",
            "Loss: 5.474803\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002534\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 921\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #922 *****\n",
            "Loss: 5.474783\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002537\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 922\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #923 *****\n",
            "Loss: 5.474764\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002540\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 923\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #924 *****\n",
            "Loss: 5.474744\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002542\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 924\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #925 *****\n",
            "Loss: 5.474724\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002545\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 925\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #926 *****\n",
            "Loss: 5.474704\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002548\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 926\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #927 *****\n",
            "Loss: 5.474684\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002551\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 927\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #928 *****\n",
            "Loss: 5.474665\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002553\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 928\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #929 *****\n",
            "Loss: 5.474645\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002556\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 929\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #930 *****\n",
            "Loss: 5.474625\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002559\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 930\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #931 *****\n",
            "Loss: 5.474605\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002562\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 931\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #932 *****\n",
            "Loss: 5.474585\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002564\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 932\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #933 *****\n",
            "Loss: 5.474565\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002567\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 933\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #934 *****\n",
            "Loss: 5.474546\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002570\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 934\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #935 *****\n",
            "Loss: 5.474526\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002573\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 935\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #936 *****\n",
            "Loss: 5.474506\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002575\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 936\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #937 *****\n",
            "Loss: 5.474486\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002578\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 937\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #938 *****\n",
            "Loss: 5.474466\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002581\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 938\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #939 *****\n",
            "Loss: 5.474447\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002584\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 939\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #940 *****\n",
            "Loss: 5.474427\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002586\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 940\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #941 *****\n",
            "Loss: 5.474407\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002589\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 941\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #942 *****\n",
            "Loss: 5.474387\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002592\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 942\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #943 *****\n",
            "Loss: 5.474367\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002595\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 943\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #944 *****\n",
            "Loss: 5.474348\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002597\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 944\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #945 *****\n",
            "Loss: 5.474328\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002600\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 945\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #946 *****\n",
            "Loss: 5.474308\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002603\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 946\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #947 *****\n",
            "Loss: 5.474288\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002606\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 947\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #948 *****\n",
            "Loss: 5.474268\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002608\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 948\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #949 *****\n",
            "Loss: 5.474249\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002611\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 949\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #950 *****\n",
            "Loss: 5.474229\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002614\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 950\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #951 *****\n",
            "Loss: 5.474209\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002617\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 951\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #952 *****\n",
            "Loss: 5.474189\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002619\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 952\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #953 *****\n",
            "Loss: 5.474169\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002622\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 953\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #954 *****\n",
            "Loss: 5.474150\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002625\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 954\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #955 *****\n",
            "Loss: 5.474130\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002628\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 955\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #956 *****\n",
            "Loss: 5.474110\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002630\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 956\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #957 *****\n",
            "Loss: 5.474090\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002633\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 957\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #958 *****\n",
            "Loss: 5.474070\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002636\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 958\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #959 *****\n",
            "Loss: 5.474050\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002639\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 959\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #960 *****\n",
            "Loss: 5.474031\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002641\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 960\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #961 *****\n",
            "Loss: 5.474011\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002644\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 961\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #962 *****\n",
            "Loss: 5.473991\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002647\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 962\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #963 *****\n",
            "Loss: 5.473971\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002650\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 963\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #964 *****\n",
            "Loss: 5.473951\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002652\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 964\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #965 *****\n",
            "Loss: 5.473932\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002655\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 965\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #966 *****\n",
            "Loss: 5.473912\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002658\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 966\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #967 *****\n",
            "Loss: 5.473892\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002661\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 967\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #968 *****\n",
            "Loss: 5.473872\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002663\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 968\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #969 *****\n",
            "Loss: 5.473852\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002666\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 969\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #970 *****\n",
            "Loss: 5.473833\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002669\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 970\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #971 *****\n",
            "Loss: 5.473813\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002672\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 971\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #972 *****\n",
            "Loss: 5.473793\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002674\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 972\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #973 *****\n",
            "Loss: 5.473773\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002677\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 973\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #974 *****\n",
            "Loss: 5.473753\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002680\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 974\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #975 *****\n",
            "Loss: 5.473734\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002683\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 975\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #976 *****\n",
            "Loss: 5.473714\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002685\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 976\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #977 *****\n",
            "Loss: 5.473694\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002688\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 977\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #978 *****\n",
            "Loss: 5.473674\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002691\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 978\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #979 *****\n",
            "Loss: 5.473654\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002694\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 979\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #980 *****\n",
            "Loss: 5.473635\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002696\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 980\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #981 *****\n",
            "Loss: 5.473615\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002699\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 981\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #982 *****\n",
            "Loss: 5.473595\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002702\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 982\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #983 *****\n",
            "Loss: 5.473575\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002705\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 983\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #984 *****\n",
            "Loss: 5.473555\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002707\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 984\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #985 *****\n",
            "Loss: 5.473536\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002710\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 985\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #986 *****\n",
            "Loss: 5.473516\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002713\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 986\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #987 *****\n",
            "Loss: 5.473496\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002716\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 987\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #988 *****\n",
            "Loss: 5.473476\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002718\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 988\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #989 *****\n",
            "Loss: 5.473456\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002721\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 989\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #990 *****\n",
            "Loss: 5.473437\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002724\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 990\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #991 *****\n",
            "Loss: 5.473417\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002727\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 991\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #992 *****\n",
            "Loss: 5.473397\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002729\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 992\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #993 *****\n",
            "Loss: 5.473377\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002732\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 993\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #994 *****\n",
            "Loss: 5.473357\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002735\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 994\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #995 *****\n",
            "Loss: 5.473338\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002738\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 995\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #996 *****\n",
            "Loss: 5.473318\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002740\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 996\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #997 *****\n",
            "Loss: 5.473298\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002743\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 997\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #998 *****\n",
            "Loss: 5.473278\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002746\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 998\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #999 *****\n",
            "Loss: 5.473258\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002749\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 999\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "***** Epoch #1000 *****\n",
            "Loss: 5.473239\n",
            "Improvement ratio: 0.000036\n",
            "Feature L2-norm: 0.002751\n",
            "Learning rate (eta): 0.000000\n",
            "Total number of feature updates: 1000\n",
            "Seconds required for this iteration: 0.000\n",
            "\n",
            "SGD terminated with the maximum number of iterations\n",
            "Loss: 5.473239\n",
            "Total seconds required for training: 0.203\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 117 (117)\n",
            "Number of active attributes: 105 (105)\n",
            "Number of active labels: 3 (3)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dCxf7HcAn5P"
      },
      "source": [
        "# See on meie testkorpus - ei kattu treeningkorpusega\n",
        "text2 = Text('Läti president elab Riias.').tag_layer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbyRU20wAn5c",
        "outputId": "ec727d2a-a276-496d-d104-cdb1ebab0d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "# Standardne NER-tagger leiab asukohad\n",
        "ner_tagger.tag(text2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td><div align = \"left\">Läti president elab Riias.</div></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>sentences</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>tokens</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>compound_tokens</td>\n",
              "      <td>type, normalized</td>\n",
              "      <td>None</td>\n",
              "      <td>tokens</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>words</td>\n",
              "      <td>normalized_form</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
              "      <td>words</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>ner</td>\n",
              "      <td>nertag</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Text(text='Läti president elab Riias.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRoJIeCNAn5k",
        "outputId": "4089fabe-10f0-48c5-b8a9-321f9ac6b5af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "text2.ner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>ner</td>\n",
              "      <td>nertag</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>nertag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['Läti']</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['Riias']</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='ner', attributes=('nertag',), spans=SL[EnvelopingSpan(['Läti'], [{'nertag': 'LOC'}]),\n",
              "EnvelopingSpan(['Riias'], [{'nertag': 'LOC'}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBgO57qqAn5t"
      },
      "source": [
        "# Loome uue NER-taggeri oma loodud 'test' mudeli põhjal\n",
        "# Anname väljundkihile nimeks ner2, \n",
        "# sest ner kiht on juba meie tekstil olemas\n",
        "ner_tagger2 = NerTagger(model_dir = 'test', output_layer = 'ner2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAznRCoEAn50",
        "outputId": "9adf59ba-472f-4e4d-bd50-a61c505ecc14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "ner_tagger2.tag(text2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td><div align = \"left\">Läti president elab Riias.</div></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>sentences</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>tokens</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>compound_tokens</td>\n",
              "      <td>type, normalized</td>\n",
              "      <td>None</td>\n",
              "      <td>tokens</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>words</td>\n",
              "      <td>normalized_form</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>morph_analysis</td>\n",
              "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
              "      <td>words</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>ner</td>\n",
              "      <td>nertag</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>ner2</td>\n",
              "      <td>nertag</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Text(text='Läti president elab Riias.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb2nQnupAn58",
        "outputId": "dcb33e0e-0878-4ac7-93c2-5ea00d9062fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "text2.ner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>ner</td>\n",
              "      <td>nertag</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>nertag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['Läti']</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['Riias']</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='ner', attributes=('nertag',), spans=SL[EnvelopingSpan(['Läti'], [{'nertag': 'LOC'}]),\n",
              "EnvelopingSpan(['Riias'], [{'nertag': 'LOC'}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "breBzS2VAn6E",
        "outputId": "50026071-6201-430d-ad36-88dd0787ac38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "text2.ner2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h4>Layer</h4>\n",
              "\n",
              "\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>layer name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>parent</th>\n",
              "      <th>enveloping</th>\n",
              "      <th>ambiguous</th>\n",
              "      <th>span count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>ner2</td>\n",
              "      <td>nertag</td>\n",
              "      <td>None</td>\n",
              "      <td>words</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>nertag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>['Läti']</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['president']</td>\n",
              "      <td>VOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>['Riias']</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "Layer(name='ner2', attributes=('nertag',), spans=SL[EnvelopingSpan(['Läti'], [{'nertag': 'LOC'}]),\n",
              "EnvelopingSpan(['president'], [{'nertag': 'VOC'}]),\n",
              "EnvelopingSpan(['Riias'], [{'nertag': 'LOC'}])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHxjcVnUAn6N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVIQ3AHUAn6X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}