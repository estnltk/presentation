{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Use [RISE](https://github.com/damianavila/RISE) to display the slides.\n",
    "\n",
    "```bash\n",
    "pip install RISE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<H1 style=\"text-align: center;\">\n",
    "Tekstitöötluse põhietapid\n",
    "</H1>\n",
    "\n",
    "<H4 style=\"text-align: center;\">\n",
    "Dage Särg\n",
    "</H4>\n",
    "\n",
    "<H4 style=\"text-align: center;\">\n",
    "Automaatne info eraldamine eestikeelsest tekstist. 08.10.2020\n",
    "</H4>\n",
    "\n",
    "<H4 style=\"text-align: center;\">\n",
    "Notebook: https://tinyurl.com/nlp-notebook\n",
    "</H4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Colab 101:\n",
    "\n",
    "Google Colaboratory on veebipõhine keskkond, kus on mugav jooksutada Pythoni koodi ning jagada seda ka teistega.\n",
    "Enda arvutisse midagi installida pole tarvis, piisab, kui omad Google kontot ja logid veebibrauseri kaudu sisse.\n",
    "\n",
    "Colabi kasutamiseks:\n",
    "* Ava käesolev notebook oma arvutis (https://tinyurl.com/nlp-notebook) \n",
    "* Logi oma google'i kontoga sisse (kui pole veel loginud)\n",
    "* Salvesta käesolev märkmik enda Google Drive kettale, valides _File_ menüüst -> _Save a copy in Drive_.\n",
    "* Ja saadki asuda katsetama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"põhietapid.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"seg2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Teksti segmenteerimine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Festivalil osales üle 30 000 muusikahuvilise.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Festivalil osales üle 30 000 muusikahuvilise.')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "# Teksti töötlemiseks peame tegema stringi Text objektiks\n",
    "text = Text(\"Festivalil osales üle 30 000 muusikahuvilise.\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Festivalil osales üle 30 000 muusikahuvilise.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Festivalil osales üle 30 000 muusikahuvilise.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag_layer() meetod märgib peale standardsed analüüsikihid,\n",
    "# mida on vaja pea kõigi keeletöötlusülesannete juures\n",
    "text.tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Festivalil osales üle 30 000 muusikahuvilise.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Festivalil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>osales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>üle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muusikahuvilise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Festivalil', [{}]),\n",
       "Span('osales', [{}]),\n",
       "Span('üle', [{}]),\n",
       "Span('30', [{}]),\n",
       "Span('000', [{}]),\n",
       "Span('muusikahuvilise', [{}]),\n",
       "Span('.', [{}])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokens e sõned - mitte alati lingvistiliselt motiveeritud\n",
    "text.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Festivalil</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>osales</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>üle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30 000</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muusikahuvilise</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Festivalil', [{'normalized_form': None}]),\n",
       "Span('osales', [{'normalized_form': None}]),\n",
       "Span('üle', [{'normalized_form': None}]),\n",
       "Span('30 000', [{'normalized_form': '30000'}]),\n",
       "Span('muusikahuvilise', [{'normalized_form': None}]),\n",
       "Span('.', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words e sõnad - mõned tokenid ühendatakse edasiseks töötluseks kokku\n",
    "text.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"seg3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>clause_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Nendel', 'on', 'ettekujutus', ',']</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[',', 'kes', 'minu', 'ja', 'Oudekki', 'kaotusele', 'loodavad', ',']</td>\n",
       "      <td>embedded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['et', 'rahval', 'polegi', 'hääli', '.']</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='clauses', attributes=('clause_type',), spans=SL[EnvelopingSpan(['Nendel', 'on', 'ettekujutus', ','], [{'clause_type': 'regular'}]),\n",
       "EnvelopingSpan([',', 'kes', 'minu', 'ja', 'Oudekki', 'kaotusele', 'loodavad', ','], [{'clause_type': 'embedded'}]),\n",
       "EnvelopingSpan(['et', 'rahval', 'polegi', 'hääli', '.'], [{'clause_type': 'regular'}])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On võimalik märgendada ka osalauseid\n",
    "text = Text('Nendel, kes minu ja Oudekki kaotusele loodavad, \\\n",
    "on ettekujutus, et rahval polegi hääli.')\n",
    "\n",
    "text.tag_layer(['clauses'])\n",
    "text.clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"seg4.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Tartu', 'Rattaralli', 'toimub', '29.', 'mail', '2020.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Tartu', 'Rattaralli', 'stardi-', 'ja', 'finišipaik', 'on', 'traditsiooniliselt ..., type: &lt;class 'list'&gt;, length: 13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='sentences', attributes=(), spans=SL[EnvelopingSpan(['Tartu', 'Rattaralli', 'toimub', '29.', 'mail', '2020.'], [{}]),\n",
       "EnvelopingSpan(['Tartu', 'Rattaralli', 'stardi-', 'ja', 'finišipaik', 'on', 'traditsiooniliselt', 'Tartu', 'kesklinnas', ',', 'Turu', 'tänaval', '.'], [{}])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Laused - punkt ei toimi alati eraldajana\n",
    "text = Text('Tartu Rattaralli toimub 29. mail 2020. \\\n",
    "Tartu Rattaralli stardi- ja finišipaik \\\n",
    "on traditsiooniliselt Tartu kesklinnas, Turu tänaval.')\n",
    "text.tag_layer()\n",
    "text.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lause:  Tartu Rattaralli toimub 29. mail 2020.\n",
      "Tartu H\n",
      "Rattaralli S\n",
      "toimub V\n",
      "29. O\n",
      "mail S\n",
      "2020. O\n",
      "\n",
      " Lause:  Tartu Rattaralli stardi- ja finišipaik on traditsiooniliselt Tartu kesklinnas, Turu tänaval.\n",
      "Tartu H\n",
      "Rattaralli S\n",
      "stardi- S\n",
      "ja J\n",
      "finišipaik S\n",
      "on V\n",
      "traditsiooniliselt D\n",
      "Tartu H\n",
      "kesklinnas S\n",
      ", Z\n",
      "Turu H\n",
      "tänaval S\n",
      ". Z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tekst koosneb lausetest, mis koosnevad omakorda sõnadest\n",
    "for sentence in text.sentences:\n",
    "    print(' Lause: ', sentence.enclosing_text)\n",
    "    for word in sentence:\n",
    "        # Väljastame sõna ja sõnaliigi\n",
    "        print( word.text, word.morph_analysis.partofspeech[0] )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Lemmatiseerimine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"oad.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>uba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>tegema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>uba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>võima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>salat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>panema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['mis', 'mis'], ['uba'], ['tegema'], ['?'], ['uba'], ['võima'], ['salat'], ['panema'], ['.']], ('lemma',))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Morf analüüs eesti keele puhul baassamm \n",
    "t = Text('Mida ubadest teha? Oad võib salatisse panna.').tag_layer()\n",
    "t.lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"k2rbes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"morf1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"morf2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mida</td>\n",
       "      <td>Mida</td>\n",
       "      <td>mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>['mis']</td>\n",
       "      <td>da</td>\n",
       "      <td></td>\n",
       "      <td>pl p</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Mida</td>\n",
       "      <td>mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>['mis']</td>\n",
       "      <td>da</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ubadest</td>\n",
       "      <td>ubadest</td>\n",
       "      <td>uba</td>\n",
       "      <td>uba</td>\n",
       "      <td>['uba']</td>\n",
       "      <td>dest</td>\n",
       "      <td></td>\n",
       "      <td>pl el</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teha</td>\n",
       "      <td>teha</td>\n",
       "      <td>tegema</td>\n",
       "      <td>tege</td>\n",
       "      <td>['tege']</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>da</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>['?']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Oad</td>\n",
       "      <td>Oad</td>\n",
       "      <td>uba</td>\n",
       "      <td>uba</td>\n",
       "      <td>['uba']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võib</td>\n",
       "      <td>võib</td>\n",
       "      <td>võima</td>\n",
       "      <td>või</td>\n",
       "      <td>['või']</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>salatisse</td>\n",
       "      <td>salatisse</td>\n",
       "      <td>salat</td>\n",
       "      <td>salat</td>\n",
       "      <td>['salat']</td>\n",
       "      <td>sse</td>\n",
       "      <td></td>\n",
       "      <td>sg ill</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>panna</td>\n",
       "      <td>panna</td>\n",
       "      <td>panema</td>\n",
       "      <td>pane</td>\n",
       "      <td>['pane']</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>da</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Mida', [{'normalized_text': 'Mida', 'lemma': 'mis', 'root': 'mis', 'root_tokens': ['mis'], 'ending': 'da', 'clitic': '', 'form': 'pl p', 'partofspeech': 'P'}, {'normalized_text': 'Mida', 'lemma': 'mis', 'root': 'mis', 'root_tokens': ['mis'], 'ending': 'da', 'clitic': '', 'form': 'sg p', 'partofspeech': 'P'}]),\n",
       "Span('ubadest', [{'normalized_text': 'ubadest', 'lemma': 'uba', 'root': 'uba', 'root_tokens': ['uba'], 'ending': 'dest', 'clitic': '', 'form': 'pl el', 'partofspeech': 'S'}]),\n",
       "Span('teha', [{'normalized_text': 'teha', 'lemma': 'tegema', 'root': 'tege', 'root_tokens': ['tege'], 'ending': 'a', 'clitic': '', 'form': 'da', 'partofspeech': 'V'}]),\n",
       "Span('?', [{'normalized_text': '?', 'lemma': '?', 'root': '?', 'root_tokens': ['?'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Oad', [{'normalized_text': 'Oad', 'lemma': 'uba', 'root': 'uba', 'root_tokens': ['uba'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('võib', [{'normalized_text': 'võib', 'lemma': 'võima', 'root': 'või', 'root_tokens': ['või'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
       "Span('salatisse', [{'normalized_text': 'salatisse', 'lemma': 'salat', 'root': 'salat', 'root_tokens': ['salat'], 'ending': 'sse', 'clitic': '', 'form': 'sg ill', 'partofspeech': 'S'}]),\n",
       "Span('panna', [{'normalized_text': 'panna', 'lemma': 'panema', 'root': 'pane', 'root_tokens': ['pane'], 'ending': 'a', 'clitic': '', 'form': 'da', 'partofspeech': 'V'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Morf analüüs eesti keele puhul baassamm \n",
    "t = Text('Mida ubadest teha? Oad võib salatisse panna.').tag_layer()\n",
    "t.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeTupleList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mida</td>\n",
       "      <td>mis</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Mida</td>\n",
       "      <td>mis</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ubadest</td>\n",
       "      <td>uba</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>teha</td>\n",
       "      <td>tegema</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Oad</td>\n",
       "      <td>uba</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>võib</td>\n",
       "      <td>võima</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>salatisse</td>\n",
       "      <td>salat</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>panna</td>\n",
       "      <td>panema</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeTupleList([[['Mida', 'mis', 'P'], ['Mida', 'mis', 'P']], [['ubadest', 'uba', 'S']], [['teha', 'tegema', 'V']], [['?', '?', 'Z']], [['Oad', 'uba', 'S']], [['võib', 'võima', 'V']], [['salatisse', 'salat', 'S']], [['panna', 'panema', 'V']], [['.', '.', 'Z']]], ('text', 'lemma', 'partofspeech'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Võime vaadata ka vaid parajasti huvitavaid atribuute, mitte kogu analüüsi\n",
    "t.morph_analysis['text', 'lemma', 'partofspeech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Näide: leiame kõik tekstis olevad nimisõnad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text = Text('Nagu nimigi reedab, on nurgasaag kõige \\\n",
    "tõhusam tööriist erinevate puitdetailide lõikamiseks, \\\n",
    "kus eesmärgiks on saavutada täpne lõikenurk ning oluline on \\\n",
    "lõikenurga seadistamise võimalus. Näiteks pildiraamide \\\n",
    "meisterdamisel, kus on oluline, et detailide lõikenurgad \\\n",
    "oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag \\\n",
    "täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. \\\n",
    "Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise \\\n",
    "lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned \\\n",
    "saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks \\\n",
    "keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka \\\n",
    "kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide \\\n",
    "ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks \\\n",
    "puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade \\\n",
    "või puitparketi paigaldamisel.')\n",
    "my_text.tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nurgasaag', 4),\n",
       " ('lõikenurk', 4),\n",
       " ('näide', 3),\n",
       " ('tööriist', 2),\n",
       " ('puitdetail', 2),\n",
       " ('lõikamine', 2),\n",
       " ('seadistamine', 2),\n",
       " ('detail', 2),\n",
       " ('nimi', 1),\n",
       " ('eesmärk', 1),\n",
       " ('võimalus', 1),\n",
       " ('pildiraam', 1),\n",
       " ('meisterdamine', 1),\n",
       " ('kraad', 1),\n",
       " ('juht', 1),\n",
       " ('täpsus', 1),\n",
       " ('lõige', 1),\n",
       " ('korratavus', 1),\n",
       " ('osa', 1),\n",
       " ('suund', 1),\n",
       " ('lisa', 1),\n",
       " ('saag', 1),\n",
       " ('saetera', 1),\n",
       " ('kaldenurk', 1),\n",
       " ('kasu', 1),\n",
       " ('laius', 1),\n",
       " ('puulaud', 1),\n",
       " ('ristlõige', 1),\n",
       " ('tegemine', 1),\n",
       " ('järkamine', 1),\n",
       " ('puitkonstruktsioon', 1),\n",
       " ('ehitamine', 1),\n",
       " ('terrassilaud', 1),\n",
       " ('puitparkett', 1),\n",
       " ('paigaldamine', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_lemmas = []\n",
    "for lemmas, postags in zip(my_text.lemma, my_text.partofspeech):\n",
    "    if 'S' in postags: # text.lemma ja partofspeech on listid, kuna analüüse võib olla mitu\n",
    "        noun_lemmas += lemmas\n",
    "noun_lemmas  \n",
    "\n",
    "from collections import Counter\n",
    "Counter(noun_lemmas).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Näide: leiame kõik infinitiivset verbi sisaldavad laused:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infinitive_sentences = []\n",
    "for sent in my_text.sentences: # vaatame teksti lause kaupa\n",
    "    for form in sent.form: # vaatame läbi kõik lause sõnade vormiinfod\n",
    "        if 'da' in form:\n",
    "            a = sent.enclosing_text # lause tekst stringina\n",
    "            infinitive_sentences.append(a)\n",
    "            break\n",
    "infinitive_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4. Süntaktiline analüüs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"synt1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"synt2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"synt3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"synt4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"synt5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"synt6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Märgendajad e taggerid\n",
    "#### võimaldavad vajadusel lisada kihte, mida läheb vaja mingis konkreetses analüüsitöövoos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags dependency syntactic analysis with MaltParser.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>MaltParserTagger</td>\n",
       "      <td>maltparser_syntax</td>\n",
       "      <td>('id', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc', 'parent_span', 'children')</td>\n",
       "      <td>('words', 'sentences', 'conll_morph')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>add_parent_and_children</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syntax_dependency_retagger</th>\n",
       "      <td>SyntaxDependencyRetagger(('maltparser_syntax',)-&gt;maltparser_syntax)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "MaltParserTagger(input_layers=('words', 'sentences', 'conll_morph'), output_layer=maltparser_syntax, output_attributes=('id', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc', ..., type: <class 'tuple'>, length: 11, add_parent_and_children=True, syntax_dependency_retagger=SyntaxDependencyRetagger(('maltparser_syntax',)->maltparser_syntax))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# süntaksi tagger\n",
    "from estnltk.taggers import MaltParserTagger\n",
    "maltparser_tagger = MaltParserTagger()\n",
    "maltparser_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "From morph_extended towards conll_syntax\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ConllMorphTagger</td>\n",
       "      <td>conll_morph</td>\n",
       "      <td>('id', 'form', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc')</td>\n",
       "      <td>('sentences', 'morph_extended')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "No configuration parameters."
      ],
      "text/plain": [
       "ConllMorphTagger()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import ConllMorphTagger\n",
    "conllmorph_tagger = ConllMorphTagger()\n",
    "conllmorph_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Poe ees õlut joonud mehed häirisid kohalikke, aga ükskõikne politsei ei teinud midagi.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_extended</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, punctuation_type, pronoun_type, letter_case, fin, verb_extension_suffix, subcat</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>conll_morph</td>\n",
       "      <td>id, form, lemma, upostag, xpostag, feats, head, deprel, deps, misc</td>\n",
       "      <td>morph_extended</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Poe ees õlut joonud mehed häirisid kohalikke, aga ükskõikne politsei ei teinud midagi.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lisame default_layers kihid\n",
    "text = Text('Poe ees õlut joonud mehed häirisid kohalikke, aga ükskõikne politsei ei teinud midagi.').tag_layer(['sentences', 'words', 'morph_extended'])\n",
    "\n",
    "# Lisame conll_morph kihi\n",
    "conllmorph_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>maltparser_syntax</td>\n",
       "      <td>id, lemma, upostag, xpostag, feats, head, deprel, deps, misc, parent_span, children</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>feats</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>deps</th>\n",
       "      <th>misc</th>\n",
       "      <th>parent_span</th>\n",
       "      <th>children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Poe</td>\n",
       "      <td>1</td>\n",
       "      <td>pood</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>OrderedDict([('sg', ''), ('gen', '')])</td>\n",
       "      <td>2</td>\n",
       "      <td>@P&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('ees', [{'id': 2, 'lemma': 'ees', 'upostag': 'K', 'xpostag': 'Kt', 'feats': ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ees</td>\n",
       "      <td>2</td>\n",
       "      <td>ees</td>\n",
       "      <td>K</td>\n",
       "      <td>Kt</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>@ADVL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('joonud', [{'id': 4, 'lemma': 'joo=nud', 'upostag': 'A', 'xpostag': 'A', 'f ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>(\"Span('Poe', [{'id': 1, 'lemma': 'pood', 'upostag': 'S', 'xpostag': 'S', 'feats ..., type: &lt;class 'tuple'&gt;, length: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õlut</td>\n",
       "      <td>3</td>\n",
       "      <td>õlu</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>OrderedDict([('sg', ''), ('part', '')])</td>\n",
       "      <td>4</td>\n",
       "      <td>@OBJ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('joonud', [{'id': 4, 'lemma': 'joo=nud', 'upostag': 'A', 'xpostag': 'A', 'f ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>joonud</td>\n",
       "      <td>4</td>\n",
       "      <td>joo=nud</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>OrderedDict([('partic', '')])</td>\n",
       "      <td>5</td>\n",
       "      <td>@AN&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('mehed', [{'id': 5, 'lemma': 'mees', 'upostag': 'S', 'xpostag': 'S', 'feats ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>(\"Span('ees', [{'id': 2, 'lemma': 'ees', 'upostag': 'K', 'xpostag': 'Kt', 'feats ..., type: &lt;class 'tuple'&gt;, length: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mehed</td>\n",
       "      <td>5</td>\n",
       "      <td>mees</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>OrderedDict([('pl', ''), ('nom', '')])</td>\n",
       "      <td>6</td>\n",
       "      <td>@SUBJ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('häirisid', [{'id': 6, 'lemma': 'häiri', 'upostag': 'V', 'xpostag': 'V', 'f ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>(\"Span('joonud', [{'id': 4, 'lemma': 'joo=nud', 'upostag': 'A', 'xpostag': 'A',  ..., type: &lt;class 'tuple'&gt;, length: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>häirisid</td>\n",
       "      <td>6</td>\n",
       "      <td>häiri</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>OrderedDict([('indic', ''), ('impf', ''), ('ps3', ''), ('pl', '')])</td>\n",
       "      <td>0</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(\"Span('mehed', [{'id': 5, 'lemma': 'mees', 'upostag': 'S', 'xpostag': 'S', 'fea ..., type: &lt;class 'tuple'&gt;, length: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kohalikke</td>\n",
       "      <td>7</td>\n",
       "      <td>kohalik</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>OrderedDict([('pl', ''), ('part', '')])</td>\n",
       "      <td>0</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(\"Span(',', [{'id': 8, 'lemma': ',', 'upostag': 'Z', 'xpostag': 'Z', 'feats': Or ..., type: &lt;class 'tuple'&gt;, length: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>8</td>\n",
       "      <td>,</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>OrderedDict([('Com', '')])</td>\n",
       "      <td>7</td>\n",
       "      <td>@Punc</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('kohalikke', [{'id': 7, 'lemma': 'kohalik', 'upostag': 'A', 'xpostag': 'A', ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aga</td>\n",
       "      <td>9</td>\n",
       "      <td>aga</td>\n",
       "      <td>J</td>\n",
       "      <td>Jc</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>@J</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'fea ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ükskõikne</td>\n",
       "      <td>10</td>\n",
       "      <td>üks_kõikne</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>OrderedDict([('sg', ''), ('nom', '')])</td>\n",
       "      <td>11</td>\n",
       "      <td>@AN&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('politsei', [{'id': 11, 'lemma': 'politsei', 'upostag': 'S', 'xpostag': 'S' ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>politsei</td>\n",
       "      <td>11</td>\n",
       "      <td>politsei</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>OrderedDict([('sg', ''), ('nom', '')])</td>\n",
       "      <td>13</td>\n",
       "      <td>@SUBJ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'fea ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>(\"Span('ükskõikne', [{'id': 10, 'lemma': 'üks_kõikne', 'upostag': 'A', 'xpostag' ..., type: &lt;class 'tuple'&gt;, length: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>12</td>\n",
       "      <td>ei</td>\n",
       "      <td>V</td>\n",
       "      <td>Vaux</td>\n",
       "      <td>OrderedDict([('neg', '')])</td>\n",
       "      <td>13</td>\n",
       "      <td>@NEG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'fea ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teinud</td>\n",
       "      <td>13</td>\n",
       "      <td>tege</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>OrderedDict([('indic', ''), ('impf', ''), ('neg', '')])</td>\n",
       "      <td>7</td>\n",
       "      <td>@FMV</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('kohalikke', [{'id': 7, 'lemma': 'kohalik', 'upostag': 'A', 'xpostag': 'A', ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>(\"Span('aga', [{'id': 9, 'lemma': 'aga', 'upostag': 'J', 'xpostag': 'Jc', 'feats ..., type: &lt;class 'tuple'&gt;, length: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>midagi</td>\n",
       "      <td>14</td>\n",
       "      <td>miski</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>OrderedDict([('intrel', ''), ('sg', ''), ('part', '')])</td>\n",
       "      <td>13</td>\n",
       "      <td>@OBJ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'fea ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>(\"Span('.', [{'id': 15, 'lemma': '.', 'upostag': 'Z', 'xpostag': 'Z', 'feats': O ..., type: &lt;class 'tuple'&gt;, length: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>15</td>\n",
       "      <td>.</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>OrderedDict([('Fst', '')])</td>\n",
       "      <td>14</td>\n",
       "      <td>@Punc</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Span('midagi', [{'id': 14, 'lemma': 'miski', 'upostag': 'P', 'xpostag': 'P', 'fe ..., type: &lt;class 'estnltk.layer.span.Span'&gt;</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='maltparser_syntax', attributes=('id', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc', 'parent_span', 'children'), spans=SL[Span('Poe', [{'id': 1, 'lemma': 'pood', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('gen', '')]), 'head': 2, 'deprel': '@P>', 'deps': None, 'misc': None, 'parent_span': Span('ees', [{'id': 2, 'lemma': 'ees', 'upostag': 'K', 'xpostag': 'Kt', 'feats': None, 'head': 4, 'deprel': '@ADVL', 'deps': None, 'misc': None, 'parent_span': Span('joonud', [{'id': 4, 'lemma': 'joo=nud', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('partic', '')]), 'head': 5, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': Span('mehed', [{'id': 5, 'lemma': 'mees', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', ''), ('nom', '')]), 'head': 6, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': Span('häirisid', [{'id': 6, 'lemma': 'häiri', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('ps3', ''), ('pl', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (...,)}]), 'children': (...,)}]), 'children': (..., Span('õlut', [{'id': 3, 'lemma': 'õlu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('part', '')]), 'head': 4, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]))}]), 'children': (...,)}]), 'children': ()}]),\n",
       "Span('ees', [{'id': 2, 'lemma': 'ees', 'upostag': 'K', 'xpostag': 'Kt', 'feats': None, 'head': 4, 'deprel': '@ADVL', 'deps': None, 'misc': None, 'parent_span': Span('joonud', [{'id': 4, 'lemma': 'joo=nud', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('partic', '')]), 'head': 5, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': Span('mehed', [{'id': 5, 'lemma': 'mees', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', ''), ('nom', '')]), 'head': 6, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': Span('häirisid', [{'id': 6, 'lemma': 'häiri', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('ps3', ''), ('pl', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (...,)}]), 'children': (...,)}]), 'children': (..., Span('õlut', [{'id': 3, 'lemma': 'õlu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('part', '')]), 'head': 4, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]))}]), 'children': (Span('Poe', [{'id': 1, 'lemma': 'pood', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('gen', '')]), 'head': 2, 'deprel': '@P>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]),\n",
       "Span('õlut', [{'id': 3, 'lemma': 'õlu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('part', '')]), 'head': 4, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': Span('joonud', [{'id': 4, 'lemma': 'joo=nud', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('partic', '')]), 'head': 5, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': Span('mehed', [{'id': 5, 'lemma': 'mees', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', ''), ('nom', '')]), 'head': 6, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': Span('häirisid', [{'id': 6, 'lemma': 'häiri', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('ps3', ''), ('pl', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (...,)}]), 'children': (...,)}]), 'children': (Span('ees', [{'id': 2, 'lemma': 'ees', 'upostag': 'K', 'xpostag': 'Kt', 'feats': None, 'head': 4, 'deprel': '@ADVL', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('Poe', [{'id': 1, 'lemma': 'pood', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('gen', '')]), 'head': 2, 'deprel': '@P>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]), ...)}]), 'children': ()}]),\n",
       "Span('joonud', [{'id': 4, 'lemma': 'joo=nud', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('partic', '')]), 'head': 5, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': Span('mehed', [{'id': 5, 'lemma': 'mees', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', ''), ('nom', '')]), 'head': 6, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': Span('häirisid', [{'id': 6, 'lemma': 'häiri', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('ps3', ''), ('pl', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (...,)}]), 'children': (...,)}]), 'children': (Span('ees', [{'id': 2, 'lemma': 'ees', 'upostag': 'K', 'xpostag': 'Kt', 'feats': None, 'head': 4, 'deprel': '@ADVL', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('Poe', [{'id': 1, 'lemma': 'pood', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('gen', '')]), 'head': 2, 'deprel': '@P>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]), Span('õlut', [{'id': 3, 'lemma': 'õlu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('part', '')]), 'head': 4, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]))}]),\n",
       "Span('mehed', [{'id': 5, 'lemma': 'mees', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', ''), ('nom', '')]), 'head': 6, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': Span('häirisid', [{'id': 6, 'lemma': 'häiri', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('ps3', ''), ('pl', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (...,)}]), 'children': (Span('joonud', [{'id': 4, 'lemma': 'joo=nud', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('partic', '')]), 'head': 5, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('ees', [{'id': 2, 'lemma': 'ees', 'upostag': 'K', 'xpostag': 'Kt', 'feats': None, 'head': 4, 'deprel': '@ADVL', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('Poe', [{'id': 1, 'lemma': 'pood', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('gen', '')]), 'head': 2, 'deprel': '@P>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]), Span('õlut', [{'id': 3, 'lemma': 'õlu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('part', '')]), 'head': 4, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]))}]),)}]),\n",
       "Span('häirisid', [{'id': 6, 'lemma': 'häiri', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('ps3', ''), ('pl', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (Span('mehed', [{'id': 5, 'lemma': 'mees', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', ''), ('nom', '')]), 'head': 6, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('joonud', [{'id': 4, 'lemma': 'joo=nud', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('partic', '')]), 'head': 5, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('ees', [{'id': 2, 'lemma': 'ees', 'upostag': 'K', 'xpostag': 'Kt', 'feats': None, 'head': 4, 'deprel': '@ADVL', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('Poe', [{'id': 1, 'lemma': 'pood', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('gen', '')]), 'head': 2, 'deprel': '@P>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]), Span('õlut', [{'id': 3, 'lemma': 'õlu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('part', '')]), 'head': 4, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]))}]),)}]),)}]),\n",
       "Span('kohalikke', [{'id': 7, 'lemma': 'kohalik', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('pl', ''), ('part', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (Span(',', [{'id': 8, 'lemma': ',', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Com', '')]), 'head': 7, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('neg', '')]), 'head': 7, 'deprel': '@FMV', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('aga', [{'id': 9, 'lemma': 'aga', 'upostag': 'J', 'xpostag': 'Jc', 'feats': None, 'head': 13, 'deprel': '@J', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('politsei', [{'id': 11, 'lemma': 'politsei', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 13, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('ükskõikne', [{'id': 10, 'lemma': 'üks_kõikne', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 11, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]), Span('ei', [{'id': 12, 'lemma': 'ei', 'upostag': 'V', 'xpostag': 'Vaux', 'feats': OrderedDict([('neg', '')]), 'head': 13, 'deprel': '@NEG', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('midagi', [{'id': 14, 'lemma': 'miski', 'upostag': 'P', 'xpostag': 'P', 'feats': OrderedDict([('intrel', ''), ('sg', ''), ('part', '')]), 'head': 13, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('.', [{'id': 15, 'lemma': '.', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Fst', '')]), 'head': 14, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]))}]))}]),\n",
       "Span(',', [{'id': 8, 'lemma': ',', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Com', '')]), 'head': 7, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': Span('kohalikke', [{'id': 7, 'lemma': 'kohalik', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('pl', ''), ('part', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (..., Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('neg', '')]), 'head': 7, 'deprel': '@FMV', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('aga', [{'id': 9, 'lemma': 'aga', 'upostag': 'J', 'xpostag': 'Jc', 'feats': None, 'head': 13, 'deprel': '@J', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('politsei', [{'id': 11, 'lemma': 'politsei', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 13, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('ükskõikne', [{'id': 10, 'lemma': 'üks_kõikne', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 11, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]), Span('ei', [{'id': 12, 'lemma': 'ei', 'upostag': 'V', 'xpostag': 'Vaux', 'feats': OrderedDict([('neg', '')]), 'head': 13, 'deprel': '@NEG', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('midagi', [{'id': 14, 'lemma': 'miski', 'upostag': 'P', 'xpostag': 'P', 'feats': OrderedDict([('intrel', ''), ('sg', ''), ('part', '')]), 'head': 13, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('.', [{'id': 15, 'lemma': '.', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Fst', '')]), 'head': 14, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]))}]))}]), 'children': ()}]),\n",
       "Span('aga', [{'id': 9, 'lemma': 'aga', 'upostag': 'J', 'xpostag': 'Jc', 'feats': None, 'head': 13, 'deprel': '@J', 'deps': None, 'misc': None, 'parent_span': Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('neg', '')]), 'head': 7, 'deprel': '@FMV', 'deps': None, 'misc': None, 'parent_span': Span('kohalikke', [{'id': 7, 'lemma': 'kohalik', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('pl', ''), ('part', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (Span(',', [{'id': 8, 'lemma': ',', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Com', '')]), 'head': 7, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), ...)}]), 'children': (..., Span('politsei', [{'id': 11, 'lemma': 'politsei', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 13, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('ükskõikne', [{'id': 10, 'lemma': 'üks_kõikne', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 11, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]), Span('ei', [{'id': 12, 'lemma': 'ei', 'upostag': 'V', 'xpostag': 'Vaux', 'feats': OrderedDict([('neg', '')]), 'head': 13, 'deprel': '@NEG', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('midagi', [{'id': 14, 'lemma': 'miski', 'upostag': 'P', 'xpostag': 'P', 'feats': OrderedDict([('intrel', ''), ('sg', ''), ('part', '')]), 'head': 13, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('.', [{'id': 15, 'lemma': '.', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Fst', '')]), 'head': 14, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]))}]), 'children': ()}]),\n",
       "Span('ükskõikne', [{'id': 10, 'lemma': 'üks_kõikne', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 11, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': Span('politsei', [{'id': 11, 'lemma': 'politsei', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 13, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('neg', '')]), 'head': 7, 'deprel': '@FMV', 'deps': None, 'misc': None, 'parent_span': Span('kohalikke', [{'id': 7, 'lemma': 'kohalik', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('pl', ''), ('part', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (Span(',', [{'id': 8, 'lemma': ',', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Com', '')]), 'head': 7, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), ...)}]), 'children': (Span('aga', [{'id': 9, 'lemma': 'aga', 'upostag': 'J', 'xpostag': 'Jc', 'feats': None, 'head': 13, 'deprel': '@J', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), ..., Span('ei', [{'id': 12, 'lemma': 'ei', 'upostag': 'V', 'xpostag': 'Vaux', 'feats': OrderedDict([('neg', '')]), 'head': 13, 'deprel': '@NEG', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('midagi', [{'id': 14, 'lemma': 'miski', 'upostag': 'P', 'xpostag': 'P', 'feats': OrderedDict([('intrel', ''), ('sg', ''), ('part', '')]), 'head': 13, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('.', [{'id': 15, 'lemma': '.', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Fst', '')]), 'head': 14, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]))}]), 'children': (...,)}]), 'children': ()}]),\n",
       "Span('politsei', [{'id': 11, 'lemma': 'politsei', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 13, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('neg', '')]), 'head': 7, 'deprel': '@FMV', 'deps': None, 'misc': None, 'parent_span': Span('kohalikke', [{'id': 7, 'lemma': 'kohalik', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('pl', ''), ('part', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (Span(',', [{'id': 8, 'lemma': ',', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Com', '')]), 'head': 7, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), ...)}]), 'children': (Span('aga', [{'id': 9, 'lemma': 'aga', 'upostag': 'J', 'xpostag': 'Jc', 'feats': None, 'head': 13, 'deprel': '@J', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), ..., Span('ei', [{'id': 12, 'lemma': 'ei', 'upostag': 'V', 'xpostag': 'Vaux', 'feats': OrderedDict([('neg', '')]), 'head': 13, 'deprel': '@NEG', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('midagi', [{'id': 14, 'lemma': 'miski', 'upostag': 'P', 'xpostag': 'P', 'feats': OrderedDict([('intrel', ''), ('sg', ''), ('part', '')]), 'head': 13, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('.', [{'id': 15, 'lemma': '.', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Fst', '')]), 'head': 14, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]))}]), 'children': (Span('ükskõikne', [{'id': 10, 'lemma': 'üks_kõikne', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 11, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]),\n",
       "Span('ei', [{'id': 12, 'lemma': 'ei', 'upostag': 'V', 'xpostag': 'Vaux', 'feats': OrderedDict([('neg', '')]), 'head': 13, 'deprel': '@NEG', 'deps': None, 'misc': None, 'parent_span': Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('neg', '')]), 'head': 7, 'deprel': '@FMV', 'deps': None, 'misc': None, 'parent_span': Span('kohalikke', [{'id': 7, 'lemma': 'kohalik', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('pl', ''), ('part', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (Span(',', [{'id': 8, 'lemma': ',', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Com', '')]), 'head': 7, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), ...)}]), 'children': (Span('aga', [{'id': 9, 'lemma': 'aga', 'upostag': 'J', 'xpostag': 'Jc', 'feats': None, 'head': 13, 'deprel': '@J', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('politsei', [{'id': 11, 'lemma': 'politsei', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 13, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('ükskõikne', [{'id': 10, 'lemma': 'üks_kõikne', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 11, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]), ..., Span('midagi', [{'id': 14, 'lemma': 'miski', 'upostag': 'P', 'xpostag': 'P', 'feats': OrderedDict([('intrel', ''), ('sg', ''), ('part', '')]), 'head': 13, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('.', [{'id': 15, 'lemma': '.', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Fst', '')]), 'head': 14, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]))}]), 'children': ()}]),\n",
       "Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('neg', '')]), 'head': 7, 'deprel': '@FMV', 'deps': None, 'misc': None, 'parent_span': Span('kohalikke', [{'id': 7, 'lemma': 'kohalik', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('pl', ''), ('part', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (Span(',', [{'id': 8, 'lemma': ',', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Com', '')]), 'head': 7, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), ...)}]), 'children': (Span('aga', [{'id': 9, 'lemma': 'aga', 'upostag': 'J', 'xpostag': 'Jc', 'feats': None, 'head': 13, 'deprel': '@J', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('politsei', [{'id': 11, 'lemma': 'politsei', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 13, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('ükskõikne', [{'id': 10, 'lemma': 'üks_kõikne', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 11, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]), Span('ei', [{'id': 12, 'lemma': 'ei', 'upostag': 'V', 'xpostag': 'Vaux', 'feats': OrderedDict([('neg', '')]), 'head': 13, 'deprel': '@NEG', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('midagi', [{'id': 14, 'lemma': 'miski', 'upostag': 'P', 'xpostag': 'P', 'feats': OrderedDict([('intrel', ''), ('sg', ''), ('part', '')]), 'head': 13, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('.', [{'id': 15, 'lemma': '.', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Fst', '')]), 'head': 14, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]))}]),\n",
       "Span('midagi', [{'id': 14, 'lemma': 'miski', 'upostag': 'P', 'xpostag': 'P', 'feats': OrderedDict([('intrel', ''), ('sg', ''), ('part', '')]), 'head': 13, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('neg', '')]), 'head': 7, 'deprel': '@FMV', 'deps': None, 'misc': None, 'parent_span': Span('kohalikke', [{'id': 7, 'lemma': 'kohalik', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('pl', ''), ('part', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (Span(',', [{'id': 8, 'lemma': ',', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Com', '')]), 'head': 7, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), ...)}]), 'children': (Span('aga', [{'id': 9, 'lemma': 'aga', 'upostag': 'J', 'xpostag': 'Jc', 'feats': None, 'head': 13, 'deprel': '@J', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('politsei', [{'id': 11, 'lemma': 'politsei', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 13, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('ükskõikne', [{'id': 10, 'lemma': 'üks_kõikne', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 11, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]), Span('ei', [{'id': 12, 'lemma': 'ei', 'upostag': 'V', 'xpostag': 'Vaux', 'feats': OrderedDict([('neg', '')]), 'head': 13, 'deprel': '@NEG', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), ...)}]), 'children': (Span('.', [{'id': 15, 'lemma': '.', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Fst', '')]), 'head': 14, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]),\n",
       "Span('.', [{'id': 15, 'lemma': '.', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Fst', '')]), 'head': 14, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': Span('midagi', [{'id': 14, 'lemma': 'miski', 'upostag': 'P', 'xpostag': 'P', 'feats': OrderedDict([('intrel', ''), ('sg', ''), ('part', '')]), 'head': 13, 'deprel': '@OBJ', 'deps': None, 'misc': None, 'parent_span': Span('teinud', [{'id': 13, 'lemma': 'tege', 'upostag': 'V', 'xpostag': 'V', 'feats': OrderedDict([('indic', ''), ('impf', ''), ('neg', '')]), 'head': 7, 'deprel': '@FMV', 'deps': None, 'misc': None, 'parent_span': Span('kohalikke', [{'id': 7, 'lemma': 'kohalik', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('pl', ''), ('part', '')]), 'head': 0, 'deprel': 'ROOT', 'deps': None, 'misc': None, 'parent_span': None, 'children': (Span(',', [{'id': 8, 'lemma': ',', 'upostag': 'Z', 'xpostag': 'Z', 'feats': OrderedDict([('Com', '')]), 'head': 7, 'deprel': '@Punc', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), ...)}]), 'children': (Span('aga', [{'id': 9, 'lemma': 'aga', 'upostag': 'J', 'xpostag': 'Jc', 'feats': None, 'head': 13, 'deprel': '@J', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), Span('politsei', [{'id': 11, 'lemma': 'politsei', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 13, 'deprel': '@SUBJ', 'deps': None, 'misc': None, 'parent_span': ..., 'children': (Span('ükskõikne', [{'id': 10, 'lemma': 'üks_kõikne', 'upostag': 'A', 'xpostag': 'A', 'feats': OrderedDict([('sg', ''), ('nom', '')]), 'head': 11, 'deprel': '@AN>', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]),)}]), Span('ei', [{'id': 12, 'lemma': 'ei', 'upostag': 'V', 'xpostag': 'Vaux', 'feats': OrderedDict([('neg', '')]), 'head': 13, 'deprel': '@NEG', 'deps': None, 'misc': None, 'parent_span': ..., 'children': ()}]), ...)}]), 'children': (...,)}]), 'children': ()}])])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lõpuks MaltParseri kiht\n",
    "maltparser_tagger.tag(text)\n",
    "text.maltparser_syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Semantiline analüüs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ajaväljendite tuvastamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text3 = Text('EKA sisearhitektuuri osakond ja RMK \\\n",
    "avavad neljapäeval kell 16.00 \\\n",
    "RMK Tallinna kontoris (Toompuiestee 24) näituse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">EKA sisearhitektuuri osakond ja RMK avavad neljapäeval kell 16.00 RMK Tallinna kontoris (Toompuiestee 24) näituse</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Metadata</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>document_creation_time</td>\n",
       "      <td>2020-10-07T21:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>timexes</td>\n",
       "      <td>tid, type, value, temporal_function, anchor_time_id, mod, quant, freq, begin_point, end_point, part_of_interval</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='EKA sisearhitektuuri osakond ja RMK avavad neljapäeval kell 16.00 RMK Tallinna kontoris (Toompuiestee 24) näituse')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Märgendame ajaväljendid\n",
    "from estnltk.taggers import TimexTagger\n",
    "\n",
    "tagger = TimexTagger()\n",
    "text3.tag_layer()\n",
    "tagger.tag( text3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>timexes</td>\n",
       "      <td>tid, type, value, temporal_function, anchor_time_id, mod, quant, freq, begin_point, end_point, part_of_interval</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>tid</th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "      <th>temporal_function</th>\n",
       "      <th>anchor_time_id</th>\n",
       "      <th>mod</th>\n",
       "      <th>quant</th>\n",
       "      <th>freq</th>\n",
       "      <th>begin_point</th>\n",
       "      <th>end_point</th>\n",
       "      <th>part_of_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['neljapäeval', 'kell', '16.00']</td>\n",
       "      <td>t1</td>\n",
       "      <td>TIME</td>\n",
       "      <td>2020-10-08T16:00</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='timexes', attributes=('tid', 'type', 'value', 'temporal_function', 'anchor_time_id', 'mod', 'quant', 'freq', 'begin_point', 'end_point', 'part_of_interval'), spans=SL[EnvelopingSpan(['neljapäeval', 'kell', '16.00'], [{'tid': 't1', 'type': 'TIME', 'value': '2020-10-08T16:00', 'temporal_function': True, 'anchor_time_id': None, 'mod': None, 'quant': None, 'freq': None, 'begin_point': None, 'end_point': None, 'part_of_interval': None}])])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.timexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">EKA sisearhitektuuri osakond ja RMK avavad neljapäeval kell 16.00 RMK Tallinna kontoris (Toompuiestee 24) näituse</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Metadata</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>document_creation_time</td>\n",
       "      <td>2019-10-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>timexes</td>\n",
       "      <td>tid, type, value, temporal_function, anchor_time_id, mod, quant, freq, begin_point, end_point, part_of_interval</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='EKA sisearhitektuuri osakond ja RMK avavad neljapäeval kell 16.00 RMK Tallinna kontoris (Toompuiestee 24) näituse')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Soovi korral võime määratleda teksti loomise aja\n",
    "text3 = Text('EKA sisearhitektuuri osakond ja RMK \\\n",
    "avavad neljapäeval kell 16.00 \\\n",
    "RMK Tallinna kontoris (Toompuiestee 24) näituse').tag_layer()\n",
    "text3.meta['document_creation_time'] = '2019-10-27'\n",
    "tagger.tag(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>timexes</td>\n",
       "      <td>tid, type, value, temporal_function, anchor_time_id, mod, quant, freq, begin_point, end_point, part_of_interval</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>tid</th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "      <th>temporal_function</th>\n",
       "      <th>anchor_time_id</th>\n",
       "      <th>mod</th>\n",
       "      <th>quant</th>\n",
       "      <th>freq</th>\n",
       "      <th>begin_point</th>\n",
       "      <th>end_point</th>\n",
       "      <th>part_of_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['neljapäeval', 'kell', '16.00']</td>\n",
       "      <td>t1</td>\n",
       "      <td>TIME</td>\n",
       "      <td>2019-10-31T16:00</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='timexes', attributes=('tid', 'type', 'value', 'temporal_function', 'anchor_time_id', 'mod', 'quant', 'freq', 'begin_point', 'end_point', 'part_of_interval'), spans=SL[EnvelopingSpan(['neljapäeval', 'kell', '16.00'], [{'tid': 't1', 'type': 'TIME', 'value': '2019-10-31T16:00', 'temporal_function': True, 'anchor_time_id': None, 'mod': None, 'quant': None, 'freq': None, 'begin_point': None, 'end_point': None, 'part_of_interval': None}])])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.timexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aadresside tuvastamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Toimub kahes etapis\n",
    "from estnltk.taggers import AddressPartTagger, AddressGrammarTagger\n",
    "address_token_tagger = AddressPartTagger(output_layer='address_tokens')\n",
    "address_tagger = AddressGrammarTagger(output_layer='addresses', \n",
    "                                      input_layer='address_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text = Text(\"Ootame teid 2. novembril külla \\\n",
    "aadressil Aia 6, Tartu.\").tag_layer(['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>address_tokens</td>\n",
       "      <td>grammar_symbol, type</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>grammar_symbol</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ootame teid</td>\n",
       "      <td>RANDOM_TEXT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>MAJA</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>novembril külla aadressil</td>\n",
       "      <td>RANDOM_TEXT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aia</td>\n",
       "      <td>TÄNAV</td>\n",
       "      <td>tänav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>MAJA</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tartu</td>\n",
       "      <td>ASULA</td>\n",
       "      <td>asula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>TÄNAV</td>\n",
       "      <td>tänav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='address_tokens', attributes=('grammar_symbol', 'type'), spans=SL[Span('Ootame teid', [{'grammar_symbol': 'RANDOM_TEXT', 'type': None}]),\n",
       "Span('2', [{'grammar_symbol': 'MAJA', 'type': None}]),\n",
       "Span('novembril külla aadressil', [{'grammar_symbol': 'RANDOM_TEXT', 'type': None}]),\n",
       "Span('Aia', [{'grammar_symbol': 'TÄNAV', 'type': 'tänav'}]),\n",
       "Span('6', [{'grammar_symbol': 'MAJA', 'type': None}]),\n",
       "Span('Tartu', [{'grammar_symbol': 'ASULA', 'type': 'asula'}, {'grammar_symbol': 'TÄNAV', 'type': 'tänav'}])])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esiteks märgime peale võimalikud aadresside komponendid\n",
    "address_token_tagger.tag(text)[\"address_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>addresses</td>\n",
       "      <td>grammar_symbol, TÄNAV, MAJA, ASULA, MAAKOND, INDEKS</td>\n",
       "      <td>None</td>\n",
       "      <td>address_tokens</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>grammar_symbol</th>\n",
       "      <th>TÄNAV</th>\n",
       "      <th>MAJA</th>\n",
       "      <th>ASULA</th>\n",
       "      <th>MAAKOND</th>\n",
       "      <th>INDEKS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Aia', '6', 'Tartu']</td>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>Aia</td>\n",
       "      <td>6</td>\n",
       "      <td>Tartu</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='addresses', attributes=('grammar_symbol', 'TÄNAV', 'MAJA', 'ASULA', 'MAAKOND', 'INDEKS'), spans=SL[EnvelopingSpan(['Aia', '6', 'Tartu'], [{'grammar_symbol': 'ADDRESS', 'TÄNAV': 'Aia', 'MAJA': '6', 'ASULA': 'Tartu', 'MAAKOND': '', 'INDEKS': ''}])])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teiseks leiame aadressid sealt, kus sobivad komponendid järjest esinevad\n",
    "address_tagger.tag(text)['addresses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"verb.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from estnltk.taggers import VerbChainDetector\n",
    "vc_detector = VerbChainDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Kas Juku alustas kodutööga? Minuteada ei alustanud.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Kas Juku alustas kodutööga? Minuteada ei alustanud.')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "# Loome teksti\n",
    "text = Text('Kas Juku alustas kodutööga? Minuteada ei alustanud.')\n",
    "# Lisame verbiahelate tuvastamiseks vajalikud sisendkihid\n",
    "text.tag_layer(['words', 'sentences', 'morph_analysis', 'clauses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>verb_chains</td>\n",
       "      <td>pattern, roots, word_ids, mood, polarity, tense, voice, remaining_verbs</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>pattern</th>\n",
       "      <th>roots</th>\n",
       "      <th>word_ids</th>\n",
       "      <th>mood</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tense</th>\n",
       "      <th>voice</th>\n",
       "      <th>remaining_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['alustas']</td>\n",
       "      <td>['verb']</td>\n",
       "      <td>['alusta']</td>\n",
       "      <td>[2]</td>\n",
       "      <td>indic</td>\n",
       "      <td>POS</td>\n",
       "      <td>imperfect</td>\n",
       "      <td>personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['ei', 'alustanud']</td>\n",
       "      <td>['ei', 'verb']</td>\n",
       "      <td>['ei', 'alusta']</td>\n",
       "      <td>[6, 7]</td>\n",
       "      <td>indic</td>\n",
       "      <td>NEG</td>\n",
       "      <td>imperfect</td>\n",
       "      <td>personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='verb_chains', attributes=('pattern', 'roots', 'word_ids', 'mood', 'polarity', 'tense', 'voice', 'remaining_verbs'), spans=SL[EnvelopingSpan(['alustas'], [{'pattern': ['verb'], 'roots': ['alusta'], 'word_ids': [2], 'mood': 'indic', 'polarity': 'POS', 'tense': 'imperfect', 'voice': 'personal', 'remaining_verbs': False}]),\n",
       "EnvelopingSpan(['ei', 'alustanud'], [{'pattern': ['ei', 'verb'], 'roots': ['ei', 'alusta'], 'word_ids': [6, 7], 'mood': 'indic', 'polarity': 'NEG', 'tense': 'imperfect', 'voice': 'personal', 'remaining_verbs': False}])])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuvastame verbiahelad\n",
    "vc_detector.tag( text )\n",
    "\n",
    "# Väljastame verbiahelad (vastavad tekstid)\n",
    "text.verb_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Oma märgendajate kirjutamine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PhraseTagger\n",
    "#### võimaldab märgendada kihis järjest esinevaid elemente mingi atribuudi alusel\n",
    "\n",
    "Proovime kirjutada taggerit, mis märgendaks lihtsaid nimisõnafraase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from estnltk.taggers import PhraseTagger\n",
    "\n",
    "# Kasutame fraaside esmaseks määratlemiseks sõnaliike\n",
    "phrase_list = [\n",
    "               { '_phrase_': ('A', 'S')},\n",
    "               { '_phrase_':  ('C', 'S')},\n",
    "               { '_phrase_':  ('U', 'S')}\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Defineerime taggeri, mis phrase_list muutujas olevaid fraasitüüpe märgendaks\n",
    "phrase_tagger = PhraseTagger(output_layer='noun_phrases',\n",
    "                      input_layer='morph_analysis',\n",
    "                      input_attribute='partofspeech',\n",
    "                      vocabulary=phrase_list,\n",
    "                      key='_phrase_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Viimasedki pardid lendasid soojemale maale, kui jää läks liiga paksuks jõest toidu hankimiseks.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noun_phrases</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Viimasedki pardid lendasid soojemale maale, kui jää läks liiga paksuks jõest toidu hankimiseks.')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rakendame kirjutatud taggerit morfanalüüsitud tekstile\n",
    "t = Text('Viimasedki pardid lendasid soojemale maale, \\\n",
    "kui jää läks liiga paksuks jõest toidu hankimiseks.').tag_layer()\n",
    "phrase_tagger.tag(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>noun_phrases</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Viimasedki', 'pardid']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['soojemale', 'maale']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['paksuks', 'jõest']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='noun_phrases', attributes=(), spans=SL[EnvelopingSpan(['Viimasedki', 'pardid'], [{}]),\n",
       "EnvelopingSpan(['soojemale', 'maale'], [{}]),\n",
       "EnvelopingSpan(['paksuks', 'jõest'], [{}])])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leiame nimisõnafraasid\n",
    "# Puuduvad algvormid\n",
    "# Paremate tulemuste jaoks peaks arvesse võtma rohkem kui sõnaliike\n",
    "t.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Dekoraator võimaldab lisada oma uuele kihile atribuute - lisame lemmad\n",
    "def decorator(span, annotation):\n",
    "    annotation['lemmas'] = ' '.join([l[0] for l in span.lemma])\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Uus phrase_tagger, mis paneb uude kihti ka fraasid algvormis\n",
    "phrase_tagger2 = PhraseTagger(output_layer='noun_phrases2',\n",
    "                      input_layer='morph_analysis',\n",
    "                      input_attribute='partofspeech',\n",
    "                      vocabulary=phrase_list,\n",
    "                      key='_phrase_',\n",
    "                      output_attributes = ['lemmas'],\n",
    "                      decorator = decorator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>noun_phrases2</td>\n",
       "      <td>lemmas</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Viimasedki', 'pardid']</td>\n",
       "      <td>viimane part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['soojemale', 'maale']</td>\n",
       "      <td>soojem maa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['paksuks', 'jõest']</td>\n",
       "      <td>paks jõgi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='noun_phrases2', attributes=('lemmas',), spans=SL[EnvelopingSpan(['Viimasedki', 'pardid'], [{'lemmas': 'viimane part'}]),\n",
       "EnvelopingSpan(['soojemale', 'maale'], [{'lemmas': 'soojem maa'}]),\n",
       "EnvelopingSpan(['paksuks', 'jõest'], [{'lemmas': 'paks jõgi'}])])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Olemas ilusad algvormis fraasid\n",
    "# Vaja oleks ka sõna vormiinfot arvestada\n",
    "phrase_tagger2.tag(t)\n",
    "t.noun_phrases2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Täiendame dekoraatorit - arvestame ka vormide ühilduvust\n",
    "def decorator2(span, annotation):\n",
    "    annotation['lemmas'] = ' '.join([l[0] for l in span.lemma])\n",
    "    \n",
    "    ninataga_sg = ['sg ter', 'sg ab', 'sg kom', 'sg es']\n",
    "    ninataga_pl = ['pl ter', 'pl ab', 'pl kom', 'pl es']\n",
    "    # Omadussõna ja nimisõna samas vormis -> OK\n",
    "    if span[0].form == span[1].form:\n",
    "        return True\n",
    "    # Omadussõna ainsuse omastavas ja nimisõna 4 viimases käändes ainsuses -> OK\n",
    "    elif span[0].form[0] == 'sg g' and span[1].form[0] in ninataga_sg:\n",
    "        return True\n",
    "    # Omadussõna mitm omastavas ja nimisõna 4 viimases käändes mitm -> OK\n",
    "    elif span[0].form[0] == 'pl g' and span[1].form[0] in ninataga_pl:\n",
    "        return True\n",
    "    # Kõik muud juhud -> ei sobi fraas\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "phrase_tagger3 = PhraseTagger(output_layer='noun_phrases3',\n",
    "                      input_layer='morph_analysis',\n",
    "                      input_attribute='partofspeech',\n",
    "                      vocabulary=phrase_list,\n",
    "                      key='_phrase_',\n",
    "                      output_attributes = ['lemmas'],\n",
    "                      decorator = decorator2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Viimasedki pardid lendasid soojemale maale, kui jää läks liiga paksuks jõest toidu hankimiseks.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noun_phrases</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noun_phrases2</td>\n",
       "      <td>lemmas</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noun_phrases3</td>\n",
       "      <td>lemmas</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Viimasedki pardid lendasid soojemale maale, kui jää läks liiga paksuks jõest toidu hankimiseks.')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Märgendame kolmanda nimisõnafraaside kihi\n",
    "phrase_tagger3.tag(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>noun_phrases3</td>\n",
       "      <td>lemmas</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Viimasedki', 'pardid']</td>\n",
       "      <td>viimane part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['soojemale', 'maale']</td>\n",
       "      <td>soojem maa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='noun_phrases3', attributes=('lemmas',), spans=SL[EnvelopingSpan(['Viimasedki', 'pardid'], [{'lemmas': 'viimane part'}]),\n",
       "EnvelopingSpan(['soojemale', 'maale'], [{'lemmas': 'soojem maa'}])])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tulemused vastavad ootustele\n",
    " t.noun_phrases3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viimane part\n",
      "soojem maa\n"
     ]
    }
   ],
   "source": [
    "# Fraase on lihtne stringidena kätte saada\n",
    "for i in t.noun_phrases3:\n",
    "    print(i.lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Näide: leiame, millised nimisõnafraasid esinevad kõige sagedamini eesti vanasõnades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/proverbs.txt\", \"r\", encoding = 'utf8') as fin:\n",
    "    # Failis on iga vanasõna eraldi real - saame listi vanasõnadest\n",
    "    proverbs = fin.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:11<00:00, 84.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Loendur fraaside kokkulugemiseks\n",
    "noun_phrases_counts = Counter()\n",
    "\n",
    "for text in tqdm(proverbs): # vaatame vanasõnade listi järjest läbi\n",
    "    t = Text(text).tag_layer() # teeme vanasõna Text objektiks ja analüüsime\n",
    "    phrase_tagger3.tag(t) # märgime peale nimisõnafraasid oma parima taggeriga\n",
    "    if len(t.noun_phrases3) > 0: \n",
    "        for p in t.noun_phrases3: # suurendame loendurit vastava fraasi kohal\n",
    "            noun_phrases_counts[p.lemmas] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tühi kõht', 11),\n",
       " ('vana koer', 11),\n",
       " ('vaene mees', 7),\n",
       " ('vana mees', 5),\n",
       " ('vaene inimene', 5),\n",
       " ('vana naine', 5),\n",
       " ('suur koer', 4),\n",
       " ('vana hobune', 4),\n",
       " ('tühi jutt', 4),\n",
       " ('noor koer', 3),\n",
       " ('vaene vald', 3),\n",
       " ('oma koer', 3),\n",
       " ('vana sõber', 3),\n",
       " ('noor mees', 2),\n",
       " ('vaene aeg', 2),\n",
       " ('noor kuu', 2),\n",
       " ('hea koer', 2),\n",
       " ('noor iga', 2),\n",
       " ('vana hobu', 2),\n",
       " ('tühi asi', 2),\n",
       " ('terav nuga', 2),\n",
       " ('arg koer', 2),\n",
       " ('vana kaev', 2),\n",
       " ('paha ilm', 2),\n",
       " ('rikas härra', 2),\n",
       " ('vaene härra', 2),\n",
       " ('rikas vald', 2),\n",
       " ('paha koer', 2),\n",
       " ('vana tee', 2),\n",
       " ('vana asi', 2),\n",
       " ('parem õnn', 2),\n",
       " ('hea ilm', 2),\n",
       " ('kuri ilm', 2),\n",
       " ('kõva kannikas', 2),\n",
       " ('paljas maa', 2),\n",
       " ('vana rasv', 1),\n",
       " ('uus lumi', 1),\n",
       " ('vana põhi', 1),\n",
       " ('valge liblikas', 1),\n",
       " ('vaenuline elu', 1),\n",
       " ('kirju elu', 1),\n",
       " ('murelik elu', 1),\n",
       " ('parem elu', 1),\n",
       " ('koer keel', 1),\n",
       " ('valge sabaots', 1),\n",
       " ('suur pea', 1),\n",
       " ('lai selg', 1),\n",
       " ('rikas mölder', 1),\n",
       " ('vana kuub', 1),\n",
       " ('vana sulg', 1),\n",
       " ('pisike mees', 1),\n",
       " ('suur mees', 1),\n",
       " ('lai lauk', 1),\n",
       " ('hea elu', 1),\n",
       " ('kitsas lauk', 1),\n",
       " ('vaevaline elu', 1),\n",
       " ('tühi aeg', 1),\n",
       " ('parem leivakõrvane', 1),\n",
       " ('parem kokk', 1),\n",
       " ('tühjem kõht', 1),\n",
       " ('magusam leib', 1),\n",
       " ('hea tahe', 1),\n",
       " ('vesine kõhutäis', 1),\n",
       " ('puhas leib', 1),\n",
       " ('oma vats', 1),\n",
       " ('õhtune kõhutäis', 1),\n",
       " ('vana kasukanäru', 1),\n",
       " ('joodik raha', 1),\n",
       " ('vaene asi', 1),\n",
       " ('vana vits', 1),\n",
       " ('kerge elu', 1),\n",
       " ('vana iga', 1),\n",
       " ('noor inimene', 1),\n",
       " ('vana nõu', 1),\n",
       " ('vana töö', 1),\n",
       " ('noorem hobune', 1),\n",
       " ('vana härg', 1),\n",
       " ('vana võllas', 1),\n",
       " ('vana vaev', 1),\n",
       " ('vana sõna', 1),\n",
       " ('vana osa', 1),\n",
       " ('terav hammas', 1),\n",
       " ('väike laps', 1),\n",
       " ('vana siga', 1),\n",
       " ('vaene laps', 1),\n",
       " ('tühi turv', 1),\n",
       " ('vana arm', 1),\n",
       " ('rammus koer', 1),\n",
       " ('suur haopinu', 1),\n",
       " ('vana inimene', 1),\n",
       " ('vana piits', 1),\n",
       " ('taline tee', 1),\n",
       " ('kolmekümne-aastane vanatüdruk', 1),\n",
       " ('üheksa-aastane hunt', 1),\n",
       " ('kümneaastane kult', 1),\n",
       " ('aastane vanatüdruk', 1),\n",
       " ('noor naine', 1),\n",
       " ('vana vana', 1),\n",
       " ('vana habe', 1),\n",
       " ('rikas pere', 1),\n",
       " ('tühi aru', 1),\n",
       " ('uus pastel', 1),\n",
       " ('vana särginäru', 1),\n",
       " ('vana karu', 1),\n",
       " ('oma maja', 1),\n",
       " ('kehv toit', 1),\n",
       " ('tark nõu', 1),\n",
       " ('julge koer', 1),\n",
       " ('kartlik koer', 1),\n",
       " ('vana vesi', 1),\n",
       " ('vana müts', 1),\n",
       " ('laisk koer', 1),\n",
       " ('hea õnn', 1),\n",
       " ('rikas mees', 1),\n",
       " ('tühi koor', 1),\n",
       " ('ahne kõht', 1),\n",
       " ('ahne koer', 1),\n",
       " ('suur pere', 1),\n",
       " ('suur kõht', 1),\n",
       " ('tühi koht', 1),\n",
       " ('tühi tuba', 1),\n",
       " ('tühi kaev', 1),\n",
       " ('tühi kott', 1),\n",
       " ('vaene pea', 1),\n",
       " ('vaene vara', 1),\n",
       " ('tühi tõrs', 1),\n",
       " ('suur härg', 1),\n",
       " ('vana vares', 1),\n",
       " ('vaene talupoeg', 1),\n",
       " ('vaene häda', 1),\n",
       " ('vigane hobune', 1),\n",
       " ('tühi rahakott', 1),\n",
       " ('targem rahvas', 1),\n",
       " ('sant saun', 1),\n",
       " ('vaene vaevai', 1),\n",
       " ('vedelam lake', 1),\n",
       " ('paksem lake', 1),\n",
       " ('rikas sulane', 1),\n",
       " ('vaene peremees', 1),\n",
       " ('parem pidu', 1),\n",
       " ('hea peremees', 1),\n",
       " ('must ronk', 1),\n",
       " ('kehv kohtumõistja', 1),\n",
       " ('pikk kõrv', 1),\n",
       " ('sitane võileib', 1),\n",
       " ('parem koer', 1),\n",
       " ('võõras vari', 1),\n",
       " ('vaene olek', 1),\n",
       " ('koer saba', 1),\n",
       " ('valge karv', 1),\n",
       " ('must koer', 1),\n",
       " ('suurem vaenlane', 1),\n",
       " ('luine aed', 1),\n",
       " ('parem tükk', 1),\n",
       " ('uus sõber', 1),\n",
       " ('avalik vaenlane', 1),\n",
       " ('suur sõprus', 1),\n",
       " ('suur vaesus', 1),\n",
       " ('hea meel', 1),\n",
       " ('karusem koer', 1),\n",
       " ('vaene varbavalu', 1),\n",
       " ('sant koer', 1),\n",
       " ('koer hunt', 1),\n",
       " ('mustem nägija', 1),\n",
       " ('hobusesitt lausuja', 1),\n",
       " ('vana hõbe', 1),\n",
       " ('vana aeg', 1),\n",
       " ('vana king', 1),\n",
       " ('paljas jalg', 1),\n",
       " ('uus kuub', 1),\n",
       " ('vana kasukas', 1),\n",
       " ('tigedam koer', 1),\n",
       " ('kõveram saba', 1),\n",
       " ('valge vasikas', 1),\n",
       " ('must ämblik', 1),\n",
       " ('parem vaik', 1),\n",
       " ('külm kuu', 1),\n",
       " ('soe kuu', 1),\n",
       " ('kuri kuu', 1),\n",
       " ('hea kuu', 1),\n",
       " ('paha kuu', 1),\n",
       " ('must pilv', 1),\n",
       " ('hommikune külaline', 1),\n",
       " ('ilus ilmakene', 1),\n",
       " ('külm küünlakuu', 1),\n",
       " ('valjum vastlakuu', 1),\n",
       " ('soe küünlakuu', 1),\n",
       " ('korralik talv', 1),\n",
       " ('kevadine maarjapäev', 1),\n",
       " ('külmem talv', 1),\n",
       " ('magusam mahl', 1),\n",
       " ('suvine pööripäev', 1),\n",
       " ('jahe kivi', 1),\n",
       " ('kuum kivi', 1),\n",
       " ('sügisene öö', 1),\n",
       " ('hilissügisene päev', 1),\n",
       " ('valgem aeg', 1),\n",
       " ('keskmine jõulupüha', 1),\n",
       " ('viimane jõulupüha', 1),\n",
       " ('soe lihavõtted', 1),\n",
       " ('roheline jõulud', 1),\n",
       " ('valge lihavõtted', 1),\n",
       " ('must öö', 1),\n",
       " ('soe maa', 1),\n",
       " ('madal talv', 1),\n",
       " ('sügav talv', 1),\n",
       " ('suur silm', 1),\n",
       " ('pikk hammas', 1),\n",
       " ('külm tali', 1),\n",
       " ('soe suvi', 1),\n",
       " ('madal tali', 1),\n",
       " ('kuiv juuli', 1),\n",
       " ('selge jaanuar', 1),\n",
       " ('vihmane juuli', 1),\n",
       " ('sajune jaanuar', 1),\n",
       " ('põline tali', 1),\n",
       " ('sügisene udu', 1),\n",
       " ('kevadine udu', 1),\n",
       " ('uus kuu', 1),\n",
       " ('uus ilm', 1),\n",
       " ('viljarikas aasta', 1),\n",
       " ('külmem tali', 1),\n",
       " ('suurem lõikus', 1),\n",
       " ('kõrgem lumehang', 1),\n",
       " ('suurem viljarõuk', 1),\n",
       " ('kena ilm', 1),\n",
       " ('viljarikas sügis', 1),\n",
       " ('külm mai', 1),\n",
       " ('märg juuni', 1),\n",
       " ('varane müristamine', 1),\n",
       " ('hiline nälg', 1),\n",
       " ('külm kanamuna', 1),\n",
       " ('kevadine lumi', 1),\n",
       " ('kevadine vihm', 1),\n",
       " ('soe vihm', 1),\n",
       " ('kuiv aasta', 1),\n",
       " ('märg aasta', 1),\n",
       " ('kuiv põu', 1),\n",
       " ('märg kesvakannikas', 1),\n",
       " ('kuiv aeg', 1),\n",
       " ('vesine aeg', 1),\n",
       " ('terve nälg', 1),\n",
       " ('suur vihm', 1),\n",
       " ('hea sügis', 1),\n",
       " ('hea lina', 1),\n",
       " ('mage leib', 1),\n",
       " ('hapu leib', 1),\n",
       " ('suur kakk', 1),\n",
       " ('villane lõng', 1),\n",
       " ('sügisene seatõngermaa', 1),\n",
       " ('suur künd', 1),\n",
       " ('hiline kesakünd', 1),\n",
       " ('varane kordus', 1),\n",
       " ('kerge sõnnikukord', 1),\n",
       " ('sügav vagu', 1),\n",
       " ('kõrge kõrs', 1),\n",
       " ('laisk mees', 1),\n",
       " ('varane rukkioras', 1),\n",
       " ('risune rukis', 1),\n",
       " ('ilus ilm', 1),\n",
       " ('varane tõug', 1),\n",
       " ('hiline tõug', 1),\n",
       " ('parem külviaeg', 1),\n",
       " ('varane põllumees', 1),\n",
       " ('paras külv', 1),\n",
       " ('paks külv', 1),\n",
       " ('harv külv', 1),\n",
       " ('kevadine päev', 1),\n",
       " ('sügisene nädal', 1),\n",
       " ('suine tund', 1),\n",
       " ('taline nädal', 1),\n",
       " ('kõva kõrs', 1),\n",
       " ('jäme tera', 1),\n",
       " ('valge leib', 1),\n",
       " ('must hein', 1),\n",
       " ('valge hein', 1),\n",
       " ('must leib', 1),\n",
       " ('kuiv töö', 1),\n",
       " ('viimane kuhjapea', 1),\n",
       " ('kevadine muld', 1),\n",
       " ('sügisene ädal', 1),\n",
       " ('rammus kass', 1),\n",
       " ('pikem piits', 1),\n",
       " ('suurem saak', 1),\n",
       " ('laisk hobune', 1),\n",
       " ('hea kasu', 1),\n",
       " ('aus mees', 1),\n",
       " ('raske amet', 1),\n",
       " ('parem viis', 1),\n",
       " ('parem tarenälg', 1),\n",
       " ('paha pätajalg', 1),\n",
       " ('must tall', 1)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saamegi kätte sagedasemad nimisõnafraasid\n",
    "noun_phrases_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Nimeüksuste tuvastamine (NER - Named Entity Recognition)\n",
    "\n",
    "EstNLTK sisaldab automaatset nimeüksuste tuvastajat. \n",
    "\n",
    "Programm võimaldab tuvastada 3 liiki nimeüksuseid:\n",
    "\n",
    "* isikunimesid ( lühend: PER );\n",
    "\n",
    "* asukohanimesid ( lühend: LOC );\n",
    "\n",
    "* organisatsiooninimesid ( lühend: ORG )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('morph_analysis',)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import NerTagger\n",
    "ner_tagger = NerTagger()\n",
    "\n",
    "# Milliseid kihte ner_tagger vajab?\n",
    "ner_tagger.input_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\"> Eesti President on Kersti Kaljulaid. Eesti Energia on \\ </br>Eesti riigile kuuluv rahvusvaheline energiaettevõte. </div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=' Eesti President on Kersti Kaljulaid. Eesti Energia on \\\\ \\nEesti riigile kuuluv rahvusvaheline energiaettevõte. ')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "# tekitame näidisteksti\n",
    "t = Text(''' Eesti President on Kersti Kaljulaid. Eesti Energia on \\ \n",
    "Eesti riigile kuuluv rahvusvaheline energiaettevõte. ''')\n",
    "\n",
    "# lisame tekstile vajamineva 'morph_analysis' kihi\n",
    "t.tag_layer('morph_analysis')\n",
    "\n",
    "# lisame nimeüksuste märgenduse\n",
    "ner_tagger.tag(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Eesti']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Kersti', 'Kaljulaid']</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Eesti', 'Energia']</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Eesti', 'riigile']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner', attributes=('nertag',), spans=SL[EnvelopingSpan(['Eesti'], [{'nertag': 'LOC'}]),\n",
       "EnvelopingSpan(['Kersti', 'Kaljulaid'], [{'nertag': 'PER'}]),\n",
       "EnvelopingSpan(['Eesti', 'Energia'], [{'nertag': 'ORG'}]),\n",
       "EnvelopingSpan(['Eesti', 'riigile'], [{'nertag': 'LOC'}])])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# väljastab tuvastatud nimeüksused\n",
    "t.ner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Oma nimeüksuste lisamine\n",
    "\n",
    "1) Leiame võimalikult suure hulga näiteid vastavast nimeüksusest\n",
    " \n",
    "2) Märgendame ümber olemasoleva korpuse - anname seal esinevatele vastavatele nimeüksustele soovitud märgendid\n",
    "\n",
    "3) Treenime nimeüksuste tuvastaja ümbermärgendatud korpuse peal\n",
    "\n",
    "4) Märgendame oma nimeüksusi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Oma nimeüksuste lisamine - kuidas luua leksikone?\n",
    "1) Spetsiifilised allikad - nt eesnimede loetelu, ametite loetelu\n",
    "\n",
    "2) Wordnet\n",
    "\n",
    "3) Suurel korpusel treenitud sõnavektorid - nt word2vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"baas1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"baas2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"baas3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"baas7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"baas4.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Synset('toit.n.01')\", \"Synset('toit.n.02')\", \"Synset('toit.n.03')\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wordneti kasutamiseks tuleb importida vastav moodul ja luua Wordneti objekt:\n",
    "from estnltk.wordnet import Wordnet\n",
    "\n",
    "wn = Wordnet()\n",
    "toit = wn['toit']\n",
    "toit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ettevalmistatud (keedetud, küpsetatud, grillitud, lõigutud vm) toiduained lauale panemiseks ja söömiseks; valmisained, mida süüakse kõhu täitmiseks'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toit[0].definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aine, mida süüakse või omandatakse muul moel kehasse, et hoida alal elu, saada energiat jne'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toit[2].definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "toidud = toit[2].closure('hyponym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Synset('sööt.n.01')\",\n",
       " \"Synset('söödavili.n.01')\",\n",
       " \"Synset('loomne sööt.n.01')\",\n",
       " \"Synset('kalajahu.n.01')\",\n",
       " \"Synset('loomajahu.n.01')\",\n",
       " \"Synset('verejahu.n.01')\",\n",
       " \"Synset('rohukuivis.n.01')\",\n",
       " \"Synset('mahlakas sööt.n.01')\",\n",
       " \"Synset('silo.n.01')\",\n",
       " \"Synset('märgsilo.n.01')\",\n",
       " \"Synset('kuivsilo.n.01')\",\n",
       " \"Synset('mesikasilo.n.01')\",\n",
       " \"Synset('kuivsööt.n.01')\",\n",
       " \"Synset('rohujahu.n.01')\",\n",
       " \"Synset('elussööt.n.01')\",\n",
       " \"Synset('haljassööt.n.01')\",\n",
       " \"Synset('rohusööt.n.01')\",\n",
       " \"Synset('kalasööt.n.01')\",\n",
       " \"Synset('õngesööt.n.01')\",\n",
       " \"Synset('koresööt.n.01')\",\n",
       " \"Synset('hein.n.01')\",\n",
       " \"Synset('soohein.n.01')\",\n",
       " \"Synset('stepihein.n.01')\",\n",
       " \"Synset('talvehein.n.01')\",\n",
       " \"Synset('vitamiinhein.n.01')\",\n",
       " \"Synset('orashein.n.01')\",\n",
       " \"Synset('stepiorashein.n.01')\",\n",
       " \"Synset('timut.n.01')\",\n",
       " \"Synset('mugultimut.n.01')\",\n",
       " \"Synset('ristik.n.01')\",\n",
       " \"Synset('metsristik.n.01')\",\n",
       " \"Synset('kassiristik.n.01')\",\n",
       " \"Synset('kuldristik.n.01')\",\n",
       " \"Synset('mägiristik.n.01')\",\n",
       " \"Synset('randristik.n.01')\",\n",
       " \"Synset('lutsern.n.01')\",\n",
       " \"Synset('harilik lutsern.n.01')\",\n",
       " \"Synset('sirplutsern.n.01')\",\n",
       " \"Synset('hübriidlutsern.n.01')\",\n",
       " \"Synset('humallutsern.n.01')\",\n",
       " \"Synset('loog.n.01')\",\n",
       " \"Synset('härghein.n.01')\",\n",
       " \"Synset('palu-härghein.n.01')\",\n",
       " \"Synset('põld-härghein.n.01')\",\n",
       " \"Synset('jusshein.n.01')\",\n",
       " \"Synset('halfahein.n.01')\",\n",
       " \"Synset('aruhein.n.02')\",\n",
       " \"Synset('aasahein.n.01')\",\n",
       " \"Synset('jõhvhein.n.01')\",\n",
       " \"Synset('kahahein.n.01')\",\n",
       " \"Synset('lambahein.n.01')\",\n",
       " \"Synset('lehmahein.n.01')\",\n",
       " \"Synset('luhahein.n.01')\",\n",
       " \"Synset('maahein.n.01')\",\n",
       " \"Synset('metsahein.n.01')\",\n",
       " \"Synset('niiduhein.n.01')\",\n",
       " \"Synset('presshein.n.01')\",\n",
       " \"Synset('segahein.n.01')\",\n",
       " \"Synset('põhksööt.n.01')\",\n",
       " \"Synset('lehissööt.n.01')\",\n",
       " \"Synset('lisasööt.n.01')\",\n",
       " \"Synset('mineraalsööt.n.01')\",\n",
       " \"Synset('soolabrikett.n.01')\",\n",
       " \"Synset('põhisööt.n.01')\",\n",
       " \"Synset('ekstraktsioonijahu.n.01')\",\n",
       " \"Synset('segatis.n.01')\",\n",
       " \"Synset('söödalisand.n.01')\",\n",
       " \"Synset('premiks.n.01')\",\n",
       " \"Synset('söödavalk.n.01')\",\n",
       " \"Synset('kalatoit.n.02')\",\n",
       " \"Synset('kandi.n.01')\",\n",
       " \"Synset('startersööt.n.01')\",\n",
       " \"Synset('rokk.n.03')\",\n",
       " \"Synset('heksel.n.01')\",\n",
       " \"Synset('õleheksel.n.01')\",\n",
       " \"Synset('sulp.n.01')\",\n",
       " \"Synset('lehesed.n.02')\",\n",
       " \"Synset('kliirokk.n.01')\",\n",
       " \"Synset('furaaž.n.01')\",\n",
       " \"Synset('soolak.n.02')\",\n",
       " \"Synset('tulpsoolak.n.01')\",\n",
       " \"Synset('jõusööt.n.01')\",\n",
       " \"Synset('lihajahu.n.01')\",\n",
       " \"Synset('õlikook.n.01')\",\n",
       " \"Synset('sojakook.n.01')\",\n",
       " \"Synset('linaseemnekook.n.01')\",\n",
       " \"Synset('maisikook.n.01')\",\n",
       " \"Synset('moonikook.n.01')\",\n",
       " \"Synset('puuvillakook.n.01')\",\n",
       " \"Synset('päevalillekook.n.01')\",\n",
       " \"Synset('rapsikook.n.01')\",\n",
       " \"Synset('seesamikook.n.01')\",\n",
       " \"Synset('lisatoitaine.n.01')\",\n",
       " \"Synset('pajuk.n.01')\",\n",
       " \"Synset('jook.n.01')\",\n",
       " \"Synset('taar.n.01')\",\n",
       " \"Synset('kali.n.01')\",\n",
       " \"Synset('alkohol.n.01')\",\n",
       " \"Synset('nastoika.n.01')\",\n",
       " \"Synset('vinjak.n.01')\",\n",
       " \"Synset('küünlapuna.n.01')\",\n",
       " \"Synset('pulke.n.01')\",\n",
       " \"Synset('raki.n.01')\",\n",
       " \"Synset('longero.n.01')\",\n",
       " \"Synset('vein.n.01')\",\n",
       " \"Synset('puuviljavein.n.01')\",\n",
       " \"Synset('õunavein.n.01')\",\n",
       " \"Synset('vaadivein.n.01')\",\n",
       " \"Synset('viinamarjavein.n.01')\",\n",
       " \"Synset('pudelivein.n.01')\",\n",
       " \"Synset('vermut.n.01')\",\n",
       " \"Synset('retsina.n.01')\",\n",
       " \"Synset('dessertvein.n.01')\",\n",
       " \"Synset('tokai.n.01')\",\n",
       " \"Synset('malaga.n.01')\",\n",
       " \"Synset('naturaalvein.n.01')\",\n",
       " \"Synset('bordoo.n.01')\",\n",
       " \"Synset('hõõgvein.n.01')\",\n",
       " \"Synset('muskaatvein.n.01')\",\n",
       " \"Synset('reinvein.n.01')\",\n",
       " \"Synset('šampanja.n.01')\",\n",
       " \"Synset('šerri.n.01')\",\n",
       " \"Synset('portvein.n.01')\",\n",
       " \"Synset('lauavein.n.01')\",\n",
       " \"Synset('majavein.n.01')\",\n",
       " \"Synset('burgunder.n.01')\",\n",
       " \"Synset('margivein.n.01')\",\n",
       " \"Synset('koduvein.n.01')\",\n",
       " \"Synset('marjavein.n.01')\",\n",
       " \"Synset('karusmarjavein.n.01')\",\n",
       " \"Synset('pihlakavein.n.01')\",\n",
       " \"Synset('sõstravein.n.01')\",\n",
       " \"Synset('mustasõstravein.n.01')\",\n",
       " \"Synset('punasesõstravein.n.01')\",\n",
       " \"Synset('peet.n.03')\",\n",
       " \"Synset('punane vein.n.01')\",\n",
       " \"Synset('valge vein.n.01')\",\n",
       " \"Synset('riisling.n.01')\",\n",
       " \"Synset('klarett.n.01')\",\n",
       " \"Synset('armulauavein.n.01')\",\n",
       " \"Synset('palmivein.n.01')\",\n",
       " \"Synset('madeira.n.01')\",\n",
       " \"Synset('jäävein.n.01')\",\n",
       " \"Synset('meevein.n.01')\",\n",
       " \"Synset('pakivein.n.01')\",\n",
       " \"Synset('piiritusvein.n.01')\",\n",
       " \"Synset('eggnog.n.01')\",\n",
       " \"Synset('naps.n.02')\",\n",
       " \"Synset('viin.n.01')\",\n",
       " \"Synset('paalinka.n.01')\",\n",
       " \"Synset('starka.n.01')\",\n",
       " \"Synset('atsissina.n.01')\",\n",
       " \"Synset('grappa.n.01')\",\n",
       " \"Synset('arrak.n.01')\",\n",
       " \"Synset('kosjaviin.n.01')\",\n",
       " \"Synset('salaviin.n.01')\",\n",
       " \"Synset('kadakaviin.n.01')\",\n",
       " \"Synset('kartuliviin.n.01')\",\n",
       " \"Synset('kompressiviin.n.01')\",\n",
       " \"Synset('köömneviin.n.01')\",\n",
       " \"Synset('lauaviin.n.01')\",\n",
       " \"Synset('lihtviin.n.01')\",\n",
       " \"Synset('peenviin.n.01')\",\n",
       " \"Synset('pihlakaviin.n.01')\",\n",
       " \"Synset('pipraviin.n.01')\",\n",
       " \"Synset('ploomiviin.n.01')\",\n",
       " \"Synset('pulmaviin.n.01')\",\n",
       " \"Synset('põleviin.n.01')\",\n",
       " \"Synset('riigiviin.n.01')\",\n",
       " \"Synset('taksoviin.n.01')\",\n",
       " \"Synset('terviseviin.n.01')\",\n",
       " \"Synset('õunaviin.n.01')\",\n",
       " \"Synset('kroonuviin.n.01')\",\n",
       " \"Synset('subrovka.n.01')\",\n",
       " \"Synset('siider.n.01')\",\n",
       " \"Synset('pirnisiider.n.01')\",\n",
       " \"Synset('õunasiider.n.01')\",\n",
       " \"Synset('puskar.n.01')\",\n",
       " \"Synset('aperitiiv.n.01')\",\n",
       " \"Synset('brändi.n.01')\",\n",
       " \"Synset('armanjak.n.01')\",\n",
       " \"Synset('kalvados.n.01')\",\n",
       " \"Synset('konjak.n.01')\",\n",
       " \"Synset('liköör.n.01')\",\n",
       " \"Synset('aniisiliköör.n.01')\",\n",
       " \"Synset('benediktiin.n.01')\",\n",
       " \"Synset('šartröös.n.01')\",\n",
       " \"Synset('nalivka.n.01')\",\n",
       " \"Synset('kürassao.n.01')\",\n",
       " \"Synset('rumm.n.01')\",\n",
       " \"Synset('õlts.n.01')\",\n",
       " \"Synset('linnaseõlu.n.01')\",\n",
       " \"Synset('odraõlu.n.01')\",\n",
       " \"Synset('poeõlu.n.01')\",\n",
       " \"Synset('pudeliõlu.n.01')\",\n",
       " \"Synset('pulmaõlu.n.01')\",\n",
       " \"Synset('pühadeõlu.n.01')\",\n",
       " \"Synset('jõuluõlu.n.01')\",\n",
       " \"Synset('maisiõlu.n.01')\",\n",
       " \"Synset('riisiõlu.n.01')\",\n",
       " \"Synset('kadakaõlu.n.01')\",\n",
       " \"Synset('matuseõlu.n.01')\",\n",
       " \"Synset('paias.n.01')\",\n",
       " \"Synset('tume õlu.n.01')\",\n",
       " \"Synset('porter.n.01')\",\n",
       " \"Synset('laager.n.04')\",\n",
       " \"Synset('pilsner.n.01')\",\n",
       " \"Synset('bock.n.01')\",\n",
       " \"Synset('jääõlu.n.01')\",\n",
       " \"Synset('koduõlu.n.01')\",\n",
       " \"Synset('porsaõlu.n.01')\",\n",
       " \"Synset('purgiõlu.n.01')\",\n",
       " \"Synset('ingveriõlu.n.01')\",\n",
       " \"Synset('hele õlu.n.01')\",\n",
       " \"Synset('vaadiõlu.n.01')\",\n",
       " \"Synset('mõdu.n.01')\",\n",
       " \"Synset('linnasejook.n.01')\",\n",
       " \"Synset('pulmajook.n.01')\",\n",
       " \"Synset('pulmapass.n.01')\",\n",
       " \"Synset('märjuke.n.01')\",\n",
       " \"Synset('viski.n.01')\",\n",
       " \"Synset('džinn.n.01')\",\n",
       " \"Synset('kumõss.n.01')\",\n",
       " \"Synset('tequila.n.01')\",\n",
       " \"Synset('tulivesi.n.01')\",\n",
       " \"Synset('riisivein.n.01')\",\n",
       " \"Synset('sake.n.02')\",\n",
       " \"Synset('mirin.n.01')\",\n",
       " \"Synset('akvaviit.n.01')\",\n",
       " \"Synset('lauluõli.n.01')\",\n",
       " \"Synset('absint.n.01')\",\n",
       " \"Synset('bitter.n.01')\",\n",
       " \"Synset('grokk.n.01')\",\n",
       " \"Synset('karastusjook.n.01')\",\n",
       " \"Synset('limonaad.n.01')\",\n",
       " \"Synset('pepsikoola.n.01')\",\n",
       " \"Synset('toonik.n.01')\",\n",
       " \"Synset('tarhun.n.01')\",\n",
       " \"Synset('kokakoola.n.01')\",\n",
       " \"Synset('kohv.n.01')\",\n",
       " \"Synset('sigurikohv.n.01')\",\n",
       " \"Synset('tammetõrukohv.n.01')\",\n",
       " \"Synset('topeltkohv.n.01')\",\n",
       " \"Synset('jäätisekohv.n.01')\",\n",
       " \"Synset('caffe latte.n.01')\",\n",
       " \"Synset('cappuccino.n.01')\",\n",
       " \"Synset('espresso.n.01')\",\n",
       " \"Synset('hommikukohv.n.01')\",\n",
       " \"Synset('jääkohv.n.01')\",\n",
       " \"Synset('kannukohv.n.01')\",\n",
       " \"Synset('koorekohv.n.01')\",\n",
       " \"Synset('masinakohv.n.01')\",\n",
       " \"Synset('mokakohv.n.01')\",\n",
       " \"Synset('viljakohv.n.01')\",\n",
       " \"Synset('oakohv.n.01')\",\n",
       " \"Synset('presskannukohv.n.01')\",\n",
       " \"Synset('maitsekohv.n.01')\",\n",
       " \"Synset('piimakohv.n.01')\",\n",
       " \"Synset('naturaalkohv.n.01')\",\n",
       " \"Synset('filtrikohv.n.01')\",\n",
       " \"Synset('tee.n.05')\",\n",
       " \"Synset('ravimtee.n.01')\",\n",
       " \"Synset('kotitee.n.01')\",\n",
       " \"Synset('taimetee.n.01')\",\n",
       " \"Synset('piparmünditee.n.01')\",\n",
       " \"Synset('jasmiinitee.n.01')\",\n",
       " \"Synset('kasepahatee.n.01')\",\n",
       " \"Synset('koirohutee.n.01')\",\n",
       " \"Synset('kummelitee.n.01')\",\n",
       " \"Synset('köömnetee.n.01')\",\n",
       " \"Synset('leesikatee.n.01')\",\n",
       " \"Synset('matetee.n.01')\",\n",
       " \"Synset('melissitee.n.01')\",\n",
       " \"Synset('mustasõstratee.n.01')\",\n",
       " \"Synset('nurmenukutee.n.01')\",\n",
       " \"Synset('nõmmeliivatee.n.01')\",\n",
       " \"Synset('paiselehetee.n.01')\",\n",
       " \"Synset('kibuvitsatee.n.01')\",\n",
       " \"Synset('pohlatee.n.01')\",\n",
       " \"Synset('pärnaõietee.n.01')\",\n",
       " \"Synset('raudrohutee.n.01')\",\n",
       " \"Synset('salveitee.n.01')\",\n",
       " \"Synset('tammekooretee.n.01')\",\n",
       " \"Synset('vaarikatee.n.01')\",\n",
       " \"Synset('ürditee.n.01')\",\n",
       " \"Synset('saialilletee.n.01')\",\n",
       " \"Synset('apteegitillitee.n.01')\",\n",
       " \"Synset('kortslehetee.n.01')\",\n",
       " \"Synset('nõgesetee.n.01')\",\n",
       " \"Synset('võililletee.n.01')\",\n",
       " \"Synset('purutee.n.01')\",\n",
       " \"Synset('must tee.n.01')\",\n",
       " \"Synset('roheline tee.n.01')\",\n",
       " \"Synset('morss.n.01')\",\n",
       " \"Synset('jõhvikajook.n.01')\",\n",
       " \"Synset('mahl.n.01')\",\n",
       " \"Synset('kookosmahl.n.01')\",\n",
       " \"Synset('täismahl.n.01')\",\n",
       " \"Synset('segamahl.n.01')\",\n",
       " \"Synset('nektar.n.02')\",\n",
       " \"Synset('ploomimehu.n.01')\",\n",
       " \"Synset('porgandimehu.n.01')\",\n",
       " \"Synset('õunamehu.n.01')\",\n",
       " \"Synset('puuviljamahl.n.01')\",\n",
       " \"Synset('ploomimahl.n.01')\",\n",
       " \"Synset('apelsinimahl.n.01')\",\n",
       " \"Synset('ananassimahl.n.01')\",\n",
       " \"Synset('õunamahl.n.01')\",\n",
       " \"Synset('sidrunimahl.n.01')\",\n",
       " \"Synset('aprikoosimahl.n.01')\",\n",
       " \"Synset('kirsimahl.n.01')\",\n",
       " \"Synset('mandariinimahl.n.01')\",\n",
       " \"Synset('mangomahl.n.01')\",\n",
       " \"Synset('pirnimahl.n.01')\",\n",
       " \"Synset('virsikumahl.n.01')\",\n",
       " \"Synset('viinamarjamahl.n.01')\",\n",
       " \"Synset('palmimahl.n.01')\",\n",
       " \"Synset('toormahl.n.01')\",\n",
       " \"Synset('marjamahl.n.01')\",\n",
       " \"Synset('arooniamahl.n.01')\",\n",
       " \"Synset('astelpajumahl.n.01')\",\n",
       " \"Synset('jõhvikamahl.n.01')\",\n",
       " \"Synset('karusmarjamahl.n.01')\",\n",
       " \"Synset('maasikamahl.n.01')\",\n",
       " \"Synset('murakamahl.n.01')\",\n",
       " \"Synset('mustikamahl.n.01')\",\n",
       " \"Synset('sõstramahl.n.01')\",\n",
       " \"Synset('mustasõstramahl.n.01')\",\n",
       " \"Synset('punasesõstramahl.n.01')\",\n",
       " \"Synset('vaarikamahl.n.01')\",\n",
       " \"Synset('köögiviljamahl.n.01')\",\n",
       " \"Synset('spinatimahl.n.01')\",\n",
       " \"Synset('juurviljamahl.n.01')\",\n",
       " \"Synset('porgandimahl.n.01')\",\n",
       " \"Synset('tomatimahl.n.01')\",\n",
       " \"Synset('kapsamahl.n.01')\",\n",
       " \"Synset('kurgimahl.n.01')\",\n",
       " \"Synset('peedimahl.n.01')\",\n",
       " \"Synset('rabarberimahl.n.01')\",\n",
       " \"Synset('vahtramahl.n.01')\",\n",
       " \"Synset('kasemahl.n.01')\",\n",
       " \"Synset('energiajook.n.01')\",\n",
       " \"Synset('kakao.n.01')\",\n",
       " \"Synset('kokteil.n.01')\",\n",
       " \"Synset('jäätisekokteil.n.01')\",\n",
       " \"Synset('piimakokteil.n.01')\",\n",
       " \"Synset('mahlakokteil.n.01')\",\n",
       " \"Synset('munakokteil.n.01')\",\n",
       " \"Synset('viinakokteil.n.01')\",\n",
       " \"Synset('punš.n.01')\",\n",
       " \"Synset('todi.n.01')\",\n",
       " \"Synset('krüšoon.n.01')\",\n",
       " \"Synset('nektar.n.03')\",\n",
       " \"Synset('sidrunijook.n.01')\",\n",
       " \"Synset('spordijook.n.01')\",\n",
       " \"Synset('bool.n.01')\",\n",
       " \"Synset('digestiiv.n.01')\",\n",
       " \"Synset('mahedik.n.01')\",\n",
       " \"Synset('glögi.n.01')\",\n",
       " \"Synset('airaan.n.01')\",\n",
       " \"Synset('kadajataar.n.01')\",\n",
       " \"Synset('rokepiim.n.01')\",\n",
       " \"Synset('toit.n.02')\",\n",
       " \"Synset('soolaseen.n.01')\",\n",
       " \"Synset('batoon.n.01')\",\n",
       " \"Synset('kakaobatoon.n.01')\",\n",
       " \"Synset('piimabatoon.n.01')\",\n",
       " \"Synset('sööde.n.01')\",\n",
       " \"Synset('substraat.n.01')\",\n",
       " \"Synset('toidulisand.n.01')\",\n",
       " \"Synset('polüvitamiin.n.01')\",\n",
       " \"Synset('mineraalainesegu.n.01')\",\n",
       " \"Synset('mineraalaine.n.02')\",\n",
       " \"Synset('kroomipreparaat.n.01')\",\n",
       " \"Synset('kroomnikotinaat.n.01')\",\n",
       " \"Synset('kroompikolinaat.n.01')\",\n",
       " \"Synset('kroomkloriid.n.01')\",\n",
       " \"Synset('põhitoitaine.n.01')\",\n",
       " \"Synset('taimetoitaine.n.01')\",\n",
       " \"Synset('kaitsetoitaine.n.01')\",\n",
       " \"Synset('toiduaine.n.01')\",\n",
       " \"Synset('riisipaber.n.01')\",\n",
       " \"Synset('krabinuudlid.n.01')\",\n",
       " \"Synset('tee.n.08')\",\n",
       " \"Synset('udemetee.n.01')\",\n",
       " \"Synset('rooibos.n.01')\",\n",
       " \"Synset('mädarõigas.n.02')\",\n",
       " \"Synset('pekk.n.02')\",\n",
       " \"Synset('täidis.n.04')\",\n",
       " \"Synset('liha.n.01')\",\n",
       " \"Synset('pähkeltükk.n.01')\",\n",
       " \"Synset('antrekoot.n.02')\",\n",
       " \"Synset('maks.n.04')\",\n",
       " \"Synset('vinnutatud liha.n.01')\",\n",
       " \"Synset('talleliha.n.01')\",\n",
       " \"Synset('põrsaliha.n.01')\",\n",
       " \"Synset('põdraliha.n.01')\",\n",
       " \"Synset('haneliha.n.01')\",\n",
       " \"Synset('hobuseliha.n.01')\",\n",
       " \"Synset('hakkliha.n.01')\",\n",
       " \"Synset('lambaliha.n.01')\",\n",
       " \"Synset('linnuliha.n.01')\",\n",
       " \"Synset('loomaliha.n.01')\",\n",
       " \"Synset('biifsteek.n.01')\",\n",
       " \"Synset('seljatükk.n.01')\",\n",
       " \"Synset('romsteek.n.01')\",\n",
       " \"Synset('rostbiif.n.01')\",\n",
       " \"Synset('vasikaliha.n.01')\",\n",
       " \"Synset('sealiha.n.01')\",\n",
       " \"Synset('peekon.n.01')\",\n",
       " \"Synset('rups.n.01')\",\n",
       " \"Synset('päädikud.n.01')\",\n",
       " \"Synset('tai.n.01')\",\n",
       " \"Synset('kana.n.02')\",\n",
       " \"Synset('metslooma liha.n.01')\",\n",
       " \"Synset('lihakeha.n.01')\",\n",
       " \"Synset('kalarümp.n.01')\",\n",
       " \"Synset('lihasaadus.n.01')\",\n",
       " \"Synset('sink.n.01')\",\n",
       " \"Synset('rullsink.n.01')\",\n",
       " \"Synset('keedusink.n.01')\",\n",
       " \"Synset('maasink.n.01')\",\n",
       " \"Synset('vinnutatud sink.n.01')\",\n",
       " \"Synset('veisesink.n.01')\",\n",
       " \"Synset('kalkunisink.n.01')\",\n",
       " \"Synset('kanasink.n.01')\",\n",
       " \"Synset('kanafileesink.n.01')\",\n",
       " \"Synset('vormisink.n.01')\",\n",
       " \"Synset('toorsink.n.01')\",\n",
       " \"Synset('seasink.n.01')\",\n",
       " \"Synset('Parma sink.n.01')\",\n",
       " \"Synset('rulaad.n.01')\",\n",
       " \"Synset('konserv.n.02')\",\n",
       " \"Synset('pemmikan.n.01')\",\n",
       " \"Synset('võrkkelme.n.01')\",\n",
       " \"Synset('vorst.n.01')\",\n",
       " \"Synset('hobuselihavorst.n.01')\",\n",
       " \"Synset('mauk.n.01')\",\n",
       " \"Synset('sardell.n.01')\",\n",
       " \"Synset('viiner.n.01')\",\n",
       " \"Synset('suitsuviiner.n.01')\",\n",
       " \"Synset('miniviiner.n.01')\",\n",
       " \"Synset('grillviiner.n.01')\",\n",
       " \"Synset('verivorst.n.01')\",\n",
       " \"Synset('maksavorst.n.01')\",\n",
       " \"Synset('kabanoss.n.01')\",\n",
       " \"Synset('keeduvorst.n.01')\",\n",
       " \"Synset('teevorst.n.01')\",\n",
       " \"Synset('rupskivorst.n.01')\",\n",
       " \"Synset('keelevorst.n.01')\",\n",
       " \"Synset('doktorivorst.n.01')\",\n",
       " \"Synset('jahuvorst.n.01')\",\n",
       " \"Synset('makk.n.02')\",\n",
       " \"Synset('tanguvorst.n.01')\",\n",
       " \"Synset('salaami.n.01')\",\n",
       " \"Synset('grillvorst.n.01')\",\n",
       " \"Synset('pipravorst.n.01')\",\n",
       " \"Synset('frankfurter.n.01')\",\n",
       " \"Synset('vorstirõngas.n.01')\",\n",
       " \"Synset('vorstikang.n.01')\",\n",
       " \"Synset('sültvorst.n.01')\",\n",
       " \"Synset('sealihavorst.n.01')\",\n",
       " \"Synset('saunavorst.n.01')\",\n",
       " \"Synset('põdravorst.n.01')\",\n",
       " \"Synset('pekkvorst.n.01')\",\n",
       " \"Synset('lihavorst.n.01')\",\n",
       " \"Synset('küüslauguvorst.n.01')\",\n",
       " \"Synset('suitsuvorst.n.01')\",\n",
       " \"Synset('poolsuitsuvorst.n.01')\",\n",
       " \"Synset('täissuitsuvorst.n.01')\",\n",
       " \"Synset('knakkvorst.n.01')\",\n",
       " \"Synset('Bologna vorst.n.01')\",\n",
       " \"Synset('juustuvorst.n.01')\",\n",
       " \"Synset('jahivorst.n.01')\",\n",
       " \"Synset('jäneseliha.n.01')\",\n",
       " \"Synset('filee.n.01')\",\n",
       " \"Synset('välisfilee.n.01')\",\n",
       " \"Synset('kalafilee.n.01')\",\n",
       " \"Synset('kanafilee.n.01')\",\n",
       " \"Synset('veisefilee.n.01')\",\n",
       " \"Synset('sisefilee.n.01')\",\n",
       " \"Synset('koot.n.01')\",\n",
       " \"Synset('karbonaad.n.01')\",\n",
       " \"Synset('kala.n.02')\",\n",
       " \"Synset('soolasiig.n.01')\",\n",
       " \"Synset('balõkk.n.01')\",\n",
       " \"Synset('surimi.n.01')\",\n",
       " \"Synset('vääriskala.n.01')\",\n",
       " \"Synset('jukola.n.01')\",\n",
       " \"Synset('äkine.n.01')\",\n",
       " \"Synset('rasvaine.n.01')\",\n",
       " \"Synset('margariin.n.01')\",\n",
       " \"Synset('rasv.n.02')\",\n",
       " \"Synset('searasv.n.01')\",\n",
       " \"Synset('hanerasv.n.01')\",\n",
       " \"Synset('juuretis.n.01')\",\n",
       " \"Synset('bakterijuuretis.n.01')\",\n",
       " \"Synset('pärm.n.01')\",\n",
       " \"Synset('kuivpärm.n.01')\",\n",
       " \"Synset('maitsepärm.n.01')\",\n",
       " \"Synset('presspärm.n.01')\",\n",
       " \"Synset('kuivaine.n.01')\",\n",
       " \"Synset('maniokitärklis.n.01')\",\n",
       " \"Synset('tapiokk.n.01')\",\n",
       " \"Synset('jahu.n.02')\",\n",
       " \"Synset('kikerhernejahu.n.01')\",\n",
       " \"Synset('sojajahu.n.01')\",\n",
       " \"Synset('mitmeviljajahu.n.01')\",\n",
       " \"Synset('odrajahu.n.01')\",\n",
       " \"Synset('sõmerik.n.01')\",\n",
       " \"Synset('mandlijahu.n.01')\",\n",
       " \"Synset('gluteenijahu.n.01')\",\n",
       " \"Synset('jaanikaunajahu.n.01')\",\n",
       " \"Synset('kaerajahu.n.01')\",\n",
       " \"Synset('keeksipulber.n.01')\",\n",
       " \"Synset('muffinipulber.n.01')\",\n",
       " \"Synset('rukkijahu.n.01')\",\n",
       " \"Synset('nisujahu.n.01')\",\n",
       " \"Synset('tordipulber.n.01')\",\n",
       " \"Synset('manna.n.01')\",\n",
       " \"Synset('polenta.n.01')\",\n",
       " \"Synset('püül.n.01')\",\n",
       " \"Synset('tatrajahu.n.01')\",\n",
       " \"Synset('riisijahu.n.01')\",\n",
       " \"Synset('pannkoogijahu.n.01')\",\n",
       " \"Synset('maisijahu.n.01')\",\n",
       " \"Synset('kohv.n.02')\",\n",
       " \"Synset('araabika.n.01')\",\n",
       " \"Synset('kakao.n.03')\",\n",
       " \"Synset('toorkakao.n.01')\",\n",
       " \"Synset('riis.n.02')\",\n",
       " \"Synset('risotoriis.n.01')\",\n",
       " \"Synset('basmatiriis.n.01')\",\n",
       " \"Synset('jasmiiniriis.n.01')\",\n",
       " \"Synset('pruun riis.n.01')\",\n",
       " \"Synset('poleeritud riis.n.01')\",\n",
       " \"Synset('riivsai.n.01')\",\n",
       " \"Synset('maisitärklis.n.01')\",\n",
       " \"Synset('puljongikuubik.n.01')\",\n",
       " \"Synset('kamajahu.n.01')\",\n",
       " \"Synset('kaerakamajahu.n.01')\",\n",
       " \"Synset('mulgi kama.n.01')\",\n",
       " \"Synset('saago.n.01')\",\n",
       " \"Synset('kartulijahu.n.01')\",\n",
       " \"Synset('riivleib.n.01')\",\n",
       " \"Synset('siirup.n.01')\",\n",
       " \"Synset('sibulasiirup.n.01')\",\n",
       " \"Synset('marjasiirup.n.01')\",\n",
       " \"Synset('vaarikasiirup.n.01')\",\n",
       " \"Synset('puuviljasiirup.n.01')\",\n",
       " \"Synset('kirsisiirup.n.01')\",\n",
       " \"Synset('sidrunisiirup.n.01')\",\n",
       " \"Synset('melass.n.01')\",\n",
       " \"Synset('vahtrasiirup.n.01')\",\n",
       " \"Synset('peedisiirup.n.01')\",\n",
       " \"Synset('tainas.n.01')\",\n",
       " \"Synset('leivataigen.n.01')\",\n",
       " \"Synset('pärmitaigen.n.01')\",\n",
       " \"Synset('lehttainas.n.01')\",\n",
       " \"Synset('keedutainas.n.01')\",\n",
       " \"Synset('muretaigen.n.01')\",\n",
       " \"Synset('liivataigen.n.01')\",\n",
       " \"Synset('filotainas.n.01')\",\n",
       " \"Synset('nori.n.01')\",\n",
       " \"Synset('želatiin.n.01')\",\n",
       " \"Synset('lehtželatiin.n.01')\",\n",
       " \"Synset('marinaad.n.01')\",\n",
       " \"Synset('krabimaitselised pulgad.n.01')\",\n",
       " \"Synset('koostisaine.n.01')\",\n",
       " \"Synset('meedium.n.04')\",\n",
       " \"Synset('tihkesti.n.01')\",\n",
       " \"Synset('maitseaine.n.01')\",\n",
       " \"Synset('essents.n.03')\",\n",
       " \"Synset('rummiessents.n.01')\",\n",
       " \"Synset('tšilli.n.02')\",\n",
       " \"Synset('suhkur.n.01')\",\n",
       " \"Synset('karamell.n.02')\",\n",
       " \"Synset('vahtrasuhkur.n.01')\",\n",
       " \"Synset('paastusuhkur.n.01')\",\n",
       " \"Synset('peasuhkur.n.01')\",\n",
       " \"Synset('peensuhkur.n.01')\",\n",
       " \"Synset('rafinaad.n.01')\",\n",
       " \"Synset('kookossuhkur.n.01')\",\n",
       " \"Synset('fruktoos.n.01')\",\n",
       " \"Synset('brülee.n.01')\",\n",
       " \"Synset('glükoos.n.01')\",\n",
       " \"Synset('veresuhkur.n.01')\",\n",
       " \"Synset('tolmsuhkur.n.01')\",\n",
       " \"Synset('suhkrupea.n.01')\",\n",
       " \"Synset('toorsuhkur.n.01')\",\n",
       " \"Synset('fariinsuhkur.n.01')\",\n",
       " \"Synset('tükksuhkur.n.01')\",\n",
       " \"Synset('demerara suhkur.n.01')\",\n",
       " \"Synset('pärlsuhkur.n.01')\",\n",
       " \"Synset('džemmisuhkur.n.01')\",\n",
       " \"Synset('vanillisuhkur.n.01')\",\n",
       " \"Synset('sool.n.02')\",\n",
       " \"Synset('jäme sool.n.01')\",\n",
       " \"Synset('peenike sool.n.01')\",\n",
       " \"Synset('soolahelbed.n.01')\",\n",
       " \"Synset('meresool.n.01')\",\n",
       " \"Synset('vürts.n.01')\",\n",
       " \"Synset('jahvatatud paprika.n.01')\",\n",
       " \"Synset('ingver.n.01')\",\n",
       " \"Synset('harilik ingver.n.01')\",\n",
       " \"Synset('koriander.n.01')\",\n",
       " \"Synset('kardemon.n.01')\",\n",
       " \"Synset('pipar.n.01')\",\n",
       " \"Synset('roseepipar.n.01')\",\n",
       " \"Synset('loorber.n.01')\",\n",
       " \"Synset('vürtsisegu.n.01')\",\n",
       " \"Synset('karri.n.01')\",\n",
       " \"Synset('viievürtsisegu.n.01')\",\n",
       " \"Synset('piparkoogimaitseaine.n.01')\",\n",
       " \"Synset('garam masala.n.01')\",\n",
       " \"Synset('muskaat.n.01')\",\n",
       " \"Synset('piment.n.01')\",\n",
       " \"Synset('nelk.n.01')\",\n",
       " \"Synset('nurmnelk.n.01')\",\n",
       " \"Synset('kaneel.n.01')\",\n",
       " \"Synset('vürtsköömen.n.01')\",\n",
       " \"Synset('safran.n.01')\",\n",
       " \"Synset('kurkum.n.01')\",\n",
       " \"Synset('muskaatpähkel.n.01')\",\n",
       " \"Synset('tamarind.n.01')\",\n",
       " \"Synset('aniispipar.n.01')\",\n",
       " \"Synset('apteegitilli seemned.n.01')\",\n",
       " \"Synset('tähtaniis.n.01')\",\n",
       " \"Synset('äädikas.n.01')\",\n",
       " \"Synset('palsamiäädikas.n.01')\",\n",
       " \"Synset('riisiäädikas.n.01')\",\n",
       " \"Synset('veiniäädikas.n.01')\",\n",
       " \"Synset('punase veini äädikas.n.01')\",\n",
       " \"Synset('valge veini äädikas.n.01')\",\n",
       " \"Synset('linnaseäädikas.n.01')\",\n",
       " \"Synset('vanill.n.01')\",\n",
       " \"Synset('sojakaste.n.01')\",\n",
       " \"Synset('roosivesi.n.01')\",\n",
       " \"Synset('austrikaste.n.01')\",\n",
       " \"Synset('kardemoniseemned.n.01')\",\n",
       " \"Synset('sinep.n.02')\",\n",
       " \"Synset('inglise sinep.n.01')\",\n",
       " \"Synset('Dijoni sinep.n.01')\",\n",
       " \"Synset('teraline sinep.n.01')\",\n",
       " \"Synset('kassia.n.01')\",\n",
       " \"Synset('vanillikaun.n.01')\",\n",
       " \"Synset('vanilliin.n.01')\",\n",
       " \"Synset('ketšup.n.01')\",\n",
       " \"Synset('tšatni.n.01')\",\n",
       " \"Synset('adžika.n.01')\",\n",
       " \"Synset('matcha.n.01')\",\n",
       " \"Synset('vanilliekstrakt.n.02')\",\n",
       " \"Synset('pärmiekstrakt.n.01')\",\n",
       " \"Synset('muna.n.02')\",\n",
       " \"Synset('jaanalinnumuna.n.01')\",\n",
       " \"Synset('mädamuna.n.01')\",\n",
       " \"Synset('kalkunimuna.n.01')\",\n",
       " \"Synset('faasanimuna.n.01')\",\n",
       " \"Synset('hanemuna.n.01')\",\n",
       " \"Synset('munapulber.n.01')\",\n",
       " \"Synset('rebu.n.01')\",\n",
       " \"Synset('pesamuna.n.02')\",\n",
       " \"Synset('haudemuna.n.01')\",\n",
       " \"Synset('kanamuna.n.01')\",\n",
       " \"Synset('linnumuna.n.01')\",\n",
       " \"Synset('pardimuna.n.01')\",\n",
       " \"Synset('vutimuna.n.01')\",\n",
       " \"Synset('munavalge.n.01')\",\n",
       " \"Synset('agar-agar.n.01')\",\n",
       " \"Synset('bambusevõrsed.n.01')\",\n",
       " \"Synset('kergitusaine.n.01')\",\n",
       " \"Synset('küpsetuspulber.n.01')\",\n",
       " \"Synset('kääritusaine.n.01')\",\n",
       " \"Synset('toit.n.01')\",\n",
       " \"Synset('püree.n.01')\",\n",
       " \"Synset('kartulipuder.n.01')\",\n",
       " \"Synset('köögiviljapüree.n.01')\",\n",
       " \"Synset('tomatipüree.n.01')\",\n",
       " \"Synset('juurviljapüree.n.01')\",\n",
       " \"Synset('hernepüree.n.01')\",\n",
       " \"Synset('kõrvitsapüree.n.01')\",\n",
       " \"Synset('porgandipüree.n.01')\",\n",
       " \"Synset('spinatipüree.n.01')\",\n",
       " \"Synset('marjapüree.n.01')\",\n",
       " \"Synset('puuviljapüree.n.01')\",\n",
       " \"Synset('õunapüree.n.01')\",\n",
       " \"Synset('friikartul.n.01')\",\n",
       " \"Synset('falafel.n.01')\",\n",
       " \"Synset('pilaff.n.01')\",\n",
       " \"Synset('taimetoit.n.01')\",\n",
       " \"Synset('hapukapsas.n.01')\",\n",
       " \"Synset('tofu.n.01')\",\n",
       " \"Synset('hefu.n.01')\",\n",
       " \"Synset('tempeh.n.01')\",\n",
       " \"Synset('tartar.n.01')\",\n",
       " \"Synset('jahuvõi.n.01')\",\n",
       " \"Synset('pitsa.n.01')\",\n",
       " \"Synset('vorstipitsa.n.01')\",\n",
       " \"Synset('singipitsa.n.01')\",\n",
       " \"Synset('Sitsiilia pitsa.n.01')\",\n",
       " \"Synset('juustupitsa.n.01')\",\n",
       " \"Synset('pepperonipitsa.n.01')\",\n",
       " \"Synset('pelmeen.n.01')\",\n",
       " \"Synset('peatoidus.n.02')\",\n",
       " \"Synset('tsepeliin.n.01')\",\n",
       " \"Synset('maius.n.01')\",\n",
       " \"Synset('šerbett.n.01')\",\n",
       " \"Synset('kompvek.n.01')\",\n",
       " \"Synset('piparmündikomm.n.01')\",\n",
       " \"Synset('nätsukomm.n.01')\",\n",
       " \"Synset('toffee.n.01')\",\n",
       " \"Synset('karamellkompvek.n.01')\",\n",
       " \"Synset('trops.n.01')\",\n",
       " \"Synset('padjakomm.n.01')\",\n",
       " \"Synset('dražee.n.01')\",\n",
       " \"Synset('pralinee.n.01')\",\n",
       " \"Synset('pulgakomm.n.01')\",\n",
       " \"Synset('iiris.n.03')\",\n",
       " \"Synset('vahukomm.n.01')\",\n",
       " \"Synset('kummikomm.n.01')\",\n",
       " \"Synset('venis.n.01')\",\n",
       " \"Synset('koorekomm.n.01')\",\n",
       " \"Synset('lehmakomm.n.01')\",\n",
       " \"Synset('lagritsakompvek.n.01')\",\n",
       " \"Synset('martsipanikomm.n.01')\",\n",
       " \"Synset('marmelaadikomm.n.01')\",\n",
       " \"Synset('vahvlikomm.n.01')\",\n",
       " \"Synset('pähklikomm.n.01')\",\n",
       " \"Synset('liköörikomm.n.01')\",\n",
       " \"Synset('brändipall.n.01')\",\n",
       " \"Synset('purgikomm.n.01')\",\n",
       " \"Synset('pumatikomm.n.01')\",\n",
       " \"Synset('šokolaad.n.01')\",\n",
       " \"Synset('pastilaa.n.01')\",\n",
       " \"Synset('martsipan.n.01')\",\n",
       " \"Synset('nugat.n.01')\",\n",
       " \"Synset('trühvel.n.01')\",\n",
       " \"Synset('kohuke.n.01')\",\n",
       " \"Synset('halvaa.n.01')\",\n",
       " \"Synset('suhkruvatt.n.01')\",\n",
       " \"Synset('griljaaž.n.01')\",\n",
       " \"Synset('nonparell.n.01')\",\n",
       " \"Synset('sukaad.n.01')\",\n",
       " \"Synset('apelsinisukaad.n.01')\",\n",
       " \"Synset('emapiimaasendaja.n.01')\",\n",
       " \"Synset('fondüü.n.01')\",\n",
       " \"Synset('juustufondüü.n.01')\",\n",
       " \"Synset('šokolaadifondüü.n.01')\",\n",
       " \"Synset('kalapulk.n.01')\",\n",
       " \"Synset('barbecue.n.01')\",\n",
       " \"Synset('gratään.n.01')\",\n",
       " \"Synset('ahjutoit.n.01')\",\n",
       " \"Synset('beebitoit.n.01')\",\n",
       " \"Synset('eritoit.n.01')\",\n",
       " \"Synset('kanepitoit.n.01')\",\n",
       " \"Synset('kartulitoit.n.01')\",\n",
       " \"Synset('katsikutoit.n.01')\",\n",
       " \"Synset('konservtoit.n.01')\",\n",
       " \"Synset('kuivtoit.n.01')\",\n",
       " \"Synset('krõbusk.n.01')\",\n",
       " \"Synset('lastetoit.n.01')\",\n",
       " \"Synset('lemmiktoit.n.01')\",\n",
       " \"Synset('lisatoit.n.01')\",\n",
       " \"Synset('maatoit.n.01')\",\n",
       " \"Synset('makaronitoit.n.01')\",\n",
       " \"Synset('paastutoit.n.01')\",\n",
       " \"Synset('peatoit.n.01')\",\n",
       " \"Synset('peietoit.n.01')\",\n",
       " \"Synset('piimatoit.n.01')\",\n",
       " \"Synset('kodutoit.n.01')\",\n",
       " \"Synset('pühadetoit.n.01')\",\n",
       " \"Synset('jõulutoit.n.01')\",\n",
       " \"Synset('nääritoit.n.01')\",\n",
       " \"Synset('rahvustoit.n.01')\",\n",
       " \"Synset('rämpstoit.n.01')\",\n",
       " \"Synset('sabatitoit.n.01')\",\n",
       " \"Synset('seenetoit.n.01')\",\n",
       " \"Synset('sõduritoit.n.01')\",\n",
       " \"Synset('sööklatoit.n.01')\",\n",
       " \"Synset('taimtoit.n.01')\",\n",
       " \"Synset('talvetoit.n.01')\",\n",
       " \"Synset('tavanditoit.n.01')\",\n",
       " \"Synset('teratoit.n.01')\",\n",
       " \"Synset('toortoit.n.01')\",\n",
       " \"Synset('tuubitoit.n.01')\",\n",
       " \"Synset('valmistoit.n.01')\",\n",
       " \"Synset('valveroog.n.01')\",\n",
       " \"Synset('veretoit.n.01')\",\n",
       " \"Synset('vormitoit.n.01')\",\n",
       " \"Synset('leivavorm.n.02')\",\n",
       " \"Synset('juurviljavormiroog.n.01')\",\n",
       " \"Synset('kalavormiroog.n.01')\",\n",
       " \"Synset('kartulivormiroog.n.01')\",\n",
       " \"Synset('kohupiimavormiroog.n.01')\",\n",
       " \"Synset('köögiviljavormiroog.n.01')\",\n",
       " \"Synset('lihavormiroog.n.01')\",\n",
       " \"Synset('makaronivormiroog.n.01')\",\n",
       " \"Synset('rabarberivormiroog.n.01')\",\n",
       " \"Synset('riisivormiroog.n.01')\",\n",
       " \"Synset('saiavormiroog.n.01')\",\n",
       " \"Synset('seenevormiroog.n.01')\",\n",
       " \"Synset('vorstivormiroog.n.01')\",\n",
       " \"Synset('õunavormiroog.n.01')\",\n",
       " \"Synset('esindusroog.n.01')\",\n",
       " \"Synset('pühapäevaroog.n.01')\",\n",
       " \"Synset('restoraniroog.n.01')\",\n",
       " \"Synset('terriin.n.01')\",\n",
       " \"Synset('jõulukulp.n.01')\",\n",
       " \"Synset('kaljapudi.n.01')\",\n",
       " \"Synset('kneedlid.n.01')\",\n",
       " \"Synset('šnitsel.n.01')\",\n",
       " \"Synset('sültkapsad.n.01')\",\n",
       " \"Synset('taaripudi.n.01')\",\n",
       " \"Synset('õllesupp.n.01')\",\n",
       " \"Synset('pihv.n.01')\",\n",
       " \"Synset('köögiviljapihv.n.01')\",\n",
       " \"Synset('kanapihv.n.01')\",\n",
       " \"Synset('hakkpihv.n.01')\",\n",
       " \"Synset('lurr.n.01')\",\n",
       " \"Synset('kondiitritoode.n.02')\",\n",
       " \"Synset('glasuur.n.02')\",\n",
       " \"Synset('pavlova.n.01')\",\n",
       " \"Synset('fondant.n.01')\",\n",
       " \"Synset('kreem.n.02')\",\n",
       " \"Synset('võikreem.n.01')\",\n",
       " \"Synset('keedukreem.n.01')\",\n",
       " \"Synset('kondiitritoode.n.01')\",\n",
       " \"Synset('liivakook.n.02')\",\n",
       " \"Synset('vahvel.n.01')\",\n",
       " \"Synset('kook.n.01')\",\n",
       " \"Synset('hapupiimakook.n.01')\",\n",
       " \"Synset('porgandikook.n.01')\",\n",
       " \"Synset('aleksandrikook.n.01')\",\n",
       " \"Synset('keeks.n.01')\",\n",
       " \"Synset('napooleonikook.n.01')\",\n",
       " \"Synset('pannkook.n.01')\",\n",
       " \"Synset('galett.n.03')\",\n",
       " \"Synset('ülepannikook.n.01')\",\n",
       " \"Synset('lusikakook.n.01')\",\n",
       " \"Synset('pliin.n.01')\",\n",
       " \"Synset('biskviit.n.01')\",\n",
       " \"Synset('rullbiskviit.n.01')\",\n",
       " \"Synset('juustukook.n.01')\",\n",
       " \"Synset('ekläär.n.01')\",\n",
       " \"Synset('plaadikook.n.01')\",\n",
       " \"Synset('marmorkook.n.01')\",\n",
       " \"Synset('purukook.n.01')\",\n",
       " \"Synset('teekook.n.01')\",\n",
       " \"Synset('šarlott.n.01')\",\n",
       " \"Synset('tort.n.01')\",\n",
       " \"Synset('vahukooretort.n.01')\",\n",
       " \"Synset('pulmatort.n.01')\",\n",
       " \"Synset('küpsisetort.n.01')\",\n",
       " \"Synset('juustutort.n.01')\",\n",
       " \"Synset('võileivatort.n.01')\",\n",
       " \"Synset('jäätisetort.n.01')\",\n",
       " \"Synset('sefiiritort.n.01')\",\n",
       " \"Synset('napooleonitort.n.01')\",\n",
       " \"Synset('vahvlitort.n.01')\",\n",
       " \"Synset('trühveltort.n.01')\",\n",
       " \"Synset('pähklitort.n.01')\",\n",
       " \"Synset('puuviljatort.n.01')\",\n",
       " \"Synset('kreemitort.n.01')\",\n",
       " \"Synset('kohupiimatort.n.01')\",\n",
       " \"Synset('beseetort.n.01')\",\n",
       " \"Synset('sidrunitort.n.01')\",\n",
       " \"Synset('beseekook.n.01')\",\n",
       " \"Synset('kookosekook.n.01')\",\n",
       " \"Synset('õunapüreekook.n.01')\",\n",
       " \"Synset('vormikook.n.01')\",\n",
       " \"Synset('vahukoorekook.n.01')\",\n",
       " \"Synset('sünnipäevakook.n.01')\",\n",
       " \"Synset('rabarberikook.n.01')\",\n",
       " \"Synset('puuviljakook.n.01')\",\n",
       " \"Synset('virsikukook.n.01')\",\n",
       " \"Synset('õunakook.n.01')\",\n",
       " \"Synset('muretaignakook.n.01')\",\n",
       " \"Synset('munakook.n.01')\",\n",
       " \"Synset('mesikook.n.01')\",\n",
       " \"Synset('marjakook.n.01')\",\n",
       " \"Synset('karusmarjakook.n.01')\",\n",
       " \"Synset('mandlikook.n.01')\",\n",
       " \"Synset('kreemikook.n.01')\",\n",
       " \"Synset('kohupiimakook.n.01')\",\n",
       " \"Synset('herkulokook.n.01')\",\n",
       " \"Synset('küpsis.n.01')\",\n",
       " \"Synset('kõrsik.n.01')\",\n",
       " \"Synset('piparkook.n.01')\",\n",
       " \"Synset('präänik.n.01')\",\n",
       " \"Synset('galett.n.02')\",\n",
       " \"Synset('kreeker.n.01')\",\n",
       " \"Synset('pumpernikkel.n.01')\",\n",
       " \"Synset('makroon.n.01')\",\n",
       " \"Synset('mandlimakroon.n.01')\",\n",
       " \"Synset('kookosmakroon.n.01')\",\n",
       " \"Synset('kaneeliküpsis.n.01')\",\n",
       " \"Synset('soolapulk.n.01')\",\n",
       " \"Synset('porgandiküpsis.n.01')\",\n",
       " \"Synset('tatraküpsis.n.01')\",\n",
       " \"Synset('juustupulk.n.01')\",\n",
       " \"Synset('pähkliküpsis.n.01')\",\n",
       " \"Synset('pistaatsiaküpsis.n.01')\",\n",
       " \"Synset('juustuküpsis.n.01')\",\n",
       " \"Synset('rukkiküpsis.n.01')\",\n",
       " \"Synset('suhkruküpsis.n.01')\",\n",
       " \"Synset('õnneküpsis.n.01')\",\n",
       " \"Synset('rosinaküpsis.n.01')\",\n",
       " \"Synset('pähklirosinaküpsis.n.01')\",\n",
       " \"Synset('aniisiküpsis.n.01')\",\n",
       " \"Synset('keeleke.n.01')\",\n",
       " \"Synset('vürtsiküpsis.n.01')\",\n",
       " \"Synset('mureküpsis.n.01')\",\n",
       " \"Synset('ingveriküpsis.n.01')\",\n",
       " \"Synset('võiküpsis.n.01')\",\n",
       " \"Synset('koeraküpsis.n.01')\",\n",
       " \"Synset('vanilliküpsis.n.01')\",\n",
       " \"Synset('teeküpsis.n.01')\",\n",
       " \"Synset('kaeraküpsis.n.01')\",\n",
       " \"Synset('besee.n.01')\",\n",
       " \"Synset('moorapea.n.01')\",\n",
       " \"Synset('rummikook.n.01')\",\n",
       " \"Synset('jahutoode.n.01')\",\n",
       " \"Synset('müsli.n.01')\",\n",
       " \"Synset('herkulo.n.01')\",\n",
       " \"Synset('pagaritoode.n.01')\",\n",
       " \"Synset('rõngik.n.01')\",\n",
       " \"Synset('sai.n.01')\",\n",
       " \"Synset('nupsusai.n.01')\",\n",
       " \"Synset('baguette.n.01')\",\n",
       " \"Synset('rõngassai.n.01')\",\n",
       " \"Synset('kalatš.n.01')\",\n",
       " \"Synset('palmiksai.n.01')\",\n",
       " \"Synset('kringel.n.01')\",\n",
       " \"Synset('porgandikringel.n.01')\",\n",
       " \"Synset('safranikringel.n.01')\",\n",
       " \"Synset('õunakringel.n.01')\",\n",
       " \"Synset('kohupiimakringel.n.01')\",\n",
       " \"Synset('suhkrukringel.n.01')\",\n",
       " \"Synset('vahukoorekringel.n.01')\",\n",
       " \"Synset('rosinakringel.n.01')\",\n",
       " \"Synset('juustukringel.n.01')\",\n",
       " \"Synset('vesikringel.n.01')\",\n",
       " \"Synset('stritsel.n.01')\",\n",
       " \"Synset('kukkel.n.01')\",\n",
       " \"Synset('rosinakukkel.n.01')\",\n",
       " \"Synset('vastlakukkel.n.01')\",\n",
       " \"Synset('mitmeviljakukkel.n.01')\",\n",
       " \"Synset('nisukukkel.n.01')\",\n",
       " \"Synset('hamburgerikukkel.n.01')\",\n",
       " \"Synset('võikukkel.n.01')\",\n",
       " \"Synset('köömnekukkel.n.01')\",\n",
       " \"Synset('baranka.n.01')\",\n",
       " \"Synset('pirukas.n.01')\",\n",
       " \"Synset('keedisepirukas.n.01')\",\n",
       " \"Synset('peekonipirukas.n.01')\",\n",
       " \"Synset('lihapirukas.n.01')\",\n",
       " \"Synset('neerupirukas.n.01')\",\n",
       " \"Synset('Inglise neerupirukas.n.01')\",\n",
       " \"Synset('kulebjaaka.n.01')\",\n",
       " \"Synset('kapsapirukas.n.01')\",\n",
       " \"Synset('porgandipirukas.n.01')\",\n",
       " \"Synset('viineripirukas.n.01')\",\n",
       " \"Synset('kohupiimapirukas.n.01')\",\n",
       " \"Synset('seenepirukas.n.01')\",\n",
       " \"Synset('kukeseenepirukas.n.01')\",\n",
       " \"Synset('singipirukas.n.01')\",\n",
       " \"Synset('moosipirukas.n.01')\",\n",
       " \"Synset('marjapirukas.n.01')\",\n",
       " \"Synset('mustikapirukas.n.01')\",\n",
       " \"Synset('quiche.n.01')\",\n",
       " \"Synset('vareenik.n.01')\",\n",
       " \"Synset('struudel.n.01')\",\n",
       " \"Synset('spinatistruudel.n.01')\",\n",
       " \"Synset('singistruudel.n.01')\",\n",
       " \"Synset('moonistruudel.n.01')\",\n",
       " \"Synset('õunastruudel.n.01')\",\n",
       " \"Synset('kapsastruudel.n.01')\",\n",
       " \"Synset('juustustruudel.n.01')\",\n",
       " \"Synset('kohupiimastruudel.n.01')\",\n",
       " \"Synset('volovan.n.01')\",\n",
       " \"Synset('kalapirukas.n.01')\",\n",
       " \"Synset('tuunikalapirukas.n.01')\",\n",
       " \"Synset('keedukreemipirukas.n.01')\",\n",
       " \"Synset('pekaanpähklipirukas.n.01')\",\n",
       " \"Synset('rabarberipirukas.n.01')\",\n",
       " \"Synset('sidrunipirukas.n.01')\",\n",
       " \"Synset('sibulapirukas.n.01')\",\n",
       " \"Synset('kõrvitsapirukas.n.01')\",\n",
       " \"Synset('kanapirukas.n.01')\",\n",
       " \"Synset('juustupirukas.n.01')\",\n",
       " \"Synset('spinatipirukas.n.01')\",\n",
       " \"Synset('lilllkapsapirukas.n.01')\",\n",
       " \"Synset('munapirukas.n.01')\",\n",
       " \"Synset('rasvapirukas.n.01')\",\n",
       " \"Synset('plaadipirukas.n.01')\",\n",
       " \"Synset('keedupirukas.n.01')\",\n",
       " \"Synset('õunapirukas.n.01')\",\n",
       " \"Synset('riisipirukas.n.01')\",\n",
       " \"Synset('saiake.n.01')\",\n",
       " \"Synset('puruvana.n.01')\",\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toidud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1616"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(toidud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kohupiimakotlett', 'sõrnik']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toidud[1000].lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"välised.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"ressursid1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"vahe.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from estnltk import Text\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:utils_any2vec.py:274: loading projection weights from ../../AREA1/cbow_100_5_10_20/ettenten.txt.word_vectors\n",
      "INFO:utils_any2vec.py:297: loaded (470688, 100) matrix from ../../AREA1/cbow_100_5_10_20/ettenten.txt.word_vectors\n"
     ]
    }
   ],
   "source": [
    "# model from here http://193.40.33.66/pretrained/cbow_100_5_10_20.zip\n",
    "# documentation here https://github.com/eleriaedmaa/embeddings\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(\"../../AREA1/cbow_100_5_10_20/ettenten.txt.word_vectors\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:keyedvectors.py:1353: precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "most_similar = model.most_similar(positive=['kurk', 'porgand'], topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tomat', 0.8834239840507507),\n",
       " ('õun', 0.8118515014648438),\n",
       " ('arbuus', 0.8091526031494141),\n",
       " ('kartul', 0.8073391914367676),\n",
       " ('sibul', 0.8037582635879517),\n",
       " ('maasikas', 0.8013646602630615),\n",
       " ('küüslauk', 0.7977540493011475),\n",
       " ('hernes', 0.7962828874588013),\n",
       " ('värske_kurk', 0.7874271869659424),\n",
       " ('kapsas', 0.7873393297195435),\n",
       " ('juurikas', 0.7767490148544312),\n",
       " ('kaalikas', 0.7753903865814209),\n",
       " ('paprika', 0.7706528902053833),\n",
       " ('mädarõigas', 0.7664803266525269),\n",
       " ('banaan', 0.7660707235336304),\n",
       " ('toores_porgand', 0.7492185831069946),\n",
       " ('kõrvits', 0.7491439580917358),\n",
       " ('purk_marineerima', 0.7484642863273621),\n",
       " ('tomat_salat', 0.7462498545646667),\n",
       " ('vaarikas', 0.7438136339187622),\n",
       " ('porrulauk', 0.741174578666687),\n",
       " ('till', 0.7391580939292908),\n",
       " ('koorimata_kartul', 0.7386457324028015),\n",
       " ('kapsas_sibul', 0.7383479475975037),\n",
       " ('küps_tomat', 0.735424816608429),\n",
       " ('kartulisupp', 0.7347218990325928),\n",
       " ('värske_kapsas', 0.7345395088195801),\n",
       " ('muna', 0.7338947653770447),\n",
       " ('rooskapsas', 0.7324499487876892),\n",
       " ('soolakurk', 0.7318482398986816),\n",
       " ('porgand_kaalikas', 0.7316907048225403),\n",
       " ('mugulsibul', 0.7311744689941406),\n",
       " ('sidrun', 0.730707049369812),\n",
       " ('lillkapsas', 0.7285114526748657),\n",
       " ('paprikaviil', 0.7279297113418579),\n",
       " ('hapendama_kurk', 0.7259374260902405),\n",
       " ('küüslauk_küüs', 0.7254580855369568),\n",
       " ('sibulamugul', 0.7247382402420044),\n",
       " ('porgand_õun', 0.7246019244194031),\n",
       " ('paprika_tomat', 0.7235838174819946),\n",
       " ('kapsaleht', 0.7235062122344971),\n",
       " ('till_sibul', 0.7233316898345947),\n",
       " ('porgand_kartul', 0.723039984703064),\n",
       " ('mahl', 0.7224684357643127),\n",
       " ('melon', 0.7220179438591003),\n",
       " ('kõrvitsaseeme', 0.7205039262771606),\n",
       " ('roheline_sibul', 0.7202038168907166),\n",
       " ('salatileht', 0.7201410531997681),\n",
       " ('ploom', 0.7191883325576782),\n",
       " ('must_ploom', 0.7179781794548035),\n",
       " ('kuivatama_õun', 0.7179631590843201),\n",
       " ('õunatükk', 0.7176859378814697),\n",
       " ('päevalilleseeme', 0.7171003222465515),\n",
       " ('värske_tomat', 0.7162690162658691),\n",
       " ('sellerivars', 0.7150477170944214),\n",
       " ('baklazhaan', 0.7148142457008362),\n",
       " ('pähkel', 0.7144126892089844),\n",
       " ('kuivatama_aprikoos', 0.7136071920394897),\n",
       " ('punapeet', 0.7135340571403503),\n",
       " ('hapu_õun', 0.7132866382598877),\n",
       " ('keedetud_porgand', 0.712530255317688),\n",
       " ('päevalill_seeme', 0.7124685049057007),\n",
       " ('küüslaauk', 0.7123298645019531),\n",
       " ('paradiisiõun', 0.7116753458976746),\n",
       " ('rabarber', 0.7112516760826111),\n",
       " ('sibulapealne', 0.7097369432449341),\n",
       " ('suvekõrvits', 0.7096918225288391),\n",
       " ('salat_tomat', 0.7089208364486694),\n",
       " ('virsik', 0.7088673114776611),\n",
       " ('tomat_paprika', 0.708534300327301),\n",
       " ('porgand_lillkapsas', 0.7084671258926392),\n",
       " ('porgand_sibul', 0.7071185111999512),\n",
       " ('sokolaa', 0.7070722579956055),\n",
       " ('spargelkapsas', 0.706957221031189),\n",
       " ('supiroheline', 0.7065977454185486),\n",
       " ('keetma_moos', 0.706031084060669),\n",
       " ('kartul_porgand', 0.705787181854248),\n",
       " ('juust', 0.7047432661056519),\n",
       " ('keedumuna', 0.7045568823814392),\n",
       " ('kartul_sibul', 0.7045187950134277),\n",
       " ('maisitõlvik', 0.7044169902801514),\n",
       " ('tomat_sibul', 0.7043876647949219),\n",
       " ('brokol', 0.7036843299865723),\n",
       " ('toores_sibul', 0.7036487460136414),\n",
       " ('pastinaak', 0.7033499479293823),\n",
       " ('sai', 0.7033058404922485),\n",
       " ('punane_paprika', 0.7029128074645996),\n",
       " ('noaots', 0.702025294303894),\n",
       " ('salat', 0.7016258835792542),\n",
       " ('fenkol', 0.7012770175933838),\n",
       " ('apelsin', 0.7004784941673279),\n",
       " ('vaarikas_mustsõstar', 0.6998558044433594),\n",
       " ('külmutama_maasikas', 0.6998476386070251),\n",
       " ('kartul_kaalikas', 0.6995839476585388),\n",
       " ('porgand_peet', 0.6991465091705322),\n",
       " ('ploom_õun', 0.6989895105361938),\n",
       " ('juurseller', 0.6987236738204956),\n",
       " ('värske_hernes', 0.6975679397583008),\n",
       " ('mustikas', 0.6975628137588501),\n",
       " ('kapsas_kartul', 0.6974055171012878)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "most_similar = model.most_similar(positive=['müüja', 'dirigent', 'ehitaja'], topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('töömees', 0.7112044095993042),\n",
       " ('ehitusfirma', 0.6680212616920471),\n",
       " ('ehitusettevõtja', 0.6548689603805542),\n",
       " ('klienditeenindaja', 0.6475248336791992),\n",
       " ('peatöövõtja', 0.6439967155456543),\n",
       " ('ehitusmees', 0.6306071877479553),\n",
       " ('töödejuhataja', 0.6255625486373901),\n",
       " ('alltöövõtja', 0.6250219345092773),\n",
       " ('maaler', 0.622079610824585),\n",
       " ('haljastusfirma', 0.6190921068191528),\n",
       " ('ehitusjuht', 0.613804817199707),\n",
       " ('teenindaja', 0.611613392829895),\n",
       " ('ehitusettevõte', 0.6074643135070801),\n",
       " ('müügimees', 0.6037381887435913),\n",
       " ('kaido_fridolin', 0.6015191674232483),\n",
       " ('õmbleja', 0.6008065938949585),\n",
       " ('maakler', 0.6000090837478638),\n",
       " ('vahetusevanem', 0.5988837480545044),\n",
       " ('tellija', 0.596854567527771),\n",
       " ('paigaldaja', 0.5958028435707092),\n",
       " ('pottsepp', 0.5929471850395203),\n",
       " ('tsehhijuhataja', 0.5889138579368591),\n",
       " ('plekksepp', 0.5879602432250977),\n",
       " ('firmajuht', 0.5878855586051941),\n",
       " ('tisler', 0.5874782204627991),\n",
       " ('ostja', 0.5855845212936401),\n",
       " ('müügiesindaja', 0.5854313373565674),\n",
       " ('üldehitustööline', 0.5854218006134033),\n",
       " ('organist', 0.585300087928772),\n",
       " ('plaatija', 0.5845584273338318),\n",
       " ('santehnik', 0.5835479497909546),\n",
       " ('bussijuht', 0.5825698971748352),\n",
       " ('pürotehnik', 0.5824065804481506),\n",
       " ('klaasija', 0.5810157060623169),\n",
       " ('seadistaja', 0.5807743072509766),\n",
       " ('automüüja', 0.5801168084144592),\n",
       " ('kunde', 0.5765864849090576),\n",
       " ('betoneerija', 0.5761038661003113),\n",
       " ('restaureerimisfirma', 0.5759567618370056),\n",
       " ('projekteerija', 0.5757932066917419),\n",
       " ('oü_frantsiskus', 0.575103223323822),\n",
       " ('müügikonsultant', 0.5750253796577454),\n",
       " ('metallimees', 0.5724018812179565),\n",
       " ('taksojuht', 0.5722497701644897),\n",
       " ('martin_ter', 0.5720041990280151),\n",
       " ('palkmaja_ehitaja', 0.5705221891403198),\n",
       " ('poejuhataja', 0.567538857460022),\n",
       " ('arhitekt_sisekujundaja', 0.5667303204536438),\n",
       " ('kaupmees', 0.5660728216171265),\n",
       " ('projektijuhtimisfirma', 0.5643405914306641),\n",
       " ('ostujuht', 0.5638421177864075),\n",
       " ('kinnisvaramaakler', 0.5598385334014893),\n",
       " ('klaasimeister', 0.5580407381057739),\n",
       " ('tarrest_ehitus', 0.5576260089874268),\n",
       " ('objektijuht', 0.5565786957740784),\n",
       " ('müügiinimene', 0.5562987923622131),\n",
       " ('hooldusfirma', 0.555979311466217),\n",
       " ('muu_üldehitustööline', 0.5559384226799011),\n",
       " ('lukksepp', 0.5559340119361877),\n",
       " ('peaettevõtja', 0.5557093024253845),\n",
       " ('kinnisvarahaldur', 0.5552806854248047),\n",
       " ('omanikujärelevalve_tegija', 0.554707407951355),\n",
       " ('kallurijuht', 0.5546644330024719),\n",
       " ('eviko', 0.5541226863861084),\n",
       " ('omanikujärelevalve', 0.5521161556243896),\n",
       " ('kutseline_maakler', 0.5520687103271484),\n",
       " ('keevitaja', 0.5516259074211121),\n",
       " ('sadulsepp', 0.5507895350456238),\n",
       " ('firma', 0.5501941442489624),\n",
       " ('atesteerima_hindaja', 0.5500528812408447),\n",
       " ('autoteenindus', 0.5499610900878906),\n",
       " ('talter', 0.5491924285888672),\n",
       " ('koger_partner', 0.5488790273666382),\n",
       " ('elektrik', 0.5487695932388306),\n",
       " ('ehitustööline', 0.5485517978668213),\n",
       " ('mööblivalmistaja', 0.5476289987564087),\n",
       " ('remonditööline', 0.5458220839500427),\n",
       " ('kassapidaja', 0.5444481372833252),\n",
       " ('metsandus_lihttööline', 0.5444009304046631),\n",
       " ('kingsepp', 0.5436429977416992),\n",
       " ('mööblitootja', 0.543582558631897),\n",
       " ('as_pajo', 0.5434471964836121),\n",
       " ('katusefirma', 0.5431376695632935),\n",
       " ('kaupleja', 0.5430086851119995),\n",
       " ('arhipov', 0.5427555441856384),\n",
       " ('sosssepp', 0.5426319241523743),\n",
       " ('ris_ehitus', 0.5424709320068359),\n",
       " ('topauto', 0.5421284437179565),\n",
       " ('elektrike', 0.5417438745498657),\n",
       " ('allhankija', 0.5412701368331909),\n",
       " ('katusepaigaldaja', 0.5408518314361572),\n",
       " ('mööblifirma', 0.540813148021698),\n",
       " ('tehnikajuht', 0.5398242473602295),\n",
       " ('laomees', 0.5395979285240173),\n",
       " ('kesko_agro', 0.5392743349075317),\n",
       " ('ülemiste_autokeskus', 0.5390855669975281),\n",
       " ('viimistleja', 0.5380411744117737),\n",
       " ('autoremonditöökoda', 0.5378923416137695),\n",
       " ('raamatupidaja', 0.5377241969108582),\n",
       " ('veoäri', 0.5374425053596497)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Oma nimeüksuste lisamine\n",
    "\n",
    "1) Leiame võimalikult suure hulga näiteid vastavast nimeüksusest\n",
    " \n",
    "2) Märgendame ümber olemasoleva korpuse - anname seal esinevatele vastavatele nimeüksustele soovitud märgendid\n",
    "\n",
    "3) Treenime nimeüksuste tuvastaja ümbermärgendatud korpuse peal\n",
    "\n",
    "4) Märgendame oma nimeüksusi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from estnltk.taggers.estner.ner_trainer import NerTrainer\n",
    "from estnltk.taggers.estner.refac.ner import ModelStorageUtil\n",
    "from estnltk.core import DEFAULT_PY3_NER_MODEL_DIR\n",
    "\n",
    "model_dir=DEFAULT_PY3_NER_MODEL_DIR\n",
    "modelUtil = ModelStorageUtil(model_dir)\n",
    "nersettings = modelUtil.load_settings()\n",
    "trainer = NerTrainer(nersettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# See on meie treeningkorpus - peab olema morfoloogiliselt märgendatud\n",
    "text = Text('Eesti president käis Euroopas.').tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Eesti</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>president</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>käis</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Euroopas</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Eesti', [{'normalized_form': None}]),\n",
       "Span('president', [{'normalized_form': None}]),\n",
       "Span('käis', [{'normalized_form': None}]),\n",
       "Span('Euroopas', [{'normalized_form': None}]),\n",
       "Span('.', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Igale sõnale peab vastama märgend; iga lause kohta üks list\n",
    "labels = [['B-LOC','B-VOC','O','B-LOC', 'O']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 117\n",
      "Seconds required: 0.012\n",
      "\n",
      "Stochastic Gradient Descent (SGD)\n",
      "c2: 0.001000\n",
      "max_iterations: 1000\n",
      "period: 10\n",
      "delta: 0.000001\n",
      "\n",
      "Calibrating the learning rate (eta)\n",
      "calibration.eta: 0.100000\n",
      "calibration.rate: 2.000000\n",
      "calibration.samples: 1\n",
      "calibration.candidates: 10\n",
      "calibration.max_trials: 20\n",
      "Initial loss: 5.493061\n",
      "Trial #1 (eta = 0.100000): 5.493583 (worse)\n",
      "Trial #2 (eta = 0.050000): 5.493192 (worse)\n",
      "Trial #3 (eta = 0.025000): 5.493094 (worse)\n",
      "Trial #4 (eta = 0.012500): 5.493070 (worse)\n",
      "Trial #5 (eta = 0.006250): 5.493063 (worse)\n",
      "Trial #6 (eta = 0.003125): 5.493062 (worse)\n",
      "Trial #7 (eta = 0.001563): 5.493062 (worse)\n",
      "Trial #8 (eta = 0.000781): 5.493061 (worse)\n",
      "Trial #9 (eta = 0.000391): 5.493061 (worse)\n",
      "Trial #10 (eta = 0.000195): 5.493061 (worse)\n",
      "Trial #11 (eta = 0.000098): 5.493061 (worse)\n",
      "Trial #12 (eta = 0.000049): 5.493061 (worse)\n",
      "Trial #13 (eta = 0.000024): 5.493061 (worse)\n",
      "Trial #14 (eta = 0.000012): 5.493061 (worse)\n",
      "Trial #15 (eta = 0.000006): 5.493061 (worse)\n",
      "Trial #16 (eta = 0.000003): 5.493061 (worse)\n",
      "Trial #17 (eta = 0.000002): 5.493061 (worse)\n",
      "Trial #18 (eta = 0.000001): 5.493061 (worse)\n",
      "Trial #19 (eta = 0.000000): 5.493061 (worse)\n",
      "Best learning rate (eta): 0.000000\n",
      "Seconds required: 0.002\n",
      "\n",
      "***** Epoch #1 *****\n",
      "Loss: 5.493061\n",
      "Feature L2-norm: 0.000003\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 1\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #2 *****\n",
      "Loss: 5.493042\n",
      "Feature L2-norm: 0.000006\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 2\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #3 *****\n",
      "Loss: 5.493022\n",
      "Feature L2-norm: 0.000008\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 3\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #4 *****\n",
      "Loss: 5.493002\n",
      "Feature L2-norm: 0.000011\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 4\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #5 *****\n",
      "Loss: 5.492982\n",
      "Feature L2-norm: 0.000014\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 5\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #6 *****\n",
      "Loss: 5.492962\n",
      "Feature L2-norm: 0.000017\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 6\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #7 *****\n",
      "Loss: 5.492942\n",
      "Feature L2-norm: 0.000019\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 7\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #8 *****\n",
      "Loss: 5.492922\n",
      "Feature L2-norm: 0.000022\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 8\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #9 *****\n",
      "Loss: 5.492902\n",
      "Feature L2-norm: 0.000025\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 9\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #10 *****\n",
      "Loss: 5.492882\n",
      "Feature L2-norm: 0.000028\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 10\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #11 *****\n",
      "Loss: 5.492863\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000030\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 11\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #12 *****\n",
      "Loss: 5.492843\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000033\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 12\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #13 *****\n",
      "Loss: 5.492823\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000036\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 13\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #14 *****\n",
      "Loss: 5.492803\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000039\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 14\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #15 *****\n",
      "Loss: 5.492783\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000041\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 15\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #16 *****\n",
      "Loss: 5.492763\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000044\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 16\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #17 *****\n",
      "Loss: 5.492743\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000047\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 17\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #18 *****\n",
      "Loss: 5.492723\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000050\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 18\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #19 *****\n",
      "Loss: 5.492704\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000052\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 19\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #20 *****\n",
      "Loss: 5.492684\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000055\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 20\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #21 *****\n",
      "Loss: 5.492664\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000058\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 21\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #22 *****\n",
      "Loss: 5.492644\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000061\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 22\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #23 *****\n",
      "Loss: 5.492624\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000063\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 23\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #24 *****\n",
      "Loss: 5.492604\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000066\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 24\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #25 *****\n",
      "Loss: 5.492584\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000069\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 25\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #26 *****\n",
      "Loss: 5.492564\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000072\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 26\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #27 *****\n",
      "Loss: 5.492544\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000074\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 27\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #28 *****\n",
      "Loss: 5.492525\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000077\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 28\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #29 *****\n",
      "Loss: 5.492505\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000080\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 29\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #30 *****\n",
      "Loss: 5.492485\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000083\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 30\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #31 *****\n",
      "Loss: 5.492465\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000085\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 31\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #32 *****\n",
      "Loss: 5.492445\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000088\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 32\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #33 *****\n",
      "Loss: 5.492425\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000091\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 33\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #34 *****\n",
      "Loss: 5.492405\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000094\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 34\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #35 *****\n",
      "Loss: 5.492385\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000096\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 35\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #36 *****\n",
      "Loss: 5.492366\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000099\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 36\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #37 *****\n",
      "Loss: 5.492346\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000102\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 37\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #38 *****\n",
      "Loss: 5.492326\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000105\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 38\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #39 *****\n",
      "Loss: 5.492306\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000107\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 39\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #40 *****\n",
      "Loss: 5.492286\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000110\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 40\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #41 *****\n",
      "Loss: 5.492266\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000113\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 41\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #42 *****\n",
      "Loss: 5.492246\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000116\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 42\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #43 *****\n",
      "Loss: 5.492226\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000118\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 43\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #44 *****\n",
      "Loss: 5.492207\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000121\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 44\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #45 *****\n",
      "Loss: 5.492187\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000124\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 45\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #46 *****\n",
      "Loss: 5.492167\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000127\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 46\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #47 *****\n",
      "Loss: 5.492147\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000129\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 47\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #48 *****\n",
      "Loss: 5.492127\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000132\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 48\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #49 *****\n",
      "Loss: 5.492107\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000135\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 49\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #50 *****\n",
      "Loss: 5.492087\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000138\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 50\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #51 *****\n",
      "Loss: 5.492067\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000140\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 51\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #52 *****\n",
      "Loss: 5.492047\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000143\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 52\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #53 *****\n",
      "Loss: 5.492028\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000146\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 53\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #54 *****\n",
      "Loss: 5.492008\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000149\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 54\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #55 *****\n",
      "Loss: 5.491988\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000151\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 55\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #56 *****\n",
      "Loss: 5.491968\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000154\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 56\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #57 *****\n",
      "Loss: 5.491948\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000157\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 57\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #58 *****\n",
      "Loss: 5.491928\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000160\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 58\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #59 *****\n",
      "Loss: 5.491908\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000162\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 59\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #60 *****\n",
      "Loss: 5.491888\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000165\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 60\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #61 *****\n",
      "Loss: 5.491869\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000168\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 61\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #62 *****\n",
      "Loss: 5.491849\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000171\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 62\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #63 *****\n",
      "Loss: 5.491829\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000173\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 63\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #64 *****\n",
      "Loss: 5.491809\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000176\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 64\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #65 *****\n",
      "Loss: 5.491789\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000179\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 65\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #66 *****\n",
      "Loss: 5.491769\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000182\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 66\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #67 *****\n",
      "Loss: 5.491749\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000185\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 67\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #68 *****\n",
      "Loss: 5.491729\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000187\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 68\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #69 *****\n",
      "Loss: 5.491710\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000190\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 69\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #70 *****\n",
      "Loss: 5.491690\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000193\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 70\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #71 *****\n",
      "Loss: 5.491670\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000196\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 71\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #72 *****\n",
      "Loss: 5.491650\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000198\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 72\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #73 *****\n",
      "Loss: 5.491630\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000201\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 73\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #74 *****\n",
      "Loss: 5.491610\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000204\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 74\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #75 *****\n",
      "Loss: 5.491590\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000207\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 75\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #76 *****\n",
      "Loss: 5.491570\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000209\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 76\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #77 *****\n",
      "Loss: 5.491551\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000212\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 77\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #78 *****\n",
      "Loss: 5.491531\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000215\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 78\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #79 *****\n",
      "Loss: 5.491511\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000218\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 79\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #80 *****\n",
      "Loss: 5.491491\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000220\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 80\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #81 *****\n",
      "Loss: 5.491471\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000223\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 81\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #82 *****\n",
      "Loss: 5.491451\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000226\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 82\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #83 *****\n",
      "Loss: 5.491431\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000229\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 83\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #84 *****\n",
      "Loss: 5.491411\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000231\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 84\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #85 *****\n",
      "Loss: 5.491392\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000234\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 85\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #86 *****\n",
      "Loss: 5.491372\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000237\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 86\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #87 *****\n",
      "Loss: 5.491352\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000240\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 87\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #88 *****\n",
      "Loss: 5.491332\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000242\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 88\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #89 *****\n",
      "Loss: 5.491312\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000245\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 89\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #90 *****\n",
      "Loss: 5.491292\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000248\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 90\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #91 *****\n",
      "Loss: 5.491272\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000251\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 91\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #92 *****\n",
      "Loss: 5.491252\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000253\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 92\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #93 *****\n",
      "Loss: 5.491233\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000256\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 93\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #94 *****\n",
      "Loss: 5.491213\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000259\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 94\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #95 *****\n",
      "Loss: 5.491193\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000262\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 95\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #96 *****\n",
      "Loss: 5.491173\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000264\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 96\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #97 *****\n",
      "Loss: 5.491153\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000267\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 97\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #98 *****\n",
      "Loss: 5.491133\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000270\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 98\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #99 *****\n",
      "Loss: 5.491113\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000273\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 99\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #100 *****\n",
      "Loss: 5.491093\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000275\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 100\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #101 *****\n",
      "Loss: 5.491073\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000278\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 101\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #102 *****\n",
      "Loss: 5.491054\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000281\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 102\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #103 *****\n",
      "Loss: 5.491034\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000284\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 103\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #104 *****\n",
      "Loss: 5.491014\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000286\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 104\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #105 *****\n",
      "Loss: 5.490994\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000289\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 105\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #106 *****\n",
      "Loss: 5.490974\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000292\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 106\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #107 *****\n",
      "Loss: 5.490954\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000295\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 107\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #108 *****\n",
      "Loss: 5.490934\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000297\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 108\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #109 *****\n",
      "Loss: 5.490914\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000300\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 109\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #110 *****\n",
      "Loss: 5.490895\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000303\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 110\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #111 *****\n",
      "Loss: 5.490875\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000306\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 111\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #112 *****\n",
      "Loss: 5.490855\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000308\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 112\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #113 *****\n",
      "Loss: 5.490835\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000311\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 113\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #114 *****\n",
      "Loss: 5.490815\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000314\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 114\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #115 *****\n",
      "Loss: 5.490795\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000317\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 115\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #116 *****\n",
      "Loss: 5.490775\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000319\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 116\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #117 *****\n",
      "Loss: 5.490756\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000322\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 117\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #118 *****\n",
      "Loss: 5.490736\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000325\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 118\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #119 *****\n",
      "Loss: 5.490716\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000328\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 119\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #120 *****\n",
      "Loss: 5.490696\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000330\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 120\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #121 *****\n",
      "Loss: 5.490676\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000333\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 121\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #122 *****\n",
      "Loss: 5.490656\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000336\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 122\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #123 *****\n",
      "Loss: 5.490636\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000339\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 123\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #124 *****\n",
      "Loss: 5.490616\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000341\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 124\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #125 *****\n",
      "Loss: 5.490597\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000344\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 125\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #126 *****\n",
      "Loss: 5.490577\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000347\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 126\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #127 *****\n",
      "Loss: 5.490557\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000350\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 127\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #128 *****\n",
      "Loss: 5.490537\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000352\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 128\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #129 *****\n",
      "Loss: 5.490517\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000355\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 129\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #130 *****\n",
      "Loss: 5.490497\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000358\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 130\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #131 *****\n",
      "Loss: 5.490477\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000361\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 131\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #132 *****\n",
      "Loss: 5.490457\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000363\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 132\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #133 *****\n",
      "Loss: 5.490438\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000366\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 133\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #134 *****\n",
      "Loss: 5.490418\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000369\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 134\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #135 *****\n",
      "Loss: 5.490398\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000372\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 135\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #136 *****\n",
      "Loss: 5.490378\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000375\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 136\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #137 *****\n",
      "Loss: 5.490358\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000377\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 137\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #138 *****\n",
      "Loss: 5.490338\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000380\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 138\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #139 *****\n",
      "Loss: 5.490318\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000383\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 139\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #140 *****\n",
      "Loss: 5.490298\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000386\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 140\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #141 *****\n",
      "Loss: 5.490279\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000388\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 141\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #142 *****\n",
      "Loss: 5.490259\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000391\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 142\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #143 *****\n",
      "Loss: 5.490239\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000394\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 143\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #144 *****\n",
      "Loss: 5.490219\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000397\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 144\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #145 *****\n",
      "Loss: 5.490199\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000399\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 145\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #146 *****\n",
      "Loss: 5.490179\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000402\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 146\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #147 *****\n",
      "Loss: 5.490159\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000405\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 147\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #148 *****\n",
      "Loss: 5.490139\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000408\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 148\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #149 *****\n",
      "Loss: 5.490120\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000410\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 149\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #150 *****\n",
      "Loss: 5.490100\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000413\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 150\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #151 *****\n",
      "Loss: 5.490080\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000416\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 151\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #152 *****\n",
      "Loss: 5.490060\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000419\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 152\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #153 *****\n",
      "Loss: 5.490040\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000421\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 153\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #154 *****\n",
      "Loss: 5.490020\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000424\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 154\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #155 *****\n",
      "Loss: 5.490000\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000427\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 155\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #156 *****\n",
      "Loss: 5.489980\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000430\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 156\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #157 *****\n",
      "Loss: 5.489961\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000432\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 157\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #158 *****\n",
      "Loss: 5.489941\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000435\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 158\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #159 *****\n",
      "Loss: 5.489921\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000438\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 159\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #160 *****\n",
      "Loss: 5.489901\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000441\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 160\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #161 *****\n",
      "Loss: 5.489881\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000443\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 161\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #162 *****\n",
      "Loss: 5.489861\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000446\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 162\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #163 *****\n",
      "Loss: 5.489841\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000449\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 163\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #164 *****\n",
      "Loss: 5.489822\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000452\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 164\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #165 *****\n",
      "Loss: 5.489802\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000454\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 165\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #166 *****\n",
      "Loss: 5.489782\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000457\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 166\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #167 *****\n",
      "Loss: 5.489762\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000460\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 167\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #168 *****\n",
      "Loss: 5.489742\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000463\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 168\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #169 *****\n",
      "Loss: 5.489722\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000465\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 169\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #170 *****\n",
      "Loss: 5.489702\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000468\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 170\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #171 *****\n",
      "Loss: 5.489682\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000471\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 171\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #172 *****\n",
      "Loss: 5.489663\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000474\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 172\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #173 *****\n",
      "Loss: 5.489643\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000476\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 173\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #174 *****\n",
      "Loss: 5.489623\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000479\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 174\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #175 *****\n",
      "Loss: 5.489603\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000482\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 175\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #176 *****\n",
      "Loss: 5.489583\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000485\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 176\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #177 *****\n",
      "Loss: 5.489563\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000487\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 177\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #178 *****\n",
      "Loss: 5.489543\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000490\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 178\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #179 *****\n",
      "Loss: 5.489523\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000493\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 179\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #180 *****\n",
      "Loss: 5.489504\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000496\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 180\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #181 *****\n",
      "Loss: 5.489484\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000498\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 181\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #182 *****\n",
      "Loss: 5.489464\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000501\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 182\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #183 *****\n",
      "Loss: 5.489444\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000504\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 183\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #184 *****\n",
      "Loss: 5.489424\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000507\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 184\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #185 *****\n",
      "Loss: 5.489404\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000509\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 185\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #186 *****\n",
      "Loss: 5.489384\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000512\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 186\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #187 *****\n",
      "Loss: 5.489365\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000515\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 187\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #188 *****\n",
      "Loss: 5.489345\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000518\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 188\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #189 *****\n",
      "Loss: 5.489325\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000520\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 189\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #190 *****\n",
      "Loss: 5.489305\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000523\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 190\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #191 *****\n",
      "Loss: 5.489285\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000526\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 191\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #192 *****\n",
      "Loss: 5.489265\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000529\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 192\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #193 *****\n",
      "Loss: 5.489245\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000531\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 193\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #194 *****\n",
      "Loss: 5.489225\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000534\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 194\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #195 *****\n",
      "Loss: 5.489206\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000537\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 195\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #196 *****\n",
      "Loss: 5.489186\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000540\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 196\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #197 *****\n",
      "Loss: 5.489166\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000542\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 197\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #198 *****\n",
      "Loss: 5.489146\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000545\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 198\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #199 *****\n",
      "Loss: 5.489126\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000548\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 199\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #200 *****\n",
      "Loss: 5.489106\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000551\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 200\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #201 *****\n",
      "Loss: 5.489086\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000553\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 201\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #202 *****\n",
      "Loss: 5.489067\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000556\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 202\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #203 *****\n",
      "Loss: 5.489047\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000559\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 203\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #204 *****\n",
      "Loss: 5.489027\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000562\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 204\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #205 *****\n",
      "Loss: 5.489007\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000564\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 205\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #206 *****\n",
      "Loss: 5.488987\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000567\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 206\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #207 *****\n",
      "Loss: 5.488967\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000570\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 207\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #208 *****\n",
      "Loss: 5.488947\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000573\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 208\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #209 *****\n",
      "Loss: 5.488927\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000575\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 209\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #210 *****\n",
      "Loss: 5.488908\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000578\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 210\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #211 *****\n",
      "Loss: 5.488888\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000581\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 211\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #212 *****\n",
      "Loss: 5.488868\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000584\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 212\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #213 *****\n",
      "Loss: 5.488848\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000586\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 213\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #214 *****\n",
      "Loss: 5.488828\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000589\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 214\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #215 *****\n",
      "Loss: 5.488808\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000592\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 215\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #216 *****\n",
      "Loss: 5.488788\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000595\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 216\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #217 *****\n",
      "Loss: 5.488769\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000598\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 217\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #218 *****\n",
      "Loss: 5.488749\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000600\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 218\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #219 *****\n",
      "Loss: 5.488729\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000603\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 219\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #220 *****\n",
      "Loss: 5.488709\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000606\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 220\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #221 *****\n",
      "Loss: 5.488689\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000609\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 221\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #222 *****\n",
      "Loss: 5.488669\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000611\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 222\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #223 *****\n",
      "Loss: 5.488649\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000614\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 223\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #224 *****\n",
      "Loss: 5.488629\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000617\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 224\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #225 *****\n",
      "Loss: 5.488610\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000620\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 225\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #226 *****\n",
      "Loss: 5.488590\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000622\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 226\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #227 *****\n",
      "Loss: 5.488570\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000625\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 227\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #228 *****\n",
      "Loss: 5.488550\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000628\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 228\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #229 *****\n",
      "Loss: 5.488530\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000631\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 229\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #230 *****\n",
      "Loss: 5.488510\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000633\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 230\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #231 *****\n",
      "Loss: 5.488490\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000636\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 231\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #232 *****\n",
      "Loss: 5.488471\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000639\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 232\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #233 *****\n",
      "Loss: 5.488451\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000642\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 233\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #234 *****\n",
      "Loss: 5.488431\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000644\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 234\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #235 *****\n",
      "Loss: 5.488411\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000647\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 235\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #236 *****\n",
      "Loss: 5.488391\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000650\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 236\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #237 *****\n",
      "Loss: 5.488371\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000653\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 237\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #238 *****\n",
      "Loss: 5.488351\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000655\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 238\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #239 *****\n",
      "Loss: 5.488331\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000658\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 239\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #240 *****\n",
      "Loss: 5.488312\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000661\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 240\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #241 *****\n",
      "Loss: 5.488292\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000664\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 241\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #242 *****\n",
      "Loss: 5.488272\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000666\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 242\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #243 *****\n",
      "Loss: 5.488252\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000669\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 243\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #244 *****\n",
      "Loss: 5.488232\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000672\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 244\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #245 *****\n",
      "Loss: 5.488212\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000675\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 245\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #246 *****\n",
      "Loss: 5.488192\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000677\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 246\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #247 *****\n",
      "Loss: 5.488173\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000680\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 247\n",
      "Seconds required for this iteration: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #248 *****\n",
      "Loss: 5.488153\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000683\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 248\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #249 *****\n",
      "Loss: 5.488133\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000686\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 249\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #250 *****\n",
      "Loss: 5.488113\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000688\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 250\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #251 *****\n",
      "Loss: 5.488093\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000691\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 251\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #252 *****\n",
      "Loss: 5.488073\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000694\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 252\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #253 *****\n",
      "Loss: 5.488053\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000697\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 253\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #254 *****\n",
      "Loss: 5.488034\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000699\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 254\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #255 *****\n",
      "Loss: 5.488014\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000702\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 255\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #256 *****\n",
      "Loss: 5.487994\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000705\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 256\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #257 *****\n",
      "Loss: 5.487974\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000708\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 257\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #258 *****\n",
      "Loss: 5.487954\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000710\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 258\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #259 *****\n",
      "Loss: 5.487934\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000713\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 259\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #260 *****\n",
      "Loss: 5.487914\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000716\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 260\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #261 *****\n",
      "Loss: 5.487894\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000719\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 261\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #262 *****\n",
      "Loss: 5.487875\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000721\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 262\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #263 *****\n",
      "Loss: 5.487855\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000724\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 263\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #264 *****\n",
      "Loss: 5.487835\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000727\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 264\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #265 *****\n",
      "Loss: 5.487815\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000730\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 265\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #266 *****\n",
      "Loss: 5.487795\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000732\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 266\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #267 *****\n",
      "Loss: 5.487775\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000735\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 267\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #268 *****\n",
      "Loss: 5.487755\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000738\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 268\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #269 *****\n",
      "Loss: 5.487736\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000741\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 269\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #270 *****\n",
      "Loss: 5.487716\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000743\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 270\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #271 *****\n",
      "Loss: 5.487696\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000746\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 271\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #272 *****\n",
      "Loss: 5.487676\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000749\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 272\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #273 *****\n",
      "Loss: 5.487656\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000752\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 273\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #274 *****\n",
      "Loss: 5.487636\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000754\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 274\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #275 *****\n",
      "Loss: 5.487616\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000757\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 275\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #276 *****\n",
      "Loss: 5.487597\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000760\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 276\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #277 *****\n",
      "Loss: 5.487577\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000763\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 277\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #278 *****\n",
      "Loss: 5.487557\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000765\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 278\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #279 *****\n",
      "Loss: 5.487537\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000768\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 279\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #280 *****\n",
      "Loss: 5.487517\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000771\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 280\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #281 *****\n",
      "Loss: 5.487497\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000774\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 281\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #282 *****\n",
      "Loss: 5.487477\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000776\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 282\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #283 *****\n",
      "Loss: 5.487458\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000779\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 283\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #284 *****\n",
      "Loss: 5.487438\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000782\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 284\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #285 *****\n",
      "Loss: 5.487418\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000785\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 285\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #286 *****\n",
      "Loss: 5.487398\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000787\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 286\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #287 *****\n",
      "Loss: 5.487378\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000790\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 287\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #288 *****\n",
      "Loss: 5.487358\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000793\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 288\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #289 *****\n",
      "Loss: 5.487338\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000796\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 289\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #290 *****\n",
      "Loss: 5.487319\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000798\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 290\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #291 *****\n",
      "Loss: 5.487299\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000801\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 291\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #292 *****\n",
      "Loss: 5.487279\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000804\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 292\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #293 *****\n",
      "Loss: 5.487259\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000807\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 293\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #294 *****\n",
      "Loss: 5.487239\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000809\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 294\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #295 *****\n",
      "Loss: 5.487219\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000812\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 295\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #296 *****\n",
      "Loss: 5.487199\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000815\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 296\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #297 *****\n",
      "Loss: 5.487179\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000818\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 297\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #298 *****\n",
      "Loss: 5.487160\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000820\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 298\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #299 *****\n",
      "Loss: 5.487140\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000823\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 299\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #300 *****\n",
      "Loss: 5.487120\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000826\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 300\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #301 *****\n",
      "Loss: 5.487100\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000829\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 301\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #302 *****\n",
      "Loss: 5.487080\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000831\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 302\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #303 *****\n",
      "Loss: 5.487060\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000834\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 303\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #304 *****\n",
      "Loss: 5.487040\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000837\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 304\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #305 *****\n",
      "Loss: 5.487021\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000840\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 305\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #306 *****\n",
      "Loss: 5.487001\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000842\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 306\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #307 *****\n",
      "Loss: 5.486981\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000845\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 307\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #308 *****\n",
      "Loss: 5.486961\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000848\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 308\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #309 *****\n",
      "Loss: 5.486941\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000851\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 309\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #310 *****\n",
      "Loss: 5.486921\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000853\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 310\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #311 *****\n",
      "Loss: 5.486901\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000856\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 311\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #312 *****\n",
      "Loss: 5.486882\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000859\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 312\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #313 *****\n",
      "Loss: 5.486862\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000862\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 313\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #314 *****\n",
      "Loss: 5.486842\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000865\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 314\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #315 *****\n",
      "Loss: 5.486822\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000867\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 315\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #316 *****\n",
      "Loss: 5.486802\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000870\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 316\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #317 *****\n",
      "Loss: 5.486782\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000873\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 317\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #318 *****\n",
      "Loss: 5.486762\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000876\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 318\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #319 *****\n",
      "Loss: 5.486743\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000878\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 319\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #320 *****\n",
      "Loss: 5.486723\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000881\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 320\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #321 *****\n",
      "Loss: 5.486703\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000884\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 321\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #322 *****\n",
      "Loss: 5.486683\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000887\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 322\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #323 *****\n",
      "Loss: 5.486663\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000889\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 323\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #324 *****\n",
      "Loss: 5.486643\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000892\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 324\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #325 *****\n",
      "Loss: 5.486623\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000895\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 325\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #326 *****\n",
      "Loss: 5.486604\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000898\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 326\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #327 *****\n",
      "Loss: 5.486584\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000900\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 327\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #328 *****\n",
      "Loss: 5.486564\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000903\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 328\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #329 *****\n",
      "Loss: 5.486544\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000906\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 329\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #330 *****\n",
      "Loss: 5.486524\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000909\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 330\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #331 *****\n",
      "Loss: 5.486504\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000911\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 331\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #332 *****\n",
      "Loss: 5.486484\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000914\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 332\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #333 *****\n",
      "Loss: 5.486465\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000917\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 333\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #334 *****\n",
      "Loss: 5.486445\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000920\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 334\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #335 *****\n",
      "Loss: 5.486425\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000922\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 335\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #336 *****\n",
      "Loss: 5.486405\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000925\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 336\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #337 *****\n",
      "Loss: 5.486385\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000928\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 337\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #338 *****\n",
      "Loss: 5.486365\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000931\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 338\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #339 *****\n",
      "Loss: 5.486345\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000933\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 339\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #340 *****\n",
      "Loss: 5.486326\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000936\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 340\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #341 *****\n",
      "Loss: 5.486306\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000939\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 341\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #342 *****\n",
      "Loss: 5.486286\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000942\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 342\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #343 *****\n",
      "Loss: 5.486266\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000944\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 343\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #344 *****\n",
      "Loss: 5.486246\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000947\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 344\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #345 *****\n",
      "Loss: 5.486226\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000950\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 345\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #346 *****\n",
      "Loss: 5.486206\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000953\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 346\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #347 *****\n",
      "Loss: 5.486187\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000955\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 347\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #348 *****\n",
      "Loss: 5.486167\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000958\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 348\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #349 *****\n",
      "Loss: 5.486147\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000961\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 349\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #350 *****\n",
      "Loss: 5.486127\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000964\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 350\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #351 *****\n",
      "Loss: 5.486107\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000966\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 351\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #352 *****\n",
      "Loss: 5.486087\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000969\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 352\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #353 *****\n",
      "Loss: 5.486067\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000972\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 353\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #354 *****\n",
      "Loss: 5.486048\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000975\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 354\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #355 *****\n",
      "Loss: 5.486028\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000977\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 355\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #356 *****\n",
      "Loss: 5.486008\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000980\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 356\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #357 *****\n",
      "Loss: 5.485988\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000983\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 357\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #358 *****\n",
      "Loss: 5.485968\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000986\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 358\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #359 *****\n",
      "Loss: 5.485948\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000988\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 359\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #360 *****\n",
      "Loss: 5.485929\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000991\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 360\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #361 *****\n",
      "Loss: 5.485909\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000994\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 361\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #362 *****\n",
      "Loss: 5.485889\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000997\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 362\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #363 *****\n",
      "Loss: 5.485869\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.000999\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 363\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #364 *****\n",
      "Loss: 5.485849\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001002\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 364\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #365 *****\n",
      "Loss: 5.485829\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001005\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 365\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #366 *****\n",
      "Loss: 5.485809\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001008\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 366\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #367 *****\n",
      "Loss: 5.485790\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001010\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 367\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #368 *****\n",
      "Loss: 5.485770\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001013\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 368\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #369 *****\n",
      "Loss: 5.485750\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001016\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 369\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #370 *****\n",
      "Loss: 5.485730\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001019\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 370\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #371 *****\n",
      "Loss: 5.485710\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001021\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 371\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #372 *****\n",
      "Loss: 5.485690\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001024\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 372\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #373 *****\n",
      "Loss: 5.485670\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001027\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 373\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #374 *****\n",
      "Loss: 5.485651\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001030\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 374\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #375 *****\n",
      "Loss: 5.485631\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001032\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 375\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #376 *****\n",
      "Loss: 5.485611\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001035\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 376\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #377 *****\n",
      "Loss: 5.485591\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001038\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 377\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #378 *****\n",
      "Loss: 5.485571\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001041\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 378\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #379 *****\n",
      "Loss: 5.485551\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001043\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 379\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #380 *****\n",
      "Loss: 5.485531\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001046\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 380\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #381 *****\n",
      "Loss: 5.485512\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001049\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 381\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #382 *****\n",
      "Loss: 5.485492\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001052\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 382\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #383 *****\n",
      "Loss: 5.485472\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001054\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 383\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #384 *****\n",
      "Loss: 5.485452\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001057\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 384\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #385 *****\n",
      "Loss: 5.485432\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001060\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 385\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #386 *****\n",
      "Loss: 5.485412\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001063\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 386\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #387 *****\n",
      "Loss: 5.485392\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001065\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 387\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #388 *****\n",
      "Loss: 5.485373\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001068\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 388\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #389 *****\n",
      "Loss: 5.485353\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001071\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 389\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #390 *****\n",
      "Loss: 5.485333\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001074\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 390\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #391 *****\n",
      "Loss: 5.485313\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001076\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 391\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #392 *****\n",
      "Loss: 5.485293\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001079\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 392\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #393 *****\n",
      "Loss: 5.485273\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001082\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 393\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #394 *****\n",
      "Loss: 5.485254\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001085\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 394\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #395 *****\n",
      "Loss: 5.485234\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001087\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 395\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #396 *****\n",
      "Loss: 5.485214\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001090\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 396\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #397 *****\n",
      "Loss: 5.485194\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001093\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 397\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #398 *****\n",
      "Loss: 5.485174\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001096\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 398\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #399 *****\n",
      "Loss: 5.485154\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001098\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 399\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #400 *****\n",
      "Loss: 5.485134\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001101\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 400\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #401 *****\n",
      "Loss: 5.485115\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001104\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 401\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #402 *****\n",
      "Loss: 5.485095\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001107\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 402\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #403 *****\n",
      "Loss: 5.485075\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001109\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 403\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #404 *****\n",
      "Loss: 5.485055\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001112\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 404\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #405 *****\n",
      "Loss: 5.485035\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001115\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 405\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #406 *****\n",
      "Loss: 5.485015\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001118\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 406\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #407 *****\n",
      "Loss: 5.484995\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001120\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 407\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #408 *****\n",
      "Loss: 5.484976\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001123\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 408\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #409 *****\n",
      "Loss: 5.484956\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001126\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 409\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #410 *****\n",
      "Loss: 5.484936\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001129\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 410\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #411 *****\n",
      "Loss: 5.484916\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001131\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 411\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #412 *****\n",
      "Loss: 5.484896\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001134\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 412\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #413 *****\n",
      "Loss: 5.484876\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001137\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 413\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #414 *****\n",
      "Loss: 5.484857\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001140\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 414\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #415 *****\n",
      "Loss: 5.484837\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001142\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 415\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #416 *****\n",
      "Loss: 5.484817\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001145\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 416\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #417 *****\n",
      "Loss: 5.484797\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001148\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 417\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #418 *****\n",
      "Loss: 5.484777\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001151\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 418\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #419 *****\n",
      "Loss: 5.484757\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001153\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 419\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #420 *****\n",
      "Loss: 5.484737\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001156\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 420\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #421 *****\n",
      "Loss: 5.484718\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001159\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 421\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #422 *****\n",
      "Loss: 5.484698\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001162\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 422\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #423 *****\n",
      "Loss: 5.484678\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001164\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 423\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #424 *****\n",
      "Loss: 5.484658\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001167\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 424\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #425 *****\n",
      "Loss: 5.484638\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001170\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 425\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #426 *****\n",
      "Loss: 5.484618\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001173\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 426\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #427 *****\n",
      "Loss: 5.484598\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001175\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 427\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #428 *****\n",
      "Loss: 5.484579\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001178\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 428\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #429 *****\n",
      "Loss: 5.484559\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001181\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 429\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #430 *****\n",
      "Loss: 5.484539\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001184\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 430\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #431 *****\n",
      "Loss: 5.484519\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001186\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 431\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #432 *****\n",
      "Loss: 5.484499\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001189\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 432\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #433 *****\n",
      "Loss: 5.484479\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001192\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 433\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #434 *****\n",
      "Loss: 5.484460\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001195\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 434\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #435 *****\n",
      "Loss: 5.484440\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001197\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 435\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #436 *****\n",
      "Loss: 5.484420\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001200\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 436\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #437 *****\n",
      "Loss: 5.484400\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001203\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 437\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #438 *****\n",
      "Loss: 5.484380\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001206\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 438\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #439 *****\n",
      "Loss: 5.484360\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001208\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 439\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #440 *****\n",
      "Loss: 5.484340\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001211\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 440\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #441 *****\n",
      "Loss: 5.484321\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001214\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 441\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #442 *****\n",
      "Loss: 5.484301\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001217\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 442\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #443 *****\n",
      "Loss: 5.484281\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001220\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 443\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #444 *****\n",
      "Loss: 5.484261\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001222\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 444\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #445 *****\n",
      "Loss: 5.484241\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001225\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 445\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #446 *****\n",
      "Loss: 5.484221\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001228\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 446\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #447 *****\n",
      "Loss: 5.484202\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001231\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 447\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #448 *****\n",
      "Loss: 5.484182\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001233\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 448\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #449 *****\n",
      "Loss: 5.484162\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001236\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 449\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #450 *****\n",
      "Loss: 5.484142\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001239\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 450\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #451 *****\n",
      "Loss: 5.484122\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001242\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 451\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #452 *****\n",
      "Loss: 5.484102\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001244\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 452\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #453 *****\n",
      "Loss: 5.484082\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001247\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 453\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #454 *****\n",
      "Loss: 5.484063\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001250\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 454\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #455 *****\n",
      "Loss: 5.484043\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001253\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 455\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #456 *****\n",
      "Loss: 5.484023\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001255\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 456\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #457 *****\n",
      "Loss: 5.484003\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001258\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 457\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #458 *****\n",
      "Loss: 5.483983\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001261\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 458\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #459 *****\n",
      "Loss: 5.483963\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001264\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 459\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #460 *****\n",
      "Loss: 5.483944\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001266\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 460\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #461 *****\n",
      "Loss: 5.483924\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001269\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 461\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #462 *****\n",
      "Loss: 5.483904\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001272\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 462\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #463 *****\n",
      "Loss: 5.483884\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001275\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 463\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #464 *****\n",
      "Loss: 5.483864\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001277\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 464\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #465 *****\n",
      "Loss: 5.483844\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001280\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 465\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #466 *****\n",
      "Loss: 5.483824\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001283\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 466\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #467 *****\n",
      "Loss: 5.483805\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001286\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 467\n",
      "Seconds required for this iteration: 0.000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #468 *****\n",
      "Loss: 5.483785\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001288\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 468\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #469 *****\n",
      "Loss: 5.483765\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001291\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 469\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #470 *****\n",
      "Loss: 5.483745\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001294\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 470\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #471 *****\n",
      "Loss: 5.483725\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001297\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 471\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #472 *****\n",
      "Loss: 5.483705\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001299\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 472\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #473 *****\n",
      "Loss: 5.483686\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001302\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 473\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #474 *****\n",
      "Loss: 5.483666\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001305\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 474\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #475 *****\n",
      "Loss: 5.483646\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001308\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 475\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #476 *****\n",
      "Loss: 5.483626\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001310\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 476\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #477 *****\n",
      "Loss: 5.483606\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001313\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 477\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #478 *****\n",
      "Loss: 5.483586\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001316\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 478\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #479 *****\n",
      "Loss: 5.483566\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001319\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 479\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #480 *****\n",
      "Loss: 5.483547\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001321\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 480\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #481 *****\n",
      "Loss: 5.483527\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001324\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 481\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #482 *****\n",
      "Loss: 5.483507\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001327\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 482\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #483 *****\n",
      "Loss: 5.483487\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001330\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 483\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #484 *****\n",
      "Loss: 5.483467\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001332\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 484\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #485 *****\n",
      "Loss: 5.483447\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001335\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 485\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #486 *****\n",
      "Loss: 5.483428\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001338\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 486\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #487 *****\n",
      "Loss: 5.483408\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001341\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 487\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #488 *****\n",
      "Loss: 5.483388\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001343\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 488\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #489 *****\n",
      "Loss: 5.483368\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001346\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 489\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #490 *****\n",
      "Loss: 5.483348\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001349\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 490\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #491 *****\n",
      "Loss: 5.483328\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001352\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 491\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #492 *****\n",
      "Loss: 5.483308\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001354\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 492\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #493 *****\n",
      "Loss: 5.483289\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001357\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 493\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #494 *****\n",
      "Loss: 5.483269\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001360\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 494\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #495 *****\n",
      "Loss: 5.483249\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001363\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 495\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #496 *****\n",
      "Loss: 5.483229\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001365\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 496\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #497 *****\n",
      "Loss: 5.483209\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001368\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 497\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #498 *****\n",
      "Loss: 5.483189\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001371\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 498\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #499 *****\n",
      "Loss: 5.483170\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001374\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 499\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #500 *****\n",
      "Loss: 5.483150\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001376\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 500\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #501 *****\n",
      "Loss: 5.483130\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001379\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 501\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #502 *****\n",
      "Loss: 5.483110\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001382\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 502\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #503 *****\n",
      "Loss: 5.483090\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001385\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 503\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #504 *****\n",
      "Loss: 5.483070\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001387\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 504\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #505 *****\n",
      "Loss: 5.483051\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001390\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 505\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #506 *****\n",
      "Loss: 5.483031\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001393\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 506\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #507 *****\n",
      "Loss: 5.483011\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001396\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 507\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #508 *****\n",
      "Loss: 5.482991\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001398\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 508\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #509 *****\n",
      "Loss: 5.482971\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001401\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 509\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #510 *****\n",
      "Loss: 5.482951\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001404\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 510\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #511 *****\n",
      "Loss: 5.482931\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001407\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 511\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #512 *****\n",
      "Loss: 5.482912\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001409\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 512\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #513 *****\n",
      "Loss: 5.482892\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001412\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 513\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #514 *****\n",
      "Loss: 5.482872\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001415\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 514\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #515 *****\n",
      "Loss: 5.482852\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001418\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 515\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #516 *****\n",
      "Loss: 5.482832\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001420\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 516\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #517 *****\n",
      "Loss: 5.482812\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001423\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 517\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #518 *****\n",
      "Loss: 5.482793\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001426\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 518\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #519 *****\n",
      "Loss: 5.482773\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001429\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 519\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #520 *****\n",
      "Loss: 5.482753\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001431\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 520\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #521 *****\n",
      "Loss: 5.482733\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001434\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 521\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #522 *****\n",
      "Loss: 5.482713\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001437\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 522\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #523 *****\n",
      "Loss: 5.482693\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001440\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 523\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #524 *****\n",
      "Loss: 5.482674\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001442\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 524\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #525 *****\n",
      "Loss: 5.482654\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001445\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 525\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #526 *****\n",
      "Loss: 5.482634\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001448\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 526\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #527 *****\n",
      "Loss: 5.482614\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001451\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 527\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #528 *****\n",
      "Loss: 5.482594\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001453\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 528\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #529 *****\n",
      "Loss: 5.482574\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001456\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 529\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #530 *****\n",
      "Loss: 5.482554\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001459\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 530\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #531 *****\n",
      "Loss: 5.482535\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001462\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 531\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #532 *****\n",
      "Loss: 5.482515\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001464\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 532\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #533 *****\n",
      "Loss: 5.482495\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001467\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 533\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #534 *****\n",
      "Loss: 5.482475\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001470\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 534\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #535 *****\n",
      "Loss: 5.482455\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001473\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 535\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #536 *****\n",
      "Loss: 5.482435\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001475\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 536\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #537 *****\n",
      "Loss: 5.482416\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001478\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 537\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #538 *****\n",
      "Loss: 5.482396\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001481\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 538\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #539 *****\n",
      "Loss: 5.482376\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001484\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 539\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #540 *****\n",
      "Loss: 5.482356\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001486\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 540\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #541 *****\n",
      "Loss: 5.482336\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001489\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 541\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #542 *****\n",
      "Loss: 5.482316\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001492\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 542\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #543 *****\n",
      "Loss: 5.482297\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001495\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 543\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #544 *****\n",
      "Loss: 5.482277\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001497\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 544\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #545 *****\n",
      "Loss: 5.482257\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001500\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 545\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #546 *****\n",
      "Loss: 5.482237\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001503\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 546\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #547 *****\n",
      "Loss: 5.482217\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001506\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 547\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #548 *****\n",
      "Loss: 5.482197\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001508\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 548\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #549 *****\n",
      "Loss: 5.482178\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001511\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 549\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #550 *****\n",
      "Loss: 5.482158\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001514\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 550\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #551 *****\n",
      "Loss: 5.482138\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001517\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 551\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #552 *****\n",
      "Loss: 5.482118\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001519\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 552\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #553 *****\n",
      "Loss: 5.482098\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001522\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 553\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #554 *****\n",
      "Loss: 5.482078\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001525\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 554\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #555 *****\n",
      "Loss: 5.482059\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001528\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 555\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #556 *****\n",
      "Loss: 5.482039\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001530\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 556\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #557 *****\n",
      "Loss: 5.482019\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001533\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 557\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #558 *****\n",
      "Loss: 5.481999\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001536\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 558\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #559 *****\n",
      "Loss: 5.481979\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001539\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 559\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #560 *****\n",
      "Loss: 5.481959\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001541\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 560\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #561 *****\n",
      "Loss: 5.481939\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001544\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 561\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #562 *****\n",
      "Loss: 5.481920\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001547\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 562\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #563 *****\n",
      "Loss: 5.481900\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001550\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 563\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #564 *****\n",
      "Loss: 5.481880\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001552\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 564\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #565 *****\n",
      "Loss: 5.481860\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001555\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 565\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #566 *****\n",
      "Loss: 5.481840\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001558\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 566\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #567 *****\n",
      "Loss: 5.481820\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001561\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 567\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #568 *****\n",
      "Loss: 5.481801\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001563\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 568\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #569 *****\n",
      "Loss: 5.481781\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001566\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 569\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #570 *****\n",
      "Loss: 5.481761\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001569\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 570\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #571 *****\n",
      "Loss: 5.481741\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001572\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 571\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #572 *****\n",
      "Loss: 5.481721\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001574\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 572\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #573 *****\n",
      "Loss: 5.481701\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001577\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 573\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #574 *****\n",
      "Loss: 5.481682\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001580\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 574\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #575 *****\n",
      "Loss: 5.481662\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001583\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 575\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #576 *****\n",
      "Loss: 5.481642\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001585\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 576\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #577 *****\n",
      "Loss: 5.481622\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001588\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 577\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #578 *****\n",
      "Loss: 5.481602\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001591\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 578\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #579 *****\n",
      "Loss: 5.481582\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001594\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 579\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #580 *****\n",
      "Loss: 5.481563\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001596\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 580\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #581 *****\n",
      "Loss: 5.481543\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001599\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 581\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #582 *****\n",
      "Loss: 5.481523\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001602\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 582\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #583 *****\n",
      "Loss: 5.481503\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001605\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 583\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #584 *****\n",
      "Loss: 5.481483\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001607\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 584\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #585 *****\n",
      "Loss: 5.481463\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001610\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 585\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #586 *****\n",
      "Loss: 5.481444\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001613\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 586\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #587 *****\n",
      "Loss: 5.481424\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001616\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 587\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #588 *****\n",
      "Loss: 5.481404\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001618\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 588\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #589 *****\n",
      "Loss: 5.481384\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001621\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 589\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #590 *****\n",
      "Loss: 5.481364\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001624\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 590\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #591 *****\n",
      "Loss: 5.481344\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001627\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 591\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #592 *****\n",
      "Loss: 5.481325\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001629\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 592\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #593 *****\n",
      "Loss: 5.481305\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001632\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 593\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #594 *****\n",
      "Loss: 5.481285\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001635\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 594\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #595 *****\n",
      "Loss: 5.481265\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001638\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 595\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #596 *****\n",
      "Loss: 5.481245\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001640\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 596\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #597 *****\n",
      "Loss: 5.481225\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001643\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 597\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #598 *****\n",
      "Loss: 5.481206\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001646\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 598\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #599 *****\n",
      "Loss: 5.481186\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001649\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 599\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #600 *****\n",
      "Loss: 5.481166\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001651\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 600\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #601 *****\n",
      "Loss: 5.481146\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001654\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 601\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #602 *****\n",
      "Loss: 5.481126\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001657\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 602\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #603 *****\n",
      "Loss: 5.481106\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001660\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 603\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #604 *****\n",
      "Loss: 5.481087\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001662\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 604\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #605 *****\n",
      "Loss: 5.481067\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001665\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 605\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #606 *****\n",
      "Loss: 5.481047\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001668\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 606\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #607 *****\n",
      "Loss: 5.481027\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001671\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 607\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #608 *****\n",
      "Loss: 5.481007\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001673\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 608\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #609 *****\n",
      "Loss: 5.480987\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001676\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 609\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #610 *****\n",
      "Loss: 5.480968\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001679\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 610\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #611 *****\n",
      "Loss: 5.480948\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001682\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 611\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #612 *****\n",
      "Loss: 5.480928\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001684\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 612\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #613 *****\n",
      "Loss: 5.480908\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001687\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 613\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #614 *****\n",
      "Loss: 5.480888\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001690\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 614\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #615 *****\n",
      "Loss: 5.480868\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001693\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 615\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #616 *****\n",
      "Loss: 5.480849\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001695\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 616\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #617 *****\n",
      "Loss: 5.480829\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001698\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 617\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #618 *****\n",
      "Loss: 5.480809\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001701\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 618\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #619 *****\n",
      "Loss: 5.480789\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001704\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 619\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #620 *****\n",
      "Loss: 5.480769\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001706\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 620\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #621 *****\n",
      "Loss: 5.480749\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001709\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 621\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #622 *****\n",
      "Loss: 5.480730\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001712\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 622\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #623 *****\n",
      "Loss: 5.480710\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001715\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 623\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #624 *****\n",
      "Loss: 5.480690\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001717\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 624\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #625 *****\n",
      "Loss: 5.480670\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001720\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 625\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #626 *****\n",
      "Loss: 5.480650\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001723\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 626\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #627 *****\n",
      "Loss: 5.480630\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001726\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 627\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #628 *****\n",
      "Loss: 5.480611\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001728\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 628\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #629 *****\n",
      "Loss: 5.480591\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001731\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 629\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #630 *****\n",
      "Loss: 5.480571\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001734\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 630\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #631 *****\n",
      "Loss: 5.480551\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001737\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 631\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #632 *****\n",
      "Loss: 5.480531\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001739\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 632\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #633 *****\n",
      "Loss: 5.480511\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001742\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 633\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #634 *****\n",
      "Loss: 5.480492\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001745\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 634\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #635 *****\n",
      "Loss: 5.480472\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001748\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 635\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #636 *****\n",
      "Loss: 5.480452\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001750\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 636\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #637 *****\n",
      "Loss: 5.480432\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001753\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 637\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #638 *****\n",
      "Loss: 5.480412\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001756\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 638\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #639 *****\n",
      "Loss: 5.480392\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001759\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 639\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #640 *****\n",
      "Loss: 5.480373\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001761\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 640\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #641 *****\n",
      "Loss: 5.480353\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001764\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 641\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #642 *****\n",
      "Loss: 5.480333\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001767\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 642\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #643 *****\n",
      "Loss: 5.480313\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001770\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 643\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #644 *****\n",
      "Loss: 5.480293\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001772\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 644\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #645 *****\n",
      "Loss: 5.480273\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001775\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 645\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #646 *****\n",
      "Loss: 5.480254\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001778\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 646\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #647 *****\n",
      "Loss: 5.480234\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001781\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 647\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #648 *****\n",
      "Loss: 5.480214\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001783\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 648\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #649 *****\n",
      "Loss: 5.480194\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001786\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 649\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #650 *****\n",
      "Loss: 5.480174\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001789\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 650\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #651 *****\n",
      "Loss: 5.480154\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001792\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 651\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #652 *****\n",
      "Loss: 5.480135\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001794\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 652\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #653 *****\n",
      "Loss: 5.480115\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001797\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 653\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #654 *****\n",
      "Loss: 5.480095\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001800\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 654\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #655 *****\n",
      "Loss: 5.480075\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001803\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 655\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #656 *****\n",
      "Loss: 5.480055\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001805\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 656\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #657 *****\n",
      "Loss: 5.480035\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001808\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 657\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #658 *****\n",
      "Loss: 5.480016\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001811\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 658\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #659 *****\n",
      "Loss: 5.479996\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001814\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 659\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #660 *****\n",
      "Loss: 5.479976\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001816\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 660\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #661 *****\n",
      "Loss: 5.479956\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001819\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 661\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #662 *****\n",
      "Loss: 5.479936\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001822\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 662\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #663 *****\n",
      "Loss: 5.479916\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001825\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 663\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #664 *****\n",
      "Loss: 5.479897\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001827\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 664\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #665 *****\n",
      "Loss: 5.479877\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001830\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 665\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #666 *****\n",
      "Loss: 5.479857\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001833\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 666\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #667 *****\n",
      "Loss: 5.479837\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001836\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 667\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #668 *****\n",
      "Loss: 5.479817\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001838\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 668\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #669 *****\n",
      "Loss: 5.479797\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001841\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 669\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #670 *****\n",
      "Loss: 5.479778\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001844\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 670\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #671 *****\n",
      "Loss: 5.479758\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001847\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 671\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #672 *****\n",
      "Loss: 5.479738\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001849\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 672\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #673 *****\n",
      "Loss: 5.479718\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001852\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 673\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #674 *****\n",
      "Loss: 5.479698\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001855\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 674\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #675 *****\n",
      "Loss: 5.479678\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001858\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 675\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #676 *****\n",
      "Loss: 5.479659\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001860\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 676\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #677 *****\n",
      "Loss: 5.479639\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001863\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 677\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #678 *****\n",
      "Loss: 5.479619\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001866\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 678\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #679 *****\n",
      "Loss: 5.479599\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001869\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 679\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #680 *****\n",
      "Loss: 5.479579\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001871\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 680\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #681 *****\n",
      "Loss: 5.479560\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001874\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 681\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #682 *****\n",
      "Loss: 5.479540\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001877\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 682\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #683 *****\n",
      "Loss: 5.479520\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001880\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 683\n",
      "Seconds required for this iteration: 0.000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #684 *****\n",
      "Loss: 5.479500\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001882\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 684\n",
      "Seconds required for this iteration: 0.004\n",
      "\n",
      "***** Epoch #685 *****\n",
      "Loss: 5.479480\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001885\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 685\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #686 *****\n",
      "Loss: 5.479460\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001888\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 686\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #687 *****\n",
      "Loss: 5.479441\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001891\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 687\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #688 *****\n",
      "Loss: 5.479421\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001893\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 688\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #689 *****\n",
      "Loss: 5.479401\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001896\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 689\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #690 *****\n",
      "Loss: 5.479381\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001899\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 690\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #691 *****\n",
      "Loss: 5.479361\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001902\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 691\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #692 *****\n",
      "Loss: 5.479341\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001904\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 692\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #693 *****\n",
      "Loss: 5.479322\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001907\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 693\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #694 *****\n",
      "Loss: 5.479302\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001910\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 694\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #695 *****\n",
      "Loss: 5.479282\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001913\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 695\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #696 *****\n",
      "Loss: 5.479262\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001915\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 696\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #697 *****\n",
      "Loss: 5.479242\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001918\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 697\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #698 *****\n",
      "Loss: 5.479222\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001921\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 698\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #699 *****\n",
      "Loss: 5.479203\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001924\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 699\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #700 *****\n",
      "Loss: 5.479183\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001926\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 700\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #701 *****\n",
      "Loss: 5.479163\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001929\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 701\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #702 *****\n",
      "Loss: 5.479143\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001932\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 702\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #703 *****\n",
      "Loss: 5.479123\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001935\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 703\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #704 *****\n",
      "Loss: 5.479104\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001937\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 704\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #705 *****\n",
      "Loss: 5.479084\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001940\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 705\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #706 *****\n",
      "Loss: 5.479064\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001943\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 706\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #707 *****\n",
      "Loss: 5.479044\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001946\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 707\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #708 *****\n",
      "Loss: 5.479024\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001948\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 708\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #709 *****\n",
      "Loss: 5.479004\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001951\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 709\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #710 *****\n",
      "Loss: 5.478985\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001954\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 710\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #711 *****\n",
      "Loss: 5.478965\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001957\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 711\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #712 *****\n",
      "Loss: 5.478945\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001959\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 712\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #713 *****\n",
      "Loss: 5.478925\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001962\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 713\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #714 *****\n",
      "Loss: 5.478905\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001965\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 714\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #715 *****\n",
      "Loss: 5.478885\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001968\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 715\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #716 *****\n",
      "Loss: 5.478866\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001970\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 716\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #717 *****\n",
      "Loss: 5.478846\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001973\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 717\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #718 *****\n",
      "Loss: 5.478826\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001976\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 718\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #719 *****\n",
      "Loss: 5.478806\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001979\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 719\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #720 *****\n",
      "Loss: 5.478786\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001981\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 720\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #721 *****\n",
      "Loss: 5.478766\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001984\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 721\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #722 *****\n",
      "Loss: 5.478747\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001987\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 722\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #723 *****\n",
      "Loss: 5.478727\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001990\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 723\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #724 *****\n",
      "Loss: 5.478707\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001992\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 724\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #725 *****\n",
      "Loss: 5.478687\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001995\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 725\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #726 *****\n",
      "Loss: 5.478667\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.001998\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 726\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #727 *****\n",
      "Loss: 5.478648\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002001\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 727\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #728 *****\n",
      "Loss: 5.478628\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002003\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 728\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #729 *****\n",
      "Loss: 5.478608\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002006\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 729\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #730 *****\n",
      "Loss: 5.478588\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002009\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 730\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #731 *****\n",
      "Loss: 5.478568\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002012\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 731\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #732 *****\n",
      "Loss: 5.478548\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002014\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 732\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #733 *****\n",
      "Loss: 5.478529\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002017\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 733\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #734 *****\n",
      "Loss: 5.478509\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002020\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 734\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #735 *****\n",
      "Loss: 5.478489\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002023\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 735\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #736 *****\n",
      "Loss: 5.478469\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002025\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 736\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #737 *****\n",
      "Loss: 5.478449\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002028\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 737\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #738 *****\n",
      "Loss: 5.478429\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002031\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 738\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #739 *****\n",
      "Loss: 5.478410\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002034\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 739\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #740 *****\n",
      "Loss: 5.478390\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002036\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 740\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #741 *****\n",
      "Loss: 5.478370\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002039\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 741\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #742 *****\n",
      "Loss: 5.478350\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002042\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 742\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #743 *****\n",
      "Loss: 5.478330\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002045\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 743\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #744 *****\n",
      "Loss: 5.478311\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002047\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 744\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #745 *****\n",
      "Loss: 5.478291\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002050\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 745\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #746 *****\n",
      "Loss: 5.478271\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002053\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 746\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #747 *****\n",
      "Loss: 5.478251\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002056\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 747\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #748 *****\n",
      "Loss: 5.478231\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002058\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 748\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #749 *****\n",
      "Loss: 5.478211\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002061\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 749\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #750 *****\n",
      "Loss: 5.478192\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002064\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 750\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #751 *****\n",
      "Loss: 5.478172\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002067\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 751\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #752 *****\n",
      "Loss: 5.478152\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002069\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 752\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #753 *****\n",
      "Loss: 5.478132\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002072\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 753\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #754 *****\n",
      "Loss: 5.478112\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002075\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 754\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #755 *****\n",
      "Loss: 5.478092\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002078\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 755\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #756 *****\n",
      "Loss: 5.478073\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002080\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 756\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #757 *****\n",
      "Loss: 5.478053\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002083\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 757\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #758 *****\n",
      "Loss: 5.478033\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002086\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 758\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #759 *****\n",
      "Loss: 5.478013\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002089\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 759\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #760 *****\n",
      "Loss: 5.477993\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002091\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 760\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #761 *****\n",
      "Loss: 5.477974\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002094\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 761\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #762 *****\n",
      "Loss: 5.477954\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002097\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 762\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #763 *****\n",
      "Loss: 5.477934\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002100\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 763\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #764 *****\n",
      "Loss: 5.477914\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002102\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 764\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #765 *****\n",
      "Loss: 5.477894\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002105\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 765\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #766 *****\n",
      "Loss: 5.477874\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002108\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 766\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #767 *****\n",
      "Loss: 5.477855\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002111\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 767\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #768 *****\n",
      "Loss: 5.477835\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002113\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 768\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #769 *****\n",
      "Loss: 5.477815\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002116\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 769\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #770 *****\n",
      "Loss: 5.477795\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002119\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 770\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #771 *****\n",
      "Loss: 5.477775\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002122\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 771\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #772 *****\n",
      "Loss: 5.477756\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002124\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 772\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #773 *****\n",
      "Loss: 5.477736\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002127\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 773\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #774 *****\n",
      "Loss: 5.477716\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002130\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 774\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #775 *****\n",
      "Loss: 5.477696\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002133\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 775\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #776 *****\n",
      "Loss: 5.477676\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002135\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 776\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #777 *****\n",
      "Loss: 5.477656\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002138\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 777\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #778 *****\n",
      "Loss: 5.477637\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002141\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 778\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #779 *****\n",
      "Loss: 5.477617\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002144\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 779\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #780 *****\n",
      "Loss: 5.477597\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002146\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 780\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #781 *****\n",
      "Loss: 5.477577\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002149\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 781\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #782 *****\n",
      "Loss: 5.477557\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002152\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 782\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #783 *****\n",
      "Loss: 5.477537\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002155\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 783\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #784 *****\n",
      "Loss: 5.477518\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002157\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 784\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #785 *****\n",
      "Loss: 5.477498\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002160\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 785\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #786 *****\n",
      "Loss: 5.477478\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002163\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 786\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #787 *****\n",
      "Loss: 5.477458\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002166\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 787\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #788 *****\n",
      "Loss: 5.477438\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002168\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 788\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #789 *****\n",
      "Loss: 5.477419\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002171\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 789\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #790 *****\n",
      "Loss: 5.477399\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002174\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 790\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #791 *****\n",
      "Loss: 5.477379\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002177\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 791\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #792 *****\n",
      "Loss: 5.477359\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002179\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 792\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #793 *****\n",
      "Loss: 5.477339\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002182\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 793\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #794 *****\n",
      "Loss: 5.477319\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002185\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 794\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #795 *****\n",
      "Loss: 5.477300\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002188\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 795\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #796 *****\n",
      "Loss: 5.477280\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002190\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 796\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #797 *****\n",
      "Loss: 5.477260\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002193\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 797\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #798 *****\n",
      "Loss: 5.477240\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002196\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 798\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #799 *****\n",
      "Loss: 5.477220\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002199\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 799\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #800 *****\n",
      "Loss: 5.477201\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002201\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 800\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #801 *****\n",
      "Loss: 5.477181\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002204\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 801\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #802 *****\n",
      "Loss: 5.477161\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002207\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 802\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #803 *****\n",
      "Loss: 5.477141\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002210\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 803\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #804 *****\n",
      "Loss: 5.477121\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002212\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 804\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #805 *****\n",
      "Loss: 5.477101\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002215\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 805\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #806 *****\n",
      "Loss: 5.477082\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002218\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 806\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #807 *****\n",
      "Loss: 5.477062\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002221\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 807\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #808 *****\n",
      "Loss: 5.477042\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002223\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 808\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #809 *****\n",
      "Loss: 5.477022\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002226\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 809\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #810 *****\n",
      "Loss: 5.477002\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002229\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 810\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #811 *****\n",
      "Loss: 5.476983\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002232\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 811\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #812 *****\n",
      "Loss: 5.476963\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002234\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 812\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #813 *****\n",
      "Loss: 5.476943\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002237\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 813\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #814 *****\n",
      "Loss: 5.476923\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002240\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 814\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #815 *****\n",
      "Loss: 5.476903\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002243\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 815\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #816 *****\n",
      "Loss: 5.476883\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002245\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 816\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #817 *****\n",
      "Loss: 5.476864\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002248\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 817\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #818 *****\n",
      "Loss: 5.476844\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002251\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 818\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #819 *****\n",
      "Loss: 5.476824\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002254\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 819\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #820 *****\n",
      "Loss: 5.476804\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002256\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 820\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #821 *****\n",
      "Loss: 5.476784\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002259\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 821\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #822 *****\n",
      "Loss: 5.476765\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002262\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 822\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #823 *****\n",
      "Loss: 5.476745\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002265\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 823\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #824 *****\n",
      "Loss: 5.476725\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002267\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 824\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #825 *****\n",
      "Loss: 5.476705\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002270\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 825\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #826 *****\n",
      "Loss: 5.476685\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002273\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 826\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #827 *****\n",
      "Loss: 5.476666\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002276\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 827\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #828 *****\n",
      "Loss: 5.476646\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002278\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 828\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #829 *****\n",
      "Loss: 5.476626\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002281\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 829\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #830 *****\n",
      "Loss: 5.476606\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002284\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 830\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #831 *****\n",
      "Loss: 5.476586\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002287\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 831\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #832 *****\n",
      "Loss: 5.476566\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002289\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 832\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #833 *****\n",
      "Loss: 5.476547\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002292\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 833\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #834 *****\n",
      "Loss: 5.476527\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002295\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 834\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #835 *****\n",
      "Loss: 5.476507\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002298\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 835\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #836 *****\n",
      "Loss: 5.476487\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002300\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 836\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #837 *****\n",
      "Loss: 5.476467\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002303\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 837\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #838 *****\n",
      "Loss: 5.476448\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002306\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 838\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #839 *****\n",
      "Loss: 5.476428\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002309\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 839\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #840 *****\n",
      "Loss: 5.476408\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002311\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 840\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #841 *****\n",
      "Loss: 5.476388\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002314\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 841\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #842 *****\n",
      "Loss: 5.476368\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002317\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 842\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #843 *****\n",
      "Loss: 5.476348\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002320\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 843\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #844 *****\n",
      "Loss: 5.476329\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002322\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 844\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #845 *****\n",
      "Loss: 5.476309\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002325\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 845\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #846 *****\n",
      "Loss: 5.476289\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002328\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 846\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #847 *****\n",
      "Loss: 5.476269\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002331\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 847\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #848 *****\n",
      "Loss: 5.476249\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002333\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 848\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #849 *****\n",
      "Loss: 5.476230\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002336\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 849\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #850 *****\n",
      "Loss: 5.476210\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002339\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 850\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #851 *****\n",
      "Loss: 5.476190\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002342\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 851\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #852 *****\n",
      "Loss: 5.476170\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002344\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 852\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #853 *****\n",
      "Loss: 5.476150\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002347\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 853\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #854 *****\n",
      "Loss: 5.476131\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002350\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 854\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #855 *****\n",
      "Loss: 5.476111\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002353\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 855\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #856 *****\n",
      "Loss: 5.476091\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002355\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 856\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #857 *****\n",
      "Loss: 5.476071\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002358\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 857\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #858 *****\n",
      "Loss: 5.476051\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002361\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 858\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #859 *****\n",
      "Loss: 5.476031\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002364\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 859\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #860 *****\n",
      "Loss: 5.476012\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002366\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 860\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #861 *****\n",
      "Loss: 5.475992\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002369\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 861\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #862 *****\n",
      "Loss: 5.475972\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002372\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 862\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #863 *****\n",
      "Loss: 5.475952\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002375\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 863\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #864 *****\n",
      "Loss: 5.475932\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002377\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 864\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #865 *****\n",
      "Loss: 5.475913\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002380\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 865\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #866 *****\n",
      "Loss: 5.475893\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002383\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 866\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #867 *****\n",
      "Loss: 5.475873\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002386\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 867\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #868 *****\n",
      "Loss: 5.475853\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002388\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 868\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #869 *****\n",
      "Loss: 5.475833\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002391\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 869\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #870 *****\n",
      "Loss: 5.475813\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002394\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 870\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #871 *****\n",
      "Loss: 5.475794\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002397\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 871\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #872 *****\n",
      "Loss: 5.475774\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002399\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 872\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #873 *****\n",
      "Loss: 5.475754\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002402\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 873\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #874 *****\n",
      "Loss: 5.475734\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002405\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 874\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #875 *****\n",
      "Loss: 5.475714\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002408\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 875\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #876 *****\n",
      "Loss: 5.475695\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002410\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 876\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #877 *****\n",
      "Loss: 5.475675\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002413\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 877\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #878 *****\n",
      "Loss: 5.475655\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002416\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 878\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #879 *****\n",
      "Loss: 5.475635\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002419\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 879\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #880 *****\n",
      "Loss: 5.475615\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002421\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 880\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #881 *****\n",
      "Loss: 5.475596\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002424\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 881\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #882 *****\n",
      "Loss: 5.475576\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002427\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 882\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #883 *****\n",
      "Loss: 5.475556\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002430\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 883\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #884 *****\n",
      "Loss: 5.475536\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002432\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 884\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #885 *****\n",
      "Loss: 5.475516\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002435\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 885\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #886 *****\n",
      "Loss: 5.475497\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002438\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 886\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #887 *****\n",
      "Loss: 5.475477\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002441\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 887\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #888 *****\n",
      "Loss: 5.475457\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002443\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 888\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #889 *****\n",
      "Loss: 5.475437\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002446\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 889\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #890 *****\n",
      "Loss: 5.475417\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002449\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 890\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #891 *****\n",
      "Loss: 5.475397\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002452\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 891\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #892 *****\n",
      "Loss: 5.475378\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002454\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 892\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #893 *****\n",
      "Loss: 5.475358\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002457\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 893\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #894 *****\n",
      "Loss: 5.475338\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002460\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 894\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #895 *****\n",
      "Loss: 5.475318\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002463\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 895\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #896 *****\n",
      "Loss: 5.475298\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002465\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 896\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #897 *****\n",
      "Loss: 5.475279\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002468\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 897\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #898 *****\n",
      "Loss: 5.475259\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002471\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 898\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #899 *****\n",
      "Loss: 5.475239\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002474\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 899\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #900 *****\n",
      "Loss: 5.475219\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002476\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 900\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #901 *****\n",
      "Loss: 5.475199\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002479\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 901\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #902 *****\n",
      "Loss: 5.475180\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002482\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 902\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #903 *****\n",
      "Loss: 5.475160\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002485\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 903\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #904 *****\n",
      "Loss: 5.475140\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002487\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 904\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #905 *****\n",
      "Loss: 5.475120\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002490\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 905\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #906 *****\n",
      "Loss: 5.475100\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002493\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 906\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #907 *****\n",
      "Loss: 5.475080\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002496\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 907\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #908 *****\n",
      "Loss: 5.475061\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002498\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 908\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #909 *****\n",
      "Loss: 5.475041\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002501\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 909\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #910 *****\n",
      "Loss: 5.475021\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002504\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 910\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #911 *****\n",
      "Loss: 5.475001\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002507\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 911\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #912 *****\n",
      "Loss: 5.474981\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002509\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 912\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #913 *****\n",
      "Loss: 5.474962\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002512\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 913\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #914 *****\n",
      "Loss: 5.474942\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002515\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 914\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #915 *****\n",
      "Loss: 5.474922\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002518\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 915\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #916 *****\n",
      "Loss: 5.474902\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002520\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 916\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #917 *****\n",
      "Loss: 5.474882\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002523\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 917\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #918 *****\n",
      "Loss: 5.474863\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002526\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 918\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #919 *****\n",
      "Loss: 5.474843\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002529\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 919\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #920 *****\n",
      "Loss: 5.474823\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002531\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 920\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #921 *****\n",
      "Loss: 5.474803\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002534\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 921\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #922 *****\n",
      "Loss: 5.474783\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002537\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 922\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #923 *****\n",
      "Loss: 5.474764\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002540\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 923\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #924 *****\n",
      "Loss: 5.474744\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002542\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 924\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #925 *****\n",
      "Loss: 5.474724\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002545\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 925\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #926 *****\n",
      "Loss: 5.474704\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002548\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 926\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #927 *****\n",
      "Loss: 5.474684\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002551\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 927\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #928 *****\n",
      "Loss: 5.474665\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002553\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 928\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #929 *****\n",
      "Loss: 5.474645\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002556\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 929\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #930 *****\n",
      "Loss: 5.474625\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002559\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 930\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #931 *****\n",
      "Loss: 5.474605\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002562\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 931\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #932 *****\n",
      "Loss: 5.474585\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002564\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 932\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #933 *****\n",
      "Loss: 5.474565\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002567\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 933\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #934 *****\n",
      "Loss: 5.474546\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002570\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 934\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #935 *****\n",
      "Loss: 5.474526\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002573\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 935\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #936 *****\n",
      "Loss: 5.474506\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002575\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 936\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #937 *****\n",
      "Loss: 5.474486\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002578\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 937\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #938 *****\n",
      "Loss: 5.474466\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002581\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 938\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #939 *****\n",
      "Loss: 5.474447\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002584\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 939\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #940 *****\n",
      "Loss: 5.474427\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002586\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 940\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #941 *****\n",
      "Loss: 5.474407\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002589\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 941\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #942 *****\n",
      "Loss: 5.474387\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002592\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 942\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #943 *****\n",
      "Loss: 5.474367\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002595\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 943\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #944 *****\n",
      "Loss: 5.474348\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002597\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 944\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #945 *****\n",
      "Loss: 5.474328\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002600\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 945\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #946 *****\n",
      "Loss: 5.474308\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002603\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 946\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #947 *****\n",
      "Loss: 5.474288\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002606\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 947\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #948 *****\n",
      "Loss: 5.474268\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002608\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 948\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #949 *****\n",
      "Loss: 5.474249\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002611\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 949\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #950 *****\n",
      "Loss: 5.474229\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002614\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 950\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #951 *****\n",
      "Loss: 5.474209\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002617\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 951\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #952 *****\n",
      "Loss: 5.474189\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002619\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 952\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #953 *****\n",
      "Loss: 5.474169\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002622\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 953\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #954 *****\n",
      "Loss: 5.474150\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002625\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 954\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #955 *****\n",
      "Loss: 5.474130\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002628\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 955\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #956 *****\n",
      "Loss: 5.474110\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002630\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 956\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #957 *****\n",
      "Loss: 5.474090\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002633\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 957\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #958 *****\n",
      "Loss: 5.474070\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002636\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 958\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #959 *****\n",
      "Loss: 5.474050\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002639\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 959\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #960 *****\n",
      "Loss: 5.474031\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002641\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 960\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #961 *****\n",
      "Loss: 5.474011\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002644\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 961\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #962 *****\n",
      "Loss: 5.473991\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002647\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 962\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #963 *****\n",
      "Loss: 5.473971\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002650\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 963\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #964 *****\n",
      "Loss: 5.473951\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002652\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 964\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #965 *****\n",
      "Loss: 5.473932\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002655\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 965\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #966 *****\n",
      "Loss: 5.473912\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002658\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 966\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #967 *****\n",
      "Loss: 5.473892\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002661\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 967\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #968 *****\n",
      "Loss: 5.473872\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002663\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 968\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #969 *****\n",
      "Loss: 5.473852\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002666\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 969\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #970 *****\n",
      "Loss: 5.473833\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002669\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 970\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #971 *****\n",
      "Loss: 5.473813\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002672\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 971\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #972 *****\n",
      "Loss: 5.473793\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002674\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 972\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #973 *****\n",
      "Loss: 5.473773\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002677\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 973\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #974 *****\n",
      "Loss: 5.473753\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002680\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 974\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #975 *****\n",
      "Loss: 5.473734\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002683\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 975\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #976 *****\n",
      "Loss: 5.473714\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002685\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 976\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #977 *****\n",
      "Loss: 5.473694\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002688\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 977\n",
      "Seconds required for this iteration: 0.002\n",
      "\n",
      "***** Epoch #978 *****\n",
      "Loss: 5.473674\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002691\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 978\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #979 *****\n",
      "Loss: 5.473654\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002694\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 979\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #980 *****\n",
      "Loss: 5.473635\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002696\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 980\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #981 *****\n",
      "Loss: 5.473615\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002699\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 981\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #982 *****\n",
      "Loss: 5.473595\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002702\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 982\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #983 *****\n",
      "Loss: 5.473575\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002705\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 983\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #984 *****\n",
      "Loss: 5.473555\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002707\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 984\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #985 *****\n",
      "Loss: 5.473536\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002710\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 985\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #986 *****\n",
      "Loss: 5.473516\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002713\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 986\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #987 *****\n",
      "Loss: 5.473496\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002716\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 987\n",
      "Seconds required for this iteration: 0.001\n",
      "\n",
      "***** Epoch #988 *****\n",
      "Loss: 5.473476\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002718\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 988\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #989 *****\n",
      "Loss: 5.473456\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002721\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 989\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #990 *****\n",
      "Loss: 5.473437\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002724\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 990\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #991 *****\n",
      "Loss: 5.473417\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002727\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 991\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #992 *****\n",
      "Loss: 5.473397\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002729\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 992\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #993 *****\n",
      "Loss: 5.473377\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002732\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 993\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #994 *****\n",
      "Loss: 5.473357\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002735\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 994\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #995 *****\n",
      "Loss: 5.473338\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002738\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 995\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #996 *****\n",
      "Loss: 5.473318\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002740\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 996\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #997 *****\n",
      "Loss: 5.473298\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002743\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 997\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #998 *****\n",
      "Loss: 5.473278\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002746\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 998\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #999 *****\n",
      "Loss: 5.473258\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002749\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 999\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "***** Epoch #1000 *****\n",
      "Loss: 5.473239\n",
      "Improvement ratio: 0.000036\n",
      "Feature L2-norm: 0.002751\n",
      "Learning rate (eta): 0.000000\n",
      "Total number of feature updates: 1000\n",
      "Seconds required for this iteration: 0.000\n",
      "\n",
      "SGD terminated with the maximum number of iterations\n",
      "Loss: 5.473239\n",
      "Total seconds required for training: 0.771\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 117 (117)\n",
      "Number of active attributes: 105 (105)\n",
      "Number of active labels: 3 (3)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Treenime, kasutades treeningkorpust ja märgendeid;\n",
    "# salvestame tulemuse kausta 'test'\n",
    "trainer.train(text, labels, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# See on meie testkorpus - ei kattu treeningkorpusega\n",
    "text2 = Text('Läti president elab Riias.').tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Läti president elab Riias.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Läti president elab Riias.')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardne NER-tagger leiab asukohad\n",
    "ner_tagger.tag(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Läti']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Riias']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner', attributes=('nertag',), spans=SL[EnvelopingSpan(['Läti'], [{'nertag': 'LOC'}]),\n",
       "EnvelopingSpan(['Riias'], [{'nertag': 'LOC'}])])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2.ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Loome uue NER-taggeri oma loodud 'test' mudeli põhjal\n",
    "# Anname väljundkihile nimeks ner2, \n",
    "# sest ner kiht on juba meie tekstil olemas\n",
    "ner_tagger2 = NerTagger(model_dir = 'test', output_layer = 'ner2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Läti president elab Riias.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner2</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Läti president elab Riias.')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tagger2.tag(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Läti']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Riias']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner', attributes=('nertag',), spans=SL[EnvelopingSpan(['Läti'], [{'nertag': 'LOC'}]),\n",
       "EnvelopingSpan(['Riias'], [{'nertag': 'LOC'}])])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2.ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner2</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Läti']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['president']</td>\n",
       "      <td>VOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Riias']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner2', attributes=('nertag',), spans=SL[EnvelopingSpan(['Läti'], [{'nertag': 'LOC'}]),\n",
       "EnvelopingSpan(['president'], [{'nertag': 'VOC'}]),\n",
       "EnvelopingSpan(['Riias'], [{'nertag': 'LOC'}])])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2.ner2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner2</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Läti']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['peaminister']</td>\n",
       "      <td>VOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Riias']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner2', attributes=('nertag',), spans=SL[EnvelopingSpan(['Läti'], [{'nertag': 'LOC'}]),\n",
       "EnvelopingSpan(['peaminister'], [{'nertag': 'VOC'}]),\n",
       "EnvelopingSpan(['Riias'], [{'nertag': 'LOC'}])])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = Text('Läti peaminister elab ka Riias.').tag_layer()\n",
    "ner_tagger2.tag(text3)\n",
    "text3.ner2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"kokkuvõte1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"kokuvõte2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"kokkuvõte.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"lõpp.png\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:estnltk] *",
   "language": "python",
   "name": "conda-env-estnltk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
